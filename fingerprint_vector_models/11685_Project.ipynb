{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "11685 Project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "prDP7lO90pFB",
        "AfUN7fz_3ObI",
        "SeeGRF0U3U16",
        "kRP-FitX3fQr",
        "Ac60F9xNEqOK",
        "d5rCSWuOEfLH",
        "KOFnYcKtLEHJ",
        "Ca-s9wHj7VjR",
        "QQMIc-ge_NCP",
        "72nDNZwNOZCE"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "prDP7lO90pFB"
      },
      "source": [
        "#Check Hardware Info"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97EqiW4T0nib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eca4055-7faf-4e8e-ce19-6567f27c3141"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Dec 11 04:28:07 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.45.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aIUDz5p0nBq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58b957b9-6b93-42c6-a643-5601bd122aa6"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 27.4 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfUN7fz_3ObI"
      },
      "source": [
        "# Environment Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6V-aENH5MFc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb23ba0b-9df2-40e3-946e-a6922be51644"
      },
      "source": [
        "%env PYTHONPATH="
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: PYTHONPATH=\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZrWO7zs4MJW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf8f9071-2720-4676-9c3e-33863e505edb"
      },
      "source": [
        "%%bash\n",
        "MINICONDA_INSTALLER_SCRIPT=Miniconda3-4.5.4-Linux-x86_64.sh\n",
        "MINICONDA_PREFIX=/usr/local\n",
        "wget https://repo.continuum.io/miniconda/$MINICONDA_INSTALLER_SCRIPT\n",
        "chmod +x $MINICONDA_INSTALLER_SCRIPT\n",
        "./$MINICONDA_INSTALLER_SCRIPT -b -f -p $MINICONDA_PREFIX\n",
        "rm -f Miniconda3-4.5.4-Linux-x86_64.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PREFIX=/usr/local\n",
            "installing: python-3.6.5-hc3d631a_2 ...\n",
            "installing: ca-certificates-2018.03.07-0 ...\n",
            "installing: conda-env-2.6.0-h36134e3_1 ...\n",
            "installing: libgcc-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libstdcxx-ng-7.2.0-hdf63c60_3 ...\n",
            "installing: libffi-3.2.1-hd88cf55_4 ...\n",
            "installing: ncurses-6.1-hf484d3e_0 ...\n",
            "installing: openssl-1.0.2o-h20670df_0 ...\n",
            "installing: tk-8.6.7-hc745277_3 ...\n",
            "installing: xz-5.2.4-h14c3975_4 ...\n",
            "installing: yaml-0.1.7-had09818_2 ...\n",
            "installing: zlib-1.2.11-ha838bed_2 ...\n",
            "installing: libedit-3.1.20170329-h6b74fdf_2 ...\n",
            "installing: readline-7.0-ha6073c6_4 ...\n",
            "installing: sqlite-3.23.1-he433501_0 ...\n",
            "installing: asn1crypto-0.24.0-py36_0 ...\n",
            "installing: certifi-2018.4.16-py36_0 ...\n",
            "installing: chardet-3.0.4-py36h0f667ec_1 ...\n",
            "installing: idna-2.6-py36h82fb2a8_1 ...\n",
            "installing: pycosat-0.6.3-py36h0a5515d_0 ...\n",
            "installing: pycparser-2.18-py36hf9f622e_1 ...\n",
            "installing: pysocks-1.6.8-py36_0 ...\n",
            "installing: ruamel_yaml-0.15.37-py36h14c3975_2 ...\n",
            "installing: six-1.11.0-py36h372c433_1 ...\n",
            "installing: cffi-1.11.5-py36h9745a5d_0 ...\n",
            "installing: setuptools-39.2.0-py36_0 ...\n",
            "installing: cryptography-2.2.2-py36h14c3975_0 ...\n",
            "installing: wheel-0.31.1-py36_0 ...\n",
            "installing: pip-10.0.1-py36_0 ...\n",
            "installing: pyopenssl-18.0.0-py36_0 ...\n",
            "installing: urllib3-1.22-py36hbe7ace6_0 ...\n",
            "installing: requests-2.18.4-py36he2e5f8d_1 ...\n",
            "installing: conda-4.5.4-py36_0 ...\n",
            "installation finished.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "--2020-12-11 04:28:19--  https://repo.continuum.io/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.201.79, 104.18.200.79, 2606:4700::6812:c84f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.201.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh [following]\n",
            "--2020-12-11 04:28:19--  https://repo.anaconda.com/miniconda/Miniconda3-4.5.4-Linux-x86_64.sh\n",
            "Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.131.3, 104.16.130.3, 2606:4700::6810:8203, ...\n",
            "Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.131.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 58468498 (56M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-4.5.4-Linux-x86_64.sh’\n",
            "\n",
            "     0K .......... .......... .......... .......... ..........  0% 65.6M 1s\n",
            "    50K .......... .......... .......... .......... ..........  0% 3.89M 8s\n",
            "   100K .......... .......... .......... .......... ..........  0% 3.87M 10s\n",
            "   150K .......... .......... .......... .......... ..........  0%  105M 7s\n",
            "   200K .......... .......... .......... .......... ..........  0% 4.07M 9s\n",
            "   250K .......... .......... .......... .......... ..........  0%  196M 7s\n",
            "   300K .......... .......... .......... .......... ..........  0%  188M 6s\n",
            "   350K .......... .......... .......... .......... ..........  0%  120M 6s\n",
            "   400K .......... .......... .......... .......... ..........  0% 62.4M 5s\n",
            "   450K .......... .......... .......... .......... ..........  0% 62.5M 5s\n",
            "   500K .......... .......... .......... .......... ..........  0%  182M 4s\n",
            "   550K .......... .......... .......... .......... ..........  1% 72.1M 4s\n",
            "   600K .......... .......... .......... .......... ..........  1% 5.30M 4s\n",
            "   650K .......... .......... .......... .......... ..........  1% 58.4M 4s\n",
            "   700K .......... .......... .......... .......... ..........  1%  114M 4s\n",
            "   750K .......... .......... .......... .......... ..........  1% 93.4M 4s\n",
            "   800K .......... .......... .......... .......... ..........  1% 67.0M 4s\n",
            "   850K .......... .......... .......... .......... ..........  1% 62.8M 3s\n",
            "   900K .......... .......... .......... .......... ..........  1% 63.7M 3s\n",
            "   950K .......... .......... .......... .......... ..........  1% 72.0M 3s\n",
            "  1000K .......... .......... .......... .......... ..........  1%  199M 3s\n",
            "  1050K .......... .......... .......... .......... ..........  1% 70.3M 3s\n",
            "  1100K .......... .......... .......... .......... ..........  2% 6.41M 3s\n",
            "  1150K .......... .......... .......... .......... ..........  2%  166M 3s\n",
            "  1200K .......... .......... .......... .......... ..........  2% 87.3M 3s\n",
            "  1250K .......... .......... .......... .......... ..........  2%  115M 3s\n",
            "  1300K .......... .......... .......... .......... ..........  2% 62.3M 3s\n",
            "  1350K .......... .......... .......... .......... ..........  2% 72.2M 3s\n",
            "  1400K .......... .......... .......... .......... ..........  2% 82.0M 3s\n",
            "  1450K .......... .......... .......... .......... ..........  2%  199M 3s\n",
            "  1500K .......... .......... .......... .......... ..........  2% 86.5M 2s\n",
            "  1550K .......... .......... .......... .......... ..........  2% 73.8M 2s\n",
            "  1600K .......... .......... .......... .......... ..........  2% 74.7M 2s\n",
            "  1650K .......... .......... .......... .......... ..........  2% 74.9M 2s\n",
            "  1700K .......... .......... .......... .......... ..........  3%  297M 2s\n",
            "  1750K .......... .......... .......... .......... ..........  3% 82.5M 2s\n",
            "  1800K .......... .......... .......... .......... ..........  3% 78.9M 2s\n",
            "  1850K .......... .......... .......... .......... ..........  3% 9.88M 2s\n",
            "  1900K .......... .......... .......... .......... ..........  3%  239M 2s\n",
            "  1950K .......... .......... .......... .......... ..........  3%  118M 2s\n",
            "  2000K .......... .......... .......... .......... ..........  3% 91.2M 2s\n",
            "  2050K .......... .......... .......... .......... ..........  3%  159M 2s\n",
            "  2100K .......... .......... .......... .......... ..........  3%  111M 2s\n",
            "  2150K .......... .......... .......... .......... ..........  3% 87.0M 2s\n",
            "  2200K .......... .......... .......... .......... ..........  3%  114M 2s\n",
            "  2250K .......... .......... .......... .......... ..........  4%  244M 2s\n",
            "  2300K .......... .......... .......... .......... ..........  4%  148M 2s\n",
            "  2350K .......... .......... .......... .......... ..........  4%  103M 2s\n",
            "  2400K .......... .......... .......... .......... ..........  4%  105M 2s\n",
            "  2450K .......... .......... .......... .......... ..........  4%  123M 2s\n",
            "  2500K .......... .......... .......... .......... ..........  4%  291M 2s\n",
            "  2550K .......... .......... .......... .......... ..........  4% 90.5M 2s\n",
            "  2600K .......... .......... .......... .......... ..........  4%  115M 2s\n",
            "  2650K .......... .......... .......... .......... ..........  4%  131M 2s\n",
            "  2700K .......... .......... .......... .......... ..........  4% 99.1M 2s\n",
            "  2750K .......... .......... .......... .......... ..........  4%  176M 2s\n",
            "  2800K .......... .......... .......... .......... ..........  4%  121M 2s\n",
            "  2850K .......... .......... .......... .......... ..........  5%  147M 2s\n",
            "  2900K .......... .......... .......... .......... ..........  5%  131M 2s\n",
            "  2950K .......... .......... .......... .......... ..........  5%  100M 2s\n",
            "  3000K .......... .......... .......... .......... ..........  5%  206M 2s\n",
            "  3050K .......... .......... .......... .......... ..........  5%  163M 1s\n",
            "  3100K .......... .......... .......... .......... ..........  5%  138M 1s\n",
            "  3150K .......... .......... .......... .......... ..........  5% 17.4M 1s\n",
            "  3200K .......... .......... .......... .......... ..........  5%  181M 1s\n",
            "  3250K .......... .......... .......... .......... ..........  5%  165M 1s\n",
            "  3300K .......... .......... .......... .......... ..........  5%  202M 1s\n",
            "  3350K .......... .......... .......... .......... ..........  5%  152M 1s\n",
            "  3400K .......... .......... .......... .......... ..........  6%  193M 1s\n",
            "  3450K .......... .......... .......... .......... ..........  6%  200M 1s\n",
            "  3500K .......... .......... .......... .......... ..........  6%  201M 1s\n",
            "  3550K .......... .......... .......... .......... ..........  6%  165M 1s\n",
            "  3600K .......... .......... .......... .......... ..........  6%  198M 1s\n",
            "  3650K .......... .......... .......... .......... ..........  6%  215M 1s\n",
            "  3700K .......... .......... .......... .......... ..........  6%  194M 1s\n",
            "  3750K .......... .......... .......... .......... ..........  6%  159M 1s\n",
            "  3800K .......... .......... .......... .......... ..........  6%  177M 1s\n",
            "  3850K .......... .......... .......... .......... ..........  6%  135M 1s\n",
            "  3900K .......... .......... .......... .......... ..........  6%  190M 1s\n",
            "  3950K .......... .......... .......... .......... ..........  7%  159M 1s\n",
            "  4000K .......... .......... .......... .......... ..........  7%  205M 1s\n",
            "  4050K .......... .......... .......... .......... ..........  7%  195M 1s\n",
            "  4100K .......... .......... .......... .......... ..........  7%  198M 1s\n",
            "  4150K .......... .......... .......... .......... ..........  7%  152M 1s\n",
            "  4200K .......... .......... .......... .......... ..........  7%  165M 1s\n",
            "  4250K .......... .......... .......... .......... ..........  7%  169M 1s\n",
            "  4300K .......... .......... .......... .......... ..........  7%  163M 1s\n",
            "  4350K .......... .......... .......... .......... ..........  7%  160M 1s\n",
            "  4400K .......... .......... .......... .......... ..........  7%  195M 1s\n",
            "  4450K .......... .......... .......... .......... ..........  7%  184M 1s\n",
            "  4500K .......... .......... .......... .......... ..........  7%  196M 1s\n",
            "  4550K .......... .......... .......... .......... ..........  8%  162M 1s\n",
            "  4600K .......... .......... .......... .......... ..........  8%  194M 1s\n",
            "  4650K .......... .......... .......... .......... ..........  8%  175M 1s\n",
            "  4700K .......... .......... .......... .......... ..........  8%  183M 1s\n",
            "  4750K .......... .......... .......... .......... ..........  8%  166M 1s\n",
            "  4800K .......... .......... .......... .......... ..........  8%  182M 1s\n",
            "  4850K .......... .......... .......... .......... ..........  8%  280M 1s\n",
            "  4900K .......... .......... .......... .......... ..........  8%  311M 1s\n",
            "  4950K .......... .......... .......... .......... ..........  8%  278M 1s\n",
            "  5000K .......... .......... .......... .......... ..........  8%  263M 1s\n",
            "  5050K .......... .......... .......... .......... ..........  8%  304M 1s\n",
            "  5100K .......... .......... .......... .......... ..........  9%  258M 1s\n",
            "  5150K .......... .......... .......... .......... ..........  9%  208M 1s\n",
            "  5200K .......... .......... .......... .......... ..........  9%  290M 1s\n",
            "  5250K .......... .......... .......... .......... ..........  9%  251M 1s\n",
            "  5300K .......... .......... .......... .......... ..........  9%  255M 1s\n",
            "  5350K .......... .......... .......... .......... ..........  9%  228M 1s\n",
            "  5400K .......... .......... .......... .......... ..........  9%  289M 1s\n",
            "  5450K .......... .......... .......... .......... ..........  9%  280M 1s\n",
            "  5500K .......... .......... .......... .......... ..........  9%  281M 1s\n",
            "  5550K .......... .......... .......... .......... ..........  9% 53.9M 1s\n",
            "  5600K .......... .......... .......... .......... ..........  9%  251M 1s\n",
            "  5650K .......... .......... .......... .......... ..........  9%  264M 1s\n",
            "  5700K .......... .......... .......... .......... .......... 10%  246M 1s\n",
            "  5750K .......... .......... .......... .......... .......... 10%  219M 1s\n",
            "  5800K .......... .......... .......... .......... .......... 10%  235M 1s\n",
            "  5850K .......... .......... .......... .......... .......... 10%  275M 1s\n",
            "  5900K .......... .......... .......... .......... .......... 10%  275M 1s\n",
            "  5950K .......... .......... .......... .......... .......... 10%  212M 1s\n",
            "  6000K .......... .......... .......... .......... .......... 10%  262M 1s\n",
            "  6050K .......... .......... .......... .......... .......... 10%  262M 1s\n",
            "  6100K .......... .......... .......... .......... .......... 10%  252M 1s\n",
            "  6150K .......... .......... .......... .......... .......... 10%  260M 1s\n",
            "  6200K .......... .......... .......... .......... .......... 10%  275M 1s\n",
            "  6250K .......... .......... .......... .......... .......... 11%  266M 1s\n",
            "  6300K .......... .......... .......... .......... .......... 11%  268M 1s\n",
            "  6350K .......... .......... .......... .......... .......... 11%  231M 1s\n",
            "  6400K .......... .......... .......... .......... .......... 11%  226M 1s\n",
            "  6450K .......... .......... .......... .......... .......... 11%  248M 1s\n",
            "  6500K .......... .......... .......... .......... .......... 11%  277M 1s\n",
            "  6550K .......... .......... .......... .......... .......... 11%  259M 1s\n",
            "  6600K .......... .......... .......... .......... .......... 11%  298M 1s\n",
            "  6650K .......... .......... .......... .......... .......... 11%  300M 1s\n",
            "  6700K .......... .......... .......... .......... .......... 11%  306M 1s\n",
            "  6750K .......... .......... .......... .......... .......... 11%  241M 1s\n",
            "  6800K .......... .......... .......... .......... .......... 11%  295M 1s\n",
            "  6850K .......... .......... .......... .......... .......... 12%  261M 1s\n",
            "  6900K .......... .......... .......... .......... .......... 12%  276M 1s\n",
            "  6950K .......... .......... .......... .......... .......... 12%  234M 1s\n",
            "  7000K .......... .......... .......... .......... .......... 12%  253M 1s\n",
            "  7050K .......... .......... .......... .......... .......... 12%  293M 1s\n",
            "  7100K .......... .......... .......... .......... .......... 12%  224M 1s\n",
            "  7150K .......... .......... .......... .......... .......... 12%  188M 1s\n",
            "  7200K .......... .......... .......... .......... .......... 12%  278M 1s\n",
            "  7250K .......... .......... .......... .......... .......... 12%  229M 1s\n",
            "  7300K .......... .......... .......... .......... .......... 12%  282M 1s\n",
            "  7350K .......... .......... .......... .......... .......... 12%  236M 1s\n",
            "  7400K .......... .......... .......... .......... .......... 13% 36.4M 1s\n",
            "  7450K .......... .......... .......... .......... .......... 13%  255M 1s\n",
            "  7500K .......... .......... .......... .......... .......... 13%  277M 1s\n",
            "  7550K .......... .......... .......... .......... .......... 13%  242M 1s\n",
            "  7600K .......... .......... .......... .......... .......... 13%  264M 1s\n",
            "  7650K .......... .......... .......... .......... .......... 13%  289M 1s\n",
            "  7700K .......... .......... .......... .......... .......... 13%  272M 1s\n",
            "  7750K .......... .......... .......... .......... .......... 13%  243M 1s\n",
            "  7800K .......... .......... .......... .......... .......... 13%  263M 1s\n",
            "  7850K .......... .......... .......... .......... .......... 13%  268M 1s\n",
            "  7900K .......... .......... .......... .......... .......... 13%  300M 1s\n",
            "  7950K .......... .......... .......... .......... .......... 14%  228M 1s\n",
            "  8000K .......... .......... .......... .......... .......... 14%  247M 1s\n",
            "  8050K .......... .......... .......... .......... .......... 14%  266M 1s\n",
            "  8100K .......... .......... .......... .......... .......... 14%  283M 1s\n",
            "  8150K .......... .......... .......... .......... .......... 14%  258M 1s\n",
            "  8200K .......... .......... .......... .......... .......... 14%  292M 1s\n",
            "  8250K .......... .......... .......... .......... .......... 14%  285M 1s\n",
            "  8300K .......... .......... .......... .......... .......... 14%  261M 1s\n",
            "  8350K .......... .......... .......... .......... .......... 14%  232M 1s\n",
            "  8400K .......... .......... .......... .......... .......... 14% 97.3M 1s\n",
            "  8450K .......... .......... .......... .......... .......... 14%  249M 1s\n",
            "  8500K .......... .......... .......... .......... .......... 14%  307M 1s\n",
            "  8550K .......... .......... .......... .......... .......... 15%  265M 1s\n",
            "  8600K .......... .......... .......... .......... .......... 15%  271M 1s\n",
            "  8650K .......... .......... .......... .......... .......... 15%  285M 1s\n",
            "  8700K .......... .......... .......... .......... .......... 15%  312M 1s\n",
            "  8750K .......... .......... .......... .......... .......... 15%  253M 1s\n",
            "  8800K .......... .......... .......... .......... .......... 15%  286M 1s\n",
            "  8850K .......... .......... .......... .......... .......... 15%  297M 1s\n",
            "  8900K .......... .......... .......... .......... .......... 15%  301M 1s\n",
            "  8950K .......... .......... .......... .......... .......... 15%  285M 1s\n",
            "  9000K .......... .......... .......... .......... .......... 15%  305M 1s\n",
            "  9050K .......... .......... .......... .......... .......... 15%  278M 1s\n",
            "  9100K .......... .......... .......... .......... .......... 16%  287M 1s\n",
            "  9150K .......... .......... .......... .......... .......... 16%  227M 1s\n",
            "  9200K .......... .......... .......... .......... .......... 16%  314M 1s\n",
            "  9250K .......... .......... .......... .......... .......... 16%  299M 1s\n",
            "  9300K .......... .......... .......... .......... .......... 16%  329M 1s\n",
            "  9350K .......... .......... .......... .......... .......... 16%  257M 1s\n",
            "  9400K .......... .......... .......... .......... .......... 16%  288M 1s\n",
            "  9450K .......... .......... .......... .......... .......... 16%  297M 1s\n",
            "  9500K .......... .......... .......... .......... .......... 16%  312M 1s\n",
            "  9550K .......... .......... .......... .......... .......... 16%  222M 1s\n",
            "  9600K .......... .......... .......... .......... .......... 16%  297M 1s\n",
            "  9650K .......... .......... .......... .......... .......... 16%  263M 1s\n",
            "  9700K .......... .......... .......... .......... .......... 17%  288M 1s\n",
            "  9750K .......... .......... .......... .......... .......... 17%  271M 1s\n",
            "  9800K .......... .......... .......... .......... .......... 17%  288M 1s\n",
            "  9850K .......... .......... .......... .......... .......... 17%  289M 1s\n",
            "  9900K .......... .......... .......... .......... .......... 17%  261M 1s\n",
            "  9950K .......... .......... .......... .......... .......... 17% 81.4M 1s\n",
            " 10000K .......... .......... .......... .......... .......... 17%  274M 1s\n",
            " 10050K .......... .......... .......... .......... .......... 17%  272M 1s\n",
            " 10100K .......... .......... .......... .......... .......... 17%  277M 1s\n",
            " 10150K .......... .......... .......... .......... .......... 17%  233M 1s\n",
            " 10200K .......... .......... .......... .......... .......... 17%  306M 1s\n",
            " 10250K .......... .......... .......... .......... .......... 18%  271M 1s\n",
            " 10300K .......... .......... .......... .......... .......... 18%  312M 1s\n",
            " 10350K .......... .......... .......... .......... .......... 18% 37.4M 1s\n",
            " 10400K .......... .......... .......... .......... .......... 18%  192M 1s\n",
            " 10450K .......... .......... .......... .......... .......... 18%  251M 1s\n",
            " 10500K .......... .......... .......... .......... .......... 18%  262M 1s\n",
            " 10550K .......... .......... .......... .......... .......... 18%  203M 1s\n",
            " 10600K .......... .......... .......... .......... .......... 18%  261M 1s\n",
            " 10650K .......... .......... .......... .......... .......... 18%  262M 1s\n",
            " 10700K .......... .......... .......... .......... .......... 18%  254M 1s\n",
            " 10750K .......... .......... .......... .......... .......... 18%  187M 1s\n",
            " 10800K .......... .......... .......... .......... .......... 19%  233M 1s\n",
            " 10850K .......... .......... .......... .......... .......... 19%  274M 1s\n",
            " 10900K .......... .......... .......... .......... .......... 19%  248M 1s\n",
            " 10950K .......... .......... .......... .......... .......... 19%  258M 1s\n",
            " 11000K .......... .......... .......... .......... .......... 19%  290M 1s\n",
            " 11050K .......... .......... .......... .......... .......... 19%  259M 1s\n",
            " 11100K .......... .......... .......... .......... .......... 19%  279M 1s\n",
            " 11150K .......... .......... .......... .......... .......... 19%  233M 1s\n",
            " 11200K .......... .......... .......... .......... .......... 19% 88.6M 1s\n",
            " 11250K .......... .......... .......... .......... .......... 19%  268M 1s\n",
            " 11300K .......... .......... .......... .......... .......... 19%  278M 1s\n",
            " 11350K .......... .......... .......... .......... .......... 19%  259M 1s\n",
            " 11400K .......... .......... .......... .......... .......... 20%  302M 1s\n",
            " 11450K .......... .......... .......... .......... .......... 20%  260M 1s\n",
            " 11500K .......... .......... .......... .......... .......... 20%  260M 1s\n",
            " 11550K .......... .......... .......... .......... .......... 20%  226M 0s\n",
            " 11600K .......... .......... .......... .......... .......... 20%  273M 0s\n",
            " 11650K .......... .......... .......... .......... .......... 20%  285M 0s\n",
            " 11700K .......... .......... .......... .......... .......... 20%  306M 0s\n",
            " 11750K .......... .......... .......... .......... .......... 20%  263M 0s\n",
            " 11800K .......... .......... .......... .......... .......... 20%  284M 0s\n",
            " 11850K .......... .......... .......... .......... .......... 20%  300M 0s\n",
            " 11900K .......... .......... .......... .......... .......... 20%  309M 0s\n",
            " 11950K .......... .......... .......... .......... .......... 21%  131M 0s\n",
            " 12000K .......... .......... .......... .......... .......... 21%  271M 0s\n",
            " 12050K .......... .......... .......... .......... .......... 21%  267M 0s\n",
            " 12100K .......... .......... .......... .......... .......... 21%  291M 0s\n",
            " 12150K .......... .......... .......... .......... .......... 21%  237M 0s\n",
            " 12200K .......... .......... .......... .......... .......... 21%  289M 0s\n",
            " 12250K .......... .......... .......... .......... .......... 21%  285M 0s\n",
            " 12300K .......... .......... .......... .......... .......... 21%  251M 0s\n",
            " 12350K .......... .......... .......... .......... .......... 21%  242M 0s\n",
            " 12400K .......... .......... .......... .......... .......... 21%  261M 0s\n",
            " 12450K .......... .......... .......... .......... .......... 21%  277M 0s\n",
            " 12500K .......... .......... .......... .......... .......... 21%  284M 0s\n",
            " 12550K .......... .......... .......... .......... .......... 22%  242M 0s\n",
            " 12600K .......... .......... .......... .......... .......... 22%  288M 0s\n",
            " 12650K .......... .......... .......... .......... .......... 22%  271M 0s\n",
            " 12700K .......... .......... .......... .......... .......... 22%  279M 0s\n",
            " 12750K .......... .......... .......... .......... .......... 22%  246M 0s\n",
            " 12800K .......... .......... .......... .......... .......... 22%  250M 0s\n",
            " 12850K .......... .......... .......... .......... .......... 22%  231M 0s\n",
            " 12900K .......... .......... .......... .......... .......... 22%  267M 0s\n",
            " 12950K .......... .......... .......... .......... .......... 22%  258M 0s\n",
            " 13000K .......... .......... .......... .......... .......... 22%  273M 0s\n",
            " 13050K .......... .......... .......... .......... .......... 22%  271M 0s\n",
            " 13100K .......... .......... .......... .......... .......... 23%  206M 0s\n",
            " 13150K .......... .......... .......... .......... .......... 23%  215M 0s\n",
            " 13200K .......... .......... .......... .......... .......... 23%  282M 0s\n",
            " 13250K .......... .......... .......... .......... .......... 23% 46.7M 0s\n",
            " 13300K .......... .......... .......... .......... .......... 23%  258M 0s\n",
            " 13350K .......... .......... .......... .......... .......... 23%  258M 0s\n",
            " 13400K .......... .......... .......... .......... .......... 23%  227M 0s\n",
            " 13450K .......... .......... .......... .......... .......... 23%  184M 0s\n",
            " 13500K .......... .......... .......... .......... .......... 23%  260M 0s\n",
            " 13550K .......... .......... .......... .......... .......... 23%  177M 0s\n",
            " 13600K .......... .......... .......... .......... .......... 23%  265M 0s\n",
            " 13650K .......... .......... .......... .......... .......... 23%  285M 0s\n",
            " 13700K .......... .......... .......... .......... .......... 24%  287M 0s\n",
            " 13750K .......... .......... .......... .......... .......... 24%  269M 0s\n",
            " 13800K .......... .......... .......... .......... .......... 24%  288M 0s\n",
            " 13850K .......... .......... .......... .......... .......... 24%  266M 0s\n",
            " 13900K .......... .......... .......... .......... .......... 24%  277M 0s\n",
            " 13950K .......... .......... .......... .......... .......... 24%  207M 0s\n",
            " 14000K .......... .......... .......... .......... .......... 24%  282M 0s\n",
            " 14050K .......... .......... .......... .......... .......... 24%  273M 0s\n",
            " 14100K .......... .......... .......... .......... .......... 24%  300M 0s\n",
            " 14150K .......... .......... .......... .......... .......... 24% 96.3M 0s\n",
            " 14200K .......... .......... .......... .......... .......... 24%  239M 0s\n",
            " 14250K .......... .......... .......... .......... .......... 25%  294M 0s\n",
            " 14300K .......... .......... .......... .......... .......... 25%  305M 0s\n",
            " 14350K .......... .......... .......... .......... .......... 25%  247M 0s\n",
            " 14400K .......... .......... .......... .......... .......... 25%  267M 0s\n",
            " 14450K .......... .......... .......... .......... .......... 25%  244M 0s\n",
            " 14500K .......... .......... .......... .......... .......... 25%  268M 0s\n",
            " 14550K .......... .......... .......... .......... .......... 25%  274M 0s\n",
            " 14600K .......... .......... .......... .......... .......... 25% 36.0M 0s\n",
            " 14650K .......... .......... .......... .......... .......... 25%  236M 0s\n",
            " 14700K .......... .......... .......... .......... .......... 25%  265M 0s\n",
            " 14750K .......... .......... .......... .......... .......... 25%  230M 0s\n",
            " 14800K .......... .......... .......... .......... .......... 26%  238M 0s\n",
            " 14850K .......... .......... .......... .......... .......... 26%  271M 0s\n",
            " 14900K .......... .......... .......... .......... .......... 26%  253M 0s\n",
            " 14950K .......... .......... .......... .......... .......... 26%  254M 0s\n",
            " 15000K .......... .......... .......... .......... .......... 26%  291M 0s\n",
            " 15050K .......... .......... .......... .......... .......... 26%  296M 0s\n",
            " 15100K .......... .......... .......... .......... .......... 26%  263M 0s\n",
            " 15150K .......... .......... .......... .......... .......... 26%  225M 0s\n",
            " 15200K .......... .......... .......... .......... .......... 26%  271M 0s\n",
            " 15250K .......... .......... .......... .......... .......... 26%  273M 0s\n",
            " 15300K .......... .......... .......... .......... .......... 26%  277M 0s\n",
            " 15350K .......... .......... .......... .......... .......... 26%  228M 0s\n",
            " 15400K .......... .......... .......... .......... .......... 27%  280M 0s\n",
            " 15450K .......... .......... .......... .......... .......... 27%  262M 0s\n",
            " 15500K .......... .......... .......... .......... .......... 27%  290M 0s\n",
            " 15550K .......... .......... .......... .......... .......... 27%  255M 0s\n",
            " 15600K .......... .......... .......... .......... .......... 27%  259M 0s\n",
            " 15650K .......... .......... .......... .......... .......... 27%  305M 0s\n",
            " 15700K .......... .......... .......... .......... .......... 27%  291M 0s\n",
            " 15750K .......... .......... .......... .......... .......... 27%  237M 0s\n",
            " 15800K .......... .......... .......... .......... .......... 27%  302M 0s\n",
            " 15850K .......... .......... .......... .......... .......... 27%  260M 0s\n",
            " 15900K .......... .......... .......... .......... .......... 27%  223M 0s\n",
            " 15950K .......... .......... .......... .......... .......... 28%  230M 0s\n",
            " 16000K .......... .......... .......... .......... .......... 28%  288M 0s\n",
            " 16050K .......... .......... .......... .......... .......... 28%  278M 0s\n",
            " 16100K .......... .......... .......... .......... .......... 28%  261M 0s\n",
            " 16150K .......... .......... .......... .......... .......... 28%  240M 0s\n",
            " 16200K .......... .......... .......... .......... .......... 28%  260M 0s\n",
            " 16250K .......... .......... .......... .......... .......... 28%  254M 0s\n",
            " 16300K .......... .......... .......... .......... .......... 28%  278M 0s\n",
            " 16350K .......... .......... .......... .......... .......... 28%  215M 0s\n",
            " 16400K .......... .......... .......... .......... .......... 28%  252M 0s\n",
            " 16450K .......... .......... .......... .......... .......... 28%  298M 0s\n",
            " 16500K .......... .......... .......... .......... .......... 28%  286M 0s\n",
            " 16550K .......... .......... .......... .......... .......... 29%  212M 0s\n",
            " 16600K .......... .......... .......... .......... .......... 29%  248M 0s\n",
            " 16650K .......... .......... .......... .......... .......... 29%  273M 0s\n",
            " 16700K .......... .......... .......... .......... .......... 29%  232M 0s\n",
            " 16750K .......... .......... .......... .......... .......... 29%  222M 0s\n",
            " 16800K .......... .......... .......... .......... .......... 29%  283M 0s\n",
            " 16850K .......... .......... .......... .......... .......... 29%  285M 0s\n",
            " 16900K .......... .......... .......... .......... .......... 29%  274M 0s\n",
            " 16950K .......... .......... .......... .......... .......... 29%  226M 0s\n",
            " 17000K .......... .......... .......... .......... .......... 29%  304M 0s\n",
            " 17050K .......... .......... .......... .......... .......... 29%  284M 0s\n",
            " 17100K .......... .......... .......... .......... .......... 30%  333M 0s\n",
            " 17150K .......... .......... .......... .......... .......... 30%  241M 0s\n",
            " 17200K .......... .......... .......... .......... .......... 30%  311M 0s\n",
            " 17250K .......... .......... .......... .......... .......... 30%  254M 0s\n",
            " 17300K .......... .......... .......... .......... .......... 30%  301M 0s\n",
            " 17350K .......... .......... .......... .......... .......... 30%  105M 0s\n",
            " 17400K .......... .......... .......... .......... .......... 30%  283M 0s\n",
            " 17450K .......... .......... .......... .......... .......... 30%  261M 0s\n",
            " 17500K .......... .......... .......... .......... .......... 30%  290M 0s\n",
            " 17550K .......... .......... .......... .......... .......... 30% 35.3M 0s\n",
            " 17600K .......... .......... .......... .......... .......... 30%  261M 0s\n",
            " 17650K .......... .......... .......... .......... .......... 30%  218M 0s\n",
            " 17700K .......... .......... .......... .......... .......... 31%  234M 0s\n",
            " 17750K .......... .......... .......... .......... .......... 31%  257M 0s\n",
            " 17800K .......... .......... .......... .......... .......... 31%  283M 0s\n",
            " 17850K .......... .......... .......... .......... .......... 31%  307M 0s\n",
            " 17900K .......... .......... .......... .......... .......... 31%  282M 0s\n",
            " 17950K .......... .......... .......... .......... .......... 31% 48.0M 0s\n",
            " 18000K .......... .......... .......... .......... .......... 31%  263M 0s\n",
            " 18050K .......... .......... .......... .......... .......... 31%  265M 0s\n",
            " 18100K .......... .......... .......... .......... .......... 31%  274M 0s\n",
            " 18150K .......... .......... .......... .......... .......... 31%  252M 0s\n",
            " 18200K .......... .......... .......... .......... .......... 31%  283M 0s\n",
            " 18250K .......... .......... .......... .......... .......... 32%  249M 0s\n",
            " 18300K .......... .......... .......... .......... .......... 32%  306M 0s\n",
            " 18350K .......... .......... .......... .......... .......... 32%  194M 0s\n",
            " 18400K .......... .......... .......... .......... .......... 32%  277M 0s\n",
            " 18450K .......... .......... .......... .......... .......... 32%  322M 0s\n",
            " 18500K .......... .......... .......... .......... .......... 32%  264M 0s\n",
            " 18550K .......... .......... .......... .......... .......... 32%  228M 0s\n",
            " 18600K .......... .......... .......... .......... .......... 32%  239M 0s\n",
            " 18650K .......... .......... .......... .......... .......... 32%  284M 0s\n",
            " 18700K .......... .......... .......... .......... .......... 32%  302M 0s\n",
            " 18750K .......... .......... .......... .......... .......... 32% 40.6M 0s\n",
            " 18800K .......... .......... .......... .......... .......... 33%  243M 0s\n",
            " 18850K .......... .......... .......... .......... .......... 33%  231M 0s\n",
            " 18900K .......... .......... .......... .......... .......... 33%  240M 0s\n",
            " 18950K .......... .......... .......... .......... .......... 33%  211M 0s\n",
            " 19000K .......... .......... .......... .......... .......... 33%  160M 0s\n",
            " 19050K .......... .......... .......... .......... .......... 33%  204M 0s\n",
            " 19100K .......... .......... .......... .......... .......... 33%  260M 0s\n",
            " 19150K .......... .......... .......... .......... .......... 33%  217M 0s\n",
            " 19200K .......... .......... .......... .......... .......... 33%  232M 0s\n",
            " 19250K .......... .......... .......... .......... .......... 33%  251M 0s\n",
            " 19300K .......... .......... .......... .......... .......... 33%  280M 0s\n",
            " 19350K .......... .......... .......... .......... .......... 33%  256M 0s\n",
            " 19400K .......... .......... .......... .......... .......... 34%  289M 0s\n",
            " 19450K .......... .......... .......... .......... .......... 34%  267M 0s\n",
            " 19500K .......... .......... .......... .......... .......... 34%  250M 0s\n",
            " 19550K .......... .......... .......... .......... .......... 34%  209M 0s\n",
            " 19600K .......... .......... .......... .......... .......... 34%  266M 0s\n",
            " 19650K .......... .......... .......... .......... .......... 34%  285M 0s\n",
            " 19700K .......... .......... .......... .......... .......... 34%  284M 0s\n",
            " 19750K .......... .......... .......... .......... .......... 34%  209M 0s\n",
            " 19800K .......... .......... .......... .......... .......... 34%  270M 0s\n",
            " 19850K .......... .......... .......... .......... .......... 34%  270M 0s\n",
            " 19900K .......... .......... .......... .......... .......... 34%  296M 0s\n",
            " 19950K .......... .......... .......... .......... .......... 35%  240M 0s\n",
            " 20000K .......... .......... .......... .......... .......... 35%  257M 0s\n",
            " 20050K .......... .......... .......... .......... .......... 35%  307M 0s\n",
            " 20100K .......... .......... .......... .......... .......... 35%  265M 0s\n",
            " 20150K .......... .......... .......... .......... .......... 35%  252M 0s\n",
            " 20200K .......... .......... .......... .......... .......... 35%  301M 0s\n",
            " 20250K .......... .......... .......... .......... .......... 35%  283M 0s\n",
            " 20300K .......... .......... .......... .......... .......... 35%  249M 0s\n",
            " 20350K .......... .......... .......... .......... .......... 35%  233M 0s\n",
            " 20400K .......... .......... .......... .......... .......... 35%  281M 0s\n",
            " 20450K .......... .......... .......... .......... .......... 35%  248M 0s\n",
            " 20500K .......... .......... .......... .......... .......... 35%  290M 0s\n",
            " 20550K .......... .......... .......... .......... .......... 36%  220M 0s\n",
            " 20600K .......... .......... .......... .......... .......... 36%  260M 0s\n",
            " 20650K .......... .......... .......... .......... .......... 36%  263M 0s\n",
            " 20700K .......... .......... .......... .......... .......... 36%  260M 0s\n",
            " 20750K .......... .......... .......... .......... .......... 36%  235M 0s\n",
            " 20800K .......... .......... .......... .......... .......... 36%  260M 0s\n",
            " 20850K .......... .......... .......... .......... .......... 36%  259M 0s\n",
            " 20900K .......... .......... .......... .......... .......... 36%  275M 0s\n",
            " 20950K .......... .......... .......... .......... .......... 36%  228M 0s\n",
            " 21000K .......... .......... .......... .......... .......... 36%  284M 0s\n",
            " 21050K .......... .......... .......... .......... .......... 36%  218M 0s\n",
            " 21100K .......... .......... .......... .......... .......... 37%  227M 0s\n",
            " 21150K .......... .......... .......... .......... .......... 37%  211M 0s\n",
            " 21200K .......... .......... .......... .......... .......... 37%  282M 0s\n",
            " 21250K .......... .......... .......... .......... .......... 37%  286M 0s\n",
            " 21300K .......... .......... .......... .......... .......... 37%  277M 0s\n",
            " 21350K .......... .......... .......... .......... .......... 37% 62.3M 0s\n",
            " 21400K .......... .......... .......... .......... .......... 37%  280M 0s\n",
            " 21450K .......... .......... .......... .......... .......... 37%  267M 0s\n",
            " 21500K .......... .......... .......... .......... .......... 37%  290M 0s\n",
            " 21550K .......... .......... .......... .......... .......... 37%  243M 0s\n",
            " 21600K .......... .......... .......... .......... .......... 37%  305M 0s\n",
            " 21650K .......... .......... .......... .......... .......... 38% 72.6M 0s\n",
            " 21700K .......... .......... .......... .......... .......... 38%  288M 0s\n",
            " 21750K .......... .......... .......... .......... .......... 38%  262M 0s\n",
            " 21800K .......... .......... .......... .......... .......... 38%  292M 0s\n",
            " 21850K .......... .......... .......... .......... .......... 38%  260M 0s\n",
            " 21900K .......... .......... .......... .......... .......... 38%  307M 0s\n",
            " 21950K .......... .......... .......... .......... .......... 38%  224M 0s\n",
            " 22000K .......... .......... .......... .......... .......... 38%  304M 0s\n",
            " 22050K .......... .......... .......... .......... .......... 38%  309M 0s\n",
            " 22100K .......... .......... .......... .......... .......... 38% 24.2M 0s\n",
            " 22150K .......... .......... .......... .......... .......... 38%  193M 0s\n",
            " 22200K .......... .......... .......... .......... .......... 38%  258M 0s\n",
            " 22250K .......... .......... .......... .......... .......... 39%  239M 0s\n",
            " 22300K .......... .......... .......... .......... .......... 39%  277M 0s\n",
            " 22350K .......... .......... .......... .......... .......... 39%  210M 0s\n",
            " 22400K .......... .......... .......... .......... .......... 39%  246M 0s\n",
            " 22450K .......... .......... .......... .......... .......... 39%  255M 0s\n",
            " 22500K .......... .......... .......... .......... .......... 39%  273M 0s\n",
            " 22550K .......... .......... .......... .......... .......... 39%  246M 0s\n",
            " 22600K .......... .......... .......... .......... .......... 39%  256M 0s\n",
            " 22650K .......... .......... .......... .......... .......... 39%  205M 0s\n",
            " 22700K .......... .......... .......... .......... .......... 39%  232M 0s\n",
            " 22750K .......... .......... .......... .......... .......... 39%  208M 0s\n",
            " 22800K .......... .......... .......... .......... .......... 40% 28.7M 0s\n",
            " 22850K .......... .......... .......... .......... .......... 40%  207M 0s\n",
            " 22900K .......... .......... .......... .......... .......... 40%  225M 0s\n",
            " 22950K .......... .......... .......... .......... .......... 40%  227M 0s\n",
            " 23000K .......... .......... .......... .......... .......... 40%  231M 0s\n",
            " 23050K .......... .......... .......... .......... .......... 40%  261M 0s\n",
            " 23100K .......... .......... .......... .......... .......... 40%  249M 0s\n",
            " 23150K .......... .......... .......... .......... .......... 40%  220M 0s\n",
            " 23200K .......... .......... .......... .......... .......... 40%  260M 0s\n",
            " 23250K .......... .......... .......... .......... .......... 40%  196M 0s\n",
            " 23300K .......... .......... .......... .......... .......... 40%  248M 0s\n",
            " 23350K .......... .......... .......... .......... .......... 40%  248M 0s\n",
            " 23400K .......... .......... .......... .......... .......... 41%  284M 0s\n",
            " 23450K .......... .......... .......... .......... .......... 41%  252M 0s\n",
            " 23500K .......... .......... .......... .......... .......... 41%  215M 0s\n",
            " 23550K .......... .......... .......... .......... .......... 41%  231M 0s\n",
            " 23600K .......... .......... .......... .......... .......... 41%  279M 0s\n",
            " 23650K .......... .......... .......... .......... .......... 41%  270M 0s\n",
            " 23700K .......... .......... .......... .......... .......... 41%  304M 0s\n",
            " 23750K .......... .......... .......... .......... .......... 41%  272M 0s\n",
            " 23800K .......... .......... .......... .......... .......... 41%  285M 0s\n",
            " 23850K .......... .......... .......... .......... .......... 41% 28.0M 0s\n",
            " 23900K .......... .......... .......... .......... .......... 41%  215M 0s\n",
            " 23950K .......... .......... .......... .......... .......... 42%  176M 0s\n",
            " 24000K .......... .......... .......... .......... .......... 42%  235M 0s\n",
            " 24050K .......... .......... .......... .......... .......... 42%  276M 0s\n",
            " 24100K .......... .......... .......... .......... .......... 42%  255M 0s\n",
            " 24150K .......... .......... .......... .......... .......... 42%  235M 0s\n",
            " 24200K .......... .......... .......... .......... .......... 42%  256M 0s\n",
            " 24250K .......... .......... .......... .......... .......... 42%  203M 0s\n",
            " 24300K .......... .......... .......... .......... .......... 42%  307M 0s\n",
            " 24350K .......... .......... .......... .......... .......... 42%  258M 0s\n",
            " 24400K .......... .......... .......... .......... .......... 42%  264M 0s\n",
            " 24450K .......... .......... .......... .......... .......... 42%  260M 0s\n",
            " 24500K .......... .......... .......... .......... .......... 42%  262M 0s\n",
            " 24550K .......... .......... .......... .......... .......... 43%  228M 0s\n",
            " 24600K .......... .......... .......... .......... .......... 43%  264M 0s\n",
            " 24650K .......... .......... .......... .......... .......... 43%  188M 0s\n",
            " 24700K .......... .......... .......... .......... .......... 43%  265M 0s\n",
            " 24750K .......... .......... .......... .......... .......... 43%  262M 0s\n",
            " 24800K .......... .......... .......... .......... .......... 43%  321M 0s\n",
            " 24850K .......... .......... .......... .......... .......... 43%  324M 0s\n",
            " 24900K .......... .......... .......... .......... .......... 43% 85.8M 0s\n",
            " 24950K .......... .......... .......... .......... .......... 43%  243M 0s\n",
            " 25000K .......... .......... .......... .......... .......... 43%  263M 0s\n",
            " 25050K .......... .......... .......... .......... .......... 43%  208M 0s\n",
            " 25100K .......... .......... .......... .......... .......... 44%  200M 0s\n",
            " 25150K .......... .......... .......... .......... .......... 44%  195M 0s\n",
            " 25200K .......... .......... .......... .......... .......... 44%  271M 0s\n",
            " 25250K .......... .......... .......... .......... .......... 44%  250M 0s\n",
            " 25300K .......... .......... .......... .......... .......... 44%  234M 0s\n",
            " 25350K .......... .......... .......... .......... .......... 44%  217M 0s\n",
            " 25400K .......... .......... .......... .......... .......... 44%  236M 0s\n",
            " 25450K .......... .......... .......... .......... .......... 44%  252M 0s\n",
            " 25500K .......... .......... .......... .......... .......... 44%  250M 0s\n",
            " 25550K .......... .......... .......... .......... .......... 44%  201M 0s\n",
            " 25600K .......... .......... .......... .......... .......... 44%  251M 0s\n",
            " 25650K .......... .......... .......... .......... .......... 45%  260M 0s\n",
            " 25700K .......... .......... .......... .......... .......... 45%  272M 0s\n",
            " 25750K .......... .......... .......... .......... .......... 45%  241M 0s\n",
            " 25800K .......... .......... .......... .......... .......... 45%  247M 0s\n",
            " 25850K .......... .......... .......... .......... .......... 45%  244M 0s\n",
            " 25900K .......... .......... .......... .......... .......... 45%  251M 0s\n",
            " 25950K .......... .......... .......... .......... .......... 45%  234M 0s\n",
            " 26000K .......... .......... .......... .......... .......... 45%  259M 0s\n",
            " 26050K .......... .......... .......... .......... .......... 45%  235M 0s\n",
            " 26100K .......... .......... .......... .......... .......... 45%  268M 0s\n",
            " 26150K .......... .......... .......... .......... .......... 45%  241M 0s\n",
            " 26200K .......... .......... .......... .......... .......... 45%  287M 0s\n",
            " 26250K .......... .......... .......... .......... .......... 46%  287M 0s\n",
            " 26300K .......... .......... .......... .......... .......... 46%  257M 0s\n",
            " 26350K .......... .......... .......... .......... .......... 46%  231M 0s\n",
            " 26400K .......... .......... .......... .......... .......... 46%  274M 0s\n",
            " 26450K .......... .......... .......... .......... .......... 46%  244M 0s\n",
            " 26500K .......... .......... .......... .......... .......... 46%  271M 0s\n",
            " 26550K .......... .......... .......... .......... .......... 46%  221M 0s\n",
            " 26600K .......... .......... .......... .......... .......... 46%  264M 0s\n",
            " 26650K .......... .......... .......... .......... .......... 46% 58.2M 0s\n",
            " 26700K .......... .......... .......... .......... .......... 46%  196M 0s\n",
            " 26750K .......... .......... .......... .......... .......... 46%  212M 0s\n",
            " 26800K .......... .......... .......... .......... .......... 47%  256M 0s\n",
            " 26850K .......... .......... .......... .......... .......... 47%  251M 0s\n",
            " 26900K .......... .......... .......... .......... .......... 47%  241M 0s\n",
            " 26950K .......... .......... .......... .......... .......... 47%  234M 0s\n",
            " 27000K .......... .......... .......... .......... .......... 47%  275M 0s\n",
            " 27050K .......... .......... .......... .......... .......... 47%  283M 0s\n",
            " 27100K .......... .......... .......... .......... .......... 47%  252M 0s\n",
            " 27150K .......... .......... .......... .......... .......... 47%  214M 0s\n",
            " 27200K .......... .......... .......... .......... .......... 47%  281M 0s\n",
            " 27250K .......... .......... .......... .......... .......... 47%  268M 0s\n",
            " 27300K .......... .......... .......... .......... .......... 47%  274M 0s\n",
            " 27350K .......... .......... .......... .......... .......... 47%  224M 0s\n",
            " 27400K .......... .......... .......... .......... .......... 48%  235M 0s\n",
            " 27450K .......... .......... .......... .......... .......... 48%  253M 0s\n",
            " 27500K .......... .......... .......... .......... .......... 48%  266M 0s\n",
            " 27550K .......... .......... .......... .......... .......... 48%  229M 0s\n",
            " 27600K .......... .......... .......... .......... .......... 48%  277M 0s\n",
            " 27650K .......... .......... .......... .......... .......... 48%  262M 0s\n",
            " 27700K .......... .......... .......... .......... .......... 48% 94.9M 0s\n",
            " 27750K .......... .......... .......... .......... .......... 48%  205M 0s\n",
            " 27800K .......... .......... .......... .......... .......... 48%  215M 0s\n",
            " 27850K .......... .......... .......... .......... .......... 48%  206M 0s\n",
            " 27900K .......... .......... .......... .......... .......... 48%  165M 0s\n",
            " 27950K .......... .......... .......... .......... .......... 49%  143M 0s\n",
            " 28000K .......... .......... .......... .......... .......... 49%  165M 0s\n",
            " 28050K .......... .......... .......... .......... .......... 49%  175M 0s\n",
            " 28100K .......... .......... .......... .......... .......... 49%  175M 0s\n",
            " 28150K .......... .......... .......... .......... .......... 49%  147M 0s\n",
            " 28200K .......... .......... .......... .......... .......... 49%  173M 0s\n",
            " 28250K .......... .......... .......... .......... .......... 49%  187M 0s\n",
            " 28300K .......... .......... .......... .......... .......... 49%  194M 0s\n",
            " 28350K .......... .......... .......... .......... .......... 49%  154M 0s\n",
            " 28400K .......... .......... .......... .......... .......... 49%  172M 0s\n",
            " 28450K .......... .......... .......... .......... .......... 49%  172M 0s\n",
            " 28500K .......... .......... .......... .......... .......... 50%  161M 0s\n",
            " 28550K .......... .......... .......... .......... .......... 50%  156M 0s\n",
            " 28600K .......... .......... .......... .......... .......... 50%  175M 0s\n",
            " 28650K .......... .......... .......... .......... .......... 50%  171M 0s\n",
            " 28700K .......... .......... .......... .......... .......... 50%  165M 0s\n",
            " 28750K .......... .......... .......... .......... .......... 50%  160M 0s\n",
            " 28800K .......... .......... .......... .......... .......... 50%  188M 0s\n",
            " 28850K .......... .......... .......... .......... .......... 50%  177M 0s\n",
            " 28900K .......... .......... .......... .......... .......... 50%  184M 0s\n",
            " 28950K .......... .......... .......... .......... .......... 50%  176M 0s\n",
            " 29000K .......... .......... .......... .......... .......... 50%  193M 0s\n",
            " 29050K .......... .......... .......... .......... .......... 50%  184M 0s\n",
            " 29100K .......... .......... .......... .......... .......... 51%  192M 0s\n",
            " 29150K .......... .......... .......... .......... .......... 51%  131M 0s\n",
            " 29200K .......... .......... .......... .......... .......... 51%  168M 0s\n",
            " 29250K .......... .......... .......... .......... .......... 51%  177M 0s\n",
            " 29300K .......... .......... .......... .......... .......... 51%  191M 0s\n",
            " 29350K .......... .......... .......... .......... .......... 51%  180M 0s\n",
            " 29400K .......... .......... .......... .......... .......... 51%  169M 0s\n",
            " 29450K .......... .......... .......... .......... .......... 51%  262M 0s\n",
            " 29500K .......... .......... .......... .......... .......... 51%  281M 0s\n",
            " 29550K .......... .......... .......... .......... .......... 51%  232M 0s\n",
            " 29600K .......... .......... .......... .......... .......... 51%  273M 0s\n",
            " 29650K .......... .......... .......... .......... .......... 52%  223M 0s\n",
            " 29700K .......... .......... .......... .......... .......... 52%  265M 0s\n",
            " 29750K .......... .......... .......... .......... .......... 52%  226M 0s\n",
            " 29800K .......... .......... .......... .......... .......... 52%  238M 0s\n",
            " 29850K .......... .......... .......... .......... .......... 52%  224M 0s\n",
            " 29900K .......... .......... .......... .......... .......... 52%  227M 0s\n",
            " 29950K .......... .......... .......... .......... .......... 52%  195M 0s\n",
            " 30000K .......... .......... .......... .......... .......... 52%  281M 0s\n",
            " 30050K .......... .......... .......... .......... .......... 52%  266M 0s\n",
            " 30100K .......... .......... .......... .......... .......... 52%  271M 0s\n",
            " 30150K .......... .......... .......... .......... .......... 52%  242M 0s\n",
            " 30200K .......... .......... .......... .......... .......... 52%  266M 0s\n",
            " 30250K .......... .......... .......... .......... .......... 53%  250M 0s\n",
            " 30300K .......... .......... .......... .......... .......... 53%  271M 0s\n",
            " 30350K .......... .......... .......... .......... .......... 53%  228M 0s\n",
            " 30400K .......... .......... .......... .......... .......... 53%  257M 0s\n",
            " 30450K .......... .......... .......... .......... .......... 53%  246M 0s\n",
            " 30500K .......... .......... .......... .......... .......... 53%  239M 0s\n",
            " 30550K .......... .......... .......... .......... .......... 53%  275M 0s\n",
            " 30600K .......... .......... .......... .......... .......... 53%  283M 0s\n",
            " 30650K .......... .......... .......... .......... .......... 53%  277M 0s\n",
            " 30700K .......... .......... .......... .......... .......... 53%  308M 0s\n",
            " 30750K .......... .......... .......... .......... .......... 53%  221M 0s\n",
            " 30800K .......... .......... .......... .......... .......... 54%  247M 0s\n",
            " 30850K .......... .......... .......... .......... .......... 54%  245M 0s\n",
            " 30900K .......... .......... .......... .......... .......... 54%  289M 0s\n",
            " 30950K .......... .......... .......... .......... .......... 54%  248M 0s\n",
            " 31000K .......... .......... .......... .......... .......... 54%  282M 0s\n",
            " 31050K .......... .......... .......... .......... .......... 54%  291M 0s\n",
            " 31100K .......... .......... .......... .......... .......... 54%  279M 0s\n",
            " 31150K .......... .......... .......... .......... .......... 54%  217M 0s\n",
            " 31200K .......... .......... .......... .......... .......... 54%  246M 0s\n",
            " 31250K .......... .......... .......... .......... .......... 54%  292M 0s\n",
            " 31300K .......... .......... .......... .......... .......... 54%  259M 0s\n",
            " 31350K .......... .......... .......... .......... .......... 54%  250M 0s\n",
            " 31400K .......... .......... .......... .......... .......... 55%  286M 0s\n",
            " 31450K .......... .......... .......... .......... .......... 55%  247M 0s\n",
            " 31500K .......... .......... .......... .......... .......... 55%  290M 0s\n",
            " 31550K .......... .......... .......... .......... .......... 55%  207M 0s\n",
            " 31600K .......... .......... .......... .......... .......... 55%  314M 0s\n",
            " 31650K .......... .......... .......... .......... .......... 55%  261M 0s\n",
            " 31700K .......... .......... .......... .......... .......... 55%  312M 0s\n",
            " 31750K .......... .......... .......... .......... .......... 55%  260M 0s\n",
            " 31800K .......... .......... .......... .......... .......... 55%  304M 0s\n",
            " 31850K .......... .......... .......... .......... .......... 55%  295M 0s\n",
            " 31900K .......... .......... .......... .......... .......... 55%  295M 0s\n",
            " 31950K .......... .......... .......... .......... .......... 56% 37.5M 0s\n",
            " 32000K .......... .......... .......... .......... .......... 56%  271M 0s\n",
            " 32050K .......... .......... .......... .......... .......... 56%  297M 0s\n",
            " 32100K .......... .......... .......... .......... .......... 56%  284M 0s\n",
            " 32150K .......... .......... .......... .......... .......... 56%  283M 0s\n",
            " 32200K .......... .......... .......... .......... .......... 56%  279M 0s\n",
            " 32250K .......... .......... .......... .......... .......... 56%  312M 0s\n",
            " 32300K .......... .......... .......... .......... .......... 56%  201M 0s\n",
            " 32350K .......... .......... .......... .......... .......... 56%  209M 0s\n",
            " 32400K .......... .......... .......... .......... .......... 56%  288M 0s\n",
            " 32450K .......... .......... .......... .......... .......... 56%  284M 0s\n",
            " 32500K .......... .......... .......... .......... .......... 57% 85.0M 0s\n",
            " 32550K .......... .......... .......... .......... .......... 57%  281M 0s\n",
            " 32600K .......... .......... .......... .......... .......... 57%  236M 0s\n",
            " 32650K .......... .......... .......... .......... .......... 57%  297M 0s\n",
            " 32700K .......... .......... .......... .......... .......... 57%  196M 0s\n",
            " 32750K .......... .......... .......... .......... .......... 57%  211M 0s\n",
            " 32800K .......... .......... .......... .......... .......... 57%  249M 0s\n",
            " 32850K .......... .......... .......... .......... .......... 57%  247M 0s\n",
            " 32900K .......... .......... .......... .......... .......... 57%  254M 0s\n",
            " 32950K .......... .......... .......... .......... .......... 57%  245M 0s\n",
            " 33000K .......... .......... .......... .......... .......... 57%  223M 0s\n",
            " 33050K .......... .......... .......... .......... .......... 57%  312M 0s\n",
            " 33100K .......... .......... .......... .......... .......... 58%  288M 0s\n",
            " 33150K .......... .......... .......... .......... .......... 58%  231M 0s\n",
            " 33200K .......... .......... .......... .......... .......... 58%  228M 0s\n",
            " 33250K .......... .......... .......... .......... .......... 58%  258M 0s\n",
            " 33300K .......... .......... .......... .......... .......... 58%  253M 0s\n",
            " 33350K .......... .......... .......... .......... .......... 58%  263M 0s\n",
            " 33400K .......... .......... .......... .......... .......... 58%  293M 0s\n",
            " 33450K .......... .......... .......... .......... .......... 58%  292M 0s\n",
            " 33500K .......... .......... .......... .......... .......... 58%  275M 0s\n",
            " 33550K .......... .......... .......... .......... .......... 58%  220M 0s\n",
            " 33600K .......... .......... .......... .......... .......... 58%  290M 0s\n",
            " 33650K .......... .......... .......... .......... .......... 59%  288M 0s\n",
            " 33700K .......... .......... .......... .......... .......... 59%  330M 0s\n",
            " 33750K .......... .......... .......... .......... .......... 59%  268M 0s\n",
            " 33800K .......... .......... .......... .......... .......... 59%  251M 0s\n",
            " 33850K .......... .......... .......... .......... .......... 59%  272M 0s\n",
            " 33900K .......... .......... .......... .......... .......... 59%  309M 0s\n",
            " 33950K .......... .......... .......... .......... .......... 59%  251M 0s\n",
            " 34000K .......... .......... .......... .......... .......... 59%  303M 0s\n",
            " 34050K .......... .......... .......... .......... .......... 59%  284M 0s\n",
            " 34100K .......... .......... .......... .......... .......... 59%  240M 0s\n",
            " 34150K .......... .......... .......... .......... .......... 59% 13.8M 0s\n",
            " 34200K .......... .......... .......... .......... .......... 59%  254M 0s\n",
            " 34250K .......... .......... .......... .......... .......... 60%  270M 0s\n",
            " 34300K .......... .......... .......... .......... .......... 60%  215M 0s\n",
            " 34350K .......... .......... .......... .......... .......... 60%  210M 0s\n",
            " 34400K .......... .......... .......... .......... .......... 60%  267M 0s\n",
            " 34450K .......... .......... .......... .......... .......... 60%  226M 0s\n",
            " 34500K .......... .......... .......... .......... .......... 60%  282M 0s\n",
            " 34550K .......... .......... .......... .......... .......... 60%  229M 0s\n",
            " 34600K .......... .......... .......... .......... .......... 60%  291M 0s\n",
            " 34650K .......... .......... .......... .......... .......... 60%  276M 0s\n",
            " 34700K .......... .......... .......... .......... .......... 60%  287M 0s\n",
            " 34750K .......... .......... .......... .......... .......... 60%  229M 0s\n",
            " 34800K .......... .......... .......... .......... .......... 61%  257M 0s\n",
            " 34850K .......... .......... .......... .......... .......... 61%  262M 0s\n",
            " 34900K .......... .......... .......... .......... .......... 61%  263M 0s\n",
            " 34950K .......... .......... .......... .......... .......... 61% 85.8M 0s\n",
            " 35000K .......... .......... .......... .......... .......... 61%  262M 0s\n",
            " 35050K .......... .......... .......... .......... .......... 61%  252M 0s\n",
            " 35100K .......... .......... .......... .......... .......... 61%  267M 0s\n",
            " 35150K .......... .......... .......... .......... .......... 61%  202M 0s\n",
            " 35200K .......... .......... .......... .......... .......... 61%  277M 0s\n",
            " 35250K .......... .......... .......... .......... .......... 61%  267M 0s\n",
            " 35300K .......... .......... .......... .......... .......... 61%  288M 0s\n",
            " 35350K .......... .......... .......... .......... .......... 61%  248M 0s\n",
            " 35400K .......... .......... .......... .......... .......... 62%  281M 0s\n",
            " 35450K .......... .......... .......... .......... .......... 62%  292M 0s\n",
            " 35500K .......... .......... .......... .......... .......... 62%  291M 0s\n",
            " 35550K .......... .......... .......... .......... .......... 62%  250M 0s\n",
            " 35600K .......... .......... .......... .......... .......... 62%  288M 0s\n",
            " 35650K .......... .......... .......... .......... .......... 62%  308M 0s\n",
            " 35700K .......... .......... .......... .......... .......... 62%  274M 0s\n",
            " 35750K .......... .......... .......... .......... .......... 62%  282M 0s\n",
            " 35800K .......... .......... .......... .......... .......... 62%  262M 0s\n",
            " 35850K .......... .......... .......... .......... .......... 62%  245M 0s\n",
            " 35900K .......... .......... .......... .......... .......... 62%  260M 0s\n",
            " 35950K .......... .......... .......... .......... .......... 63%  211M 0s\n",
            " 36000K .......... .......... .......... .......... .......... 63%  307M 0s\n",
            " 36050K .......... .......... .......... .......... .......... 63%  290M 0s\n",
            " 36100K .......... .......... .......... .......... .......... 63%  281M 0s\n",
            " 36150K .......... .......... .......... .......... .......... 63%  273M 0s\n",
            " 36200K .......... .......... .......... .......... .......... 63%  295M 0s\n",
            " 36250K .......... .......... .......... .......... .......... 63%  303M 0s\n",
            " 36300K .......... .......... .......... .......... .......... 63%  327M 0s\n",
            " 36350K .......... .......... .......... .......... .......... 63%  237M 0s\n",
            " 36400K .......... .......... .......... .......... .......... 63%  295M 0s\n",
            " 36450K .......... .......... .......... .......... .......... 63%  316M 0s\n",
            " 36500K .......... .......... .......... .......... .......... 64%  317M 0s\n",
            " 36550K .......... .......... .......... .......... .......... 64%  262M 0s\n",
            " 36600K .......... .......... .......... .......... .......... 64%  310M 0s\n",
            " 36650K .......... .......... .......... .......... .......... 64%  297M 0s\n",
            " 36700K .......... .......... .......... .......... .......... 64%  309M 0s\n",
            " 36750K .......... .......... .......... .......... .......... 64%  256M 0s\n",
            " 36800K .......... .......... .......... .......... .......... 64%  270M 0s\n",
            " 36850K .......... .......... .......... .......... .......... 64%  194M 0s\n",
            " 36900K .......... .......... .......... .......... .......... 64%  246M 0s\n",
            " 36950K .......... .......... .......... .......... .......... 64%  272M 0s\n",
            " 37000K .......... .......... .......... .......... .......... 64%  244M 0s\n",
            " 37050K .......... .......... .......... .......... .......... 64%  183M 0s\n",
            " 37100K .......... .......... .......... .......... .......... 65% 42.4M 0s\n",
            " 37150K .......... .......... .......... .......... .......... 65%  237M 0s\n",
            " 37200K .......... .......... .......... .......... .......... 65%  344M 0s\n",
            " 37250K .......... .......... .......... .......... .......... 65%  248M 0s\n",
            " 37300K .......... .......... .......... .......... .......... 65%  300M 0s\n",
            " 37350K .......... .......... .......... .......... .......... 65%  241M 0s\n",
            " 37400K .......... .......... .......... .......... .......... 65%  329M 0s\n",
            " 37450K .......... .......... .......... .......... .......... 65%  279M 0s\n",
            " 37500K .......... .......... .......... .......... .......... 65%  241M 0s\n",
            " 37550K .......... .......... .......... .......... .......... 65%  206M 0s\n",
            " 37600K .......... .......... .......... .......... .......... 65%  249M 0s\n",
            " 37650K .......... .......... .......... .......... .......... 66%  292M 0s\n",
            " 37700K .......... .......... .......... .......... .......... 66%  283M 0s\n",
            " 37750K .......... .......... .......... .......... .......... 66%  301M 0s\n",
            " 37800K .......... .......... .......... .......... .......... 66%  247M 0s\n",
            " 37850K .......... .......... .......... .......... .......... 66%  311M 0s\n",
            " 37900K .......... .......... .......... .......... .......... 66%  241M 0s\n",
            " 37950K .......... .......... .......... .......... .......... 66%  215M 0s\n",
            " 38000K .......... .......... .......... .......... .......... 66%  214M 0s\n",
            " 38050K .......... .......... .......... .......... .......... 66%  246M 0s\n",
            " 38100K .......... .......... .......... .......... .......... 66%  205M 0s\n",
            " 38150K .......... .......... .......... .......... .......... 66%  167M 0s\n",
            " 38200K .......... .......... .......... .......... .......... 66%  206M 0s\n",
            " 38250K .......... .......... .......... .......... .......... 67%  217M 0s\n",
            " 38300K .......... .......... .......... .......... .......... 67%  209M 0s\n",
            " 38350K .......... .......... .......... .......... .......... 67%  180M 0s\n",
            " 38400K .......... .......... .......... .......... .......... 67%  178M 0s\n",
            " 38450K .......... .......... .......... .......... .......... 67%  196M 0s\n",
            " 38500K .......... .......... .......... .......... .......... 67%  190M 0s\n",
            " 38550K .......... .......... .......... .......... .......... 67%  171M 0s\n",
            " 38600K .......... .......... .......... .......... .......... 67%  207M 0s\n",
            " 38650K .......... .......... .......... .......... .......... 67%  220M 0s\n",
            " 38700K .......... .......... .......... .......... .......... 67%  193M 0s\n",
            " 38750K .......... .......... .......... .......... .......... 67%  162M 0s\n",
            " 38800K .......... .......... .......... .......... .......... 68%  195M 0s\n",
            " 38850K .......... .......... .......... .......... .......... 68%  210M 0s\n",
            " 38900K .......... .......... .......... .......... .......... 68%  208M 0s\n",
            " 38950K .......... .......... .......... .......... .......... 68%  294M 0s\n",
            " 39000K .......... .......... .......... .......... .......... 68%  262M 0s\n",
            " 39050K .......... .......... .......... .......... .......... 68%  261M 0s\n",
            " 39100K .......... .......... .......... .......... .......... 68%  234M 0s\n",
            " 39150K .......... .......... .......... .......... .......... 68%  198M 0s\n",
            " 39200K .......... .......... .......... .......... .......... 68%  274M 0s\n",
            " 39250K .......... .......... .......... .......... .......... 68%  301M 0s\n",
            " 39300K .......... .......... .......... .......... .......... 68%  312M 0s\n",
            " 39350K .......... .......... .......... .......... .......... 69%  278M 0s\n",
            " 39400K .......... .......... .......... .......... .......... 69%  312M 0s\n",
            " 39450K .......... .......... .......... .......... .......... 69%  261M 0s\n",
            " 39500K .......... .......... .......... .......... .......... 69%  243M 0s\n",
            " 39550K .......... .......... .......... .......... .......... 69%  245M 0s\n",
            " 39600K .......... .......... .......... .......... .......... 69%  307M 0s\n",
            " 39650K .......... .......... .......... .......... .......... 69%  311M 0s\n",
            " 39700K .......... .......... .......... .......... .......... 69%  264M 0s\n",
            " 39750K .......... .......... .......... .......... .......... 69% 30.7M 0s\n",
            " 39800K .......... .......... .......... .......... .......... 69%  244M 0s\n",
            " 39850K .......... .......... .......... .......... .......... 69%  270M 0s\n",
            " 39900K .......... .......... .......... .......... .......... 69%  250M 0s\n",
            " 39950K .......... .......... .......... .......... .......... 70%  219M 0s\n",
            " 40000K .......... .......... .......... .......... .......... 70%  301M 0s\n",
            " 40050K .......... .......... .......... .......... .......... 70%  309M 0s\n",
            " 40100K .......... .......... .......... .......... .......... 70%  279M 0s\n",
            " 40150K .......... .......... .......... .......... .......... 70%  229M 0s\n",
            " 40200K .......... .......... .......... .......... .......... 70%  300M 0s\n",
            " 40250K .......... .......... .......... .......... .......... 70%  294M 0s\n",
            " 40300K .......... .......... .......... .......... .......... 70%  290M 0s\n",
            " 40350K .......... .......... .......... .......... .......... 70%  254M 0s\n",
            " 40400K .......... .......... .......... .......... .......... 70%  305M 0s\n",
            " 40450K .......... .......... .......... .......... .......... 70%  260M 0s\n",
            " 40500K .......... .......... .......... .......... .......... 71%  218M 0s\n",
            " 40550K .......... .......... .......... .......... .......... 71%  271M 0s\n",
            " 40600K .......... .......... .......... .......... .......... 71%  311M 0s\n",
            " 40650K .......... .......... .......... .......... .......... 71%  280M 0s\n",
            " 40700K .......... .......... .......... .......... .......... 71%  279M 0s\n",
            " 40750K .......... .......... .......... .......... .......... 71%  257M 0s\n",
            " 40800K .......... .......... .......... .......... .......... 71%  317M 0s\n",
            " 40850K .......... .......... .......... .......... .......... 71%  241M 0s\n",
            " 40900K .......... .......... .......... .......... .......... 71%  206M 0s\n",
            " 40950K .......... .......... .......... .......... .......... 71%  245M 0s\n",
            " 41000K .......... .......... .......... .......... .......... 71%  277M 0s\n",
            " 41050K .......... .......... .......... .......... .......... 71%  287M 0s\n",
            " 41100K .......... .......... .......... .......... .......... 72%  274M 0s\n",
            " 41150K .......... .......... .......... .......... .......... 72%  262M 0s\n",
            " 41200K .......... .......... .......... .......... .......... 72%  311M 0s\n",
            " 41250K .......... .......... .......... .......... .......... 72%  273M 0s\n",
            " 41300K .......... .......... .......... .......... .......... 72%  259M 0s\n",
            " 41350K .......... .......... .......... .......... .......... 72%  242M 0s\n",
            " 41400K .......... .......... .......... .......... .......... 72%  262M 0s\n",
            " 41450K .......... .......... .......... .......... .......... 72%  256M 0s\n",
            " 41500K .......... .......... .......... .......... .......... 72%  243M 0s\n",
            " 41550K .......... .......... .......... .......... .......... 72%  213M 0s\n",
            " 41600K .......... .......... .......... .......... .......... 72%  233M 0s\n",
            " 41650K .......... .......... .......... .......... .......... 73%  308M 0s\n",
            " 41700K .......... .......... .......... .......... .......... 73%  259M 0s\n",
            " 41750K .......... .......... .......... .......... .......... 73%  253M 0s\n",
            " 41800K .......... .......... .......... .......... .......... 73%  233M 0s\n",
            " 41850K .......... .......... .......... .......... .......... 73%  285M 0s\n",
            " 41900K .......... .......... .......... .......... .......... 73%  307M 0s\n",
            " 41950K .......... .......... .......... .......... .......... 73%  253M 0s\n",
            " 42000K .......... .......... .......... .......... .......... 73%  292M 0s\n",
            " 42050K .......... .......... .......... .......... .......... 73%  243M 0s\n",
            " 42100K .......... .......... .......... .......... .......... 73%  279M 0s\n",
            " 42150K .......... .......... .......... .......... .......... 73%  237M 0s\n",
            " 42200K .......... .......... .......... .......... .......... 73%  289M 0s\n",
            " 42250K .......... .......... .......... .......... .......... 74%  299M 0s\n",
            " 42300K .......... .......... .......... .......... .......... 74%  304M 0s\n",
            " 42350K .......... .......... .......... .......... .......... 74%  213M 0s\n",
            " 42400K .......... .......... .......... .......... .......... 74% 18.1M 0s\n",
            " 42450K .......... .......... .......... .......... .......... 74%  210M 0s\n",
            " 42500K .......... .......... .......... .......... .......... 74%  269M 0s\n",
            " 42550K .......... .......... .......... .......... .......... 74%  259M 0s\n",
            " 42600K .......... .......... .......... .......... .......... 74%  298M 0s\n",
            " 42650K .......... .......... .......... .......... .......... 74%  330M 0s\n",
            " 42700K .......... .......... .......... .......... .......... 74%  282M 0s\n",
            " 42750K .......... .......... .......... .......... .......... 74%  201M 0s\n",
            " 42800K .......... .......... .......... .......... .......... 75%  230M 0s\n",
            " 42850K .......... .......... .......... .......... .......... 75%  293M 0s\n",
            " 42900K .......... .......... .......... .......... .......... 75%  289M 0s\n",
            " 42950K .......... .......... .......... .......... .......... 75%  235M 0s\n",
            " 43000K .......... .......... .......... .......... .......... 75%  253M 0s\n",
            " 43050K .......... .......... .......... .......... .......... 75%  150M 0s\n",
            " 43100K .......... .......... .......... .......... .......... 75%  243M 0s\n",
            " 43150K .......... .......... .......... .......... .......... 75%  166M 0s\n",
            " 43200K .......... .......... .......... .......... .......... 75%  228M 0s\n",
            " 43250K .......... .......... .......... .......... .......... 75%  253M 0s\n",
            " 43300K .......... .......... .......... .......... .......... 75%  272M 0s\n",
            " 43350K .......... .......... .......... .......... .......... 76%  239M 0s\n",
            " 43400K .......... .......... .......... .......... .......... 76%  278M 0s\n",
            " 43450K .......... .......... .......... .......... .......... 76%  279M 0s\n",
            " 43500K .......... .......... .......... .......... .......... 76%  284M 0s\n",
            " 43550K .......... .......... .......... .......... .......... 76%  232M 0s\n",
            " 43600K .......... .......... .......... .......... .......... 76%  287M 0s\n",
            " 43650K .......... .......... .......... .......... .......... 76%  311M 0s\n",
            " 43700K .......... .......... .......... .......... .......... 76%  293M 0s\n",
            " 43750K .......... .......... .......... .......... .......... 76%  258M 0s\n",
            " 43800K .......... .......... .......... .......... .......... 76%  304M 0s\n",
            " 43850K .......... .......... .......... .......... .......... 76%  306M 0s\n",
            " 43900K .......... .......... .......... .......... .......... 76%  318M 0s\n",
            " 43950K .......... .......... .......... .......... .......... 77%  245M 0s\n",
            " 44000K .......... .......... .......... .......... .......... 77%  255M 0s\n",
            " 44050K .......... .......... .......... .......... .......... 77%  239M 0s\n",
            " 44100K .......... .......... .......... .......... .......... 77%  260M 0s\n",
            " 44150K .......... .......... .......... .......... .......... 77%  261M 0s\n",
            " 44200K .......... .......... .......... .......... .......... 77%  277M 0s\n",
            " 44250K .......... .......... .......... .......... .......... 77%  234M 0s\n",
            " 44300K .......... .......... .......... .......... .......... 77%  240M 0s\n",
            " 44350K .......... .......... .......... .......... .......... 77%  245M 0s\n",
            " 44400K .......... .......... .......... .......... .......... 77%  297M 0s\n",
            " 44450K .......... .......... .......... .......... .......... 77%  325M 0s\n",
            " 44500K .......... .......... .......... .......... .......... 78%  281M 0s\n",
            " 44550K .......... .......... .......... .......... .......... 78%  254M 0s\n",
            " 44600K .......... .......... .......... .......... .......... 78%  328M 0s\n",
            " 44650K .......... .......... .......... .......... .......... 78% 31.9M 0s\n",
            " 44700K .......... .......... .......... .......... .......... 78%  230M 0s\n",
            " 44750K .......... .......... .......... .......... .......... 78%  207M 0s\n",
            " 44800K .......... .......... .......... .......... .......... 78%  270M 0s\n",
            " 44850K .......... .......... .......... .......... .......... 78%  268M 0s\n",
            " 44900K .......... .......... .......... .......... .......... 78%  278M 0s\n",
            " 44950K .......... .......... .......... .......... .......... 78%  194M 0s\n",
            " 45000K .......... .......... .......... .......... .......... 78%  281M 0s\n",
            " 45050K .......... .......... .......... .......... .......... 78%  246M 0s\n",
            " 45100K .......... .......... .......... .......... .......... 79%  291M 0s\n",
            " 45150K .......... .......... .......... .......... .......... 79%  237M 0s\n",
            " 45200K .......... .......... .......... .......... .......... 79%  270M 0s\n",
            " 45250K .......... .......... .......... .......... .......... 79%  269M 0s\n",
            " 45300K .......... .......... .......... .......... .......... 79%  235M 0s\n",
            " 45350K .......... .......... .......... .......... .......... 79%  262M 0s\n",
            " 45400K .......... .......... .......... .......... .......... 79%  198M 0s\n",
            " 45450K .......... .......... .......... .......... .......... 79%  154M 0s\n",
            " 45500K .......... .......... .......... .......... .......... 79%  181M 0s\n",
            " 45550K .......... .......... .......... .......... .......... 79%  164M 0s\n",
            " 45600K .......... .......... .......... .......... .......... 79%  186M 0s\n",
            " 45650K .......... .......... .......... .......... .......... 80%  169M 0s\n",
            " 45700K .......... .......... .......... .......... .......... 80%  182M 0s\n",
            " 45750K .......... .......... .......... .......... .......... 80%  194M 0s\n",
            " 45800K .......... .......... .......... .......... .......... 80%  168M 0s\n",
            " 45850K .......... .......... .......... .......... .......... 80%  231M 0s\n",
            " 45900K .......... .......... .......... .......... .......... 80%  207M 0s\n",
            " 45950K .......... .......... .......... .......... .......... 80%  151M 0s\n",
            " 46000K .......... .......... .......... .......... .......... 80%  306M 0s\n",
            " 46050K .......... .......... .......... .......... .......... 80%  195M 0s\n",
            " 46100K .......... .......... .......... .......... .......... 80%  159M 0s\n",
            " 46150K .......... .......... .......... .......... .......... 80%  180M 0s\n",
            " 46200K .......... .......... .......... .......... .......... 81%  241M 0s\n",
            " 46250K .......... .......... .......... .......... .......... 81%  280M 0s\n",
            " 46300K .......... .......... .......... .......... .......... 81%  247M 0s\n",
            " 46350K .......... .......... .......... .......... .......... 81%  233M 0s\n",
            " 46400K .......... .......... .......... .......... .......... 81%  289M 0s\n",
            " 46450K .......... .......... .......... .......... .......... 81%  295M 0s\n",
            " 46500K .......... .......... .......... .......... .......... 81%  220M 0s\n",
            " 46550K .......... .......... .......... .......... .......... 81%  242M 0s\n",
            " 46600K .......... .......... .......... .......... .......... 81%  276M 0s\n",
            " 46650K .......... .......... .......... .......... .......... 81%  282M 0s\n",
            " 46700K .......... .......... .......... .......... .......... 81%  280M 0s\n",
            " 46750K .......... .......... .......... .......... .......... 81%  200M 0s\n",
            " 46800K .......... .......... .......... .......... .......... 82%  269M 0s\n",
            " 46850K .......... .......... .......... .......... .......... 82%  288M 0s\n",
            " 46900K .......... .......... .......... .......... .......... 82%  290M 0s\n",
            " 46950K .......... .......... .......... .......... .......... 82%  262M 0s\n",
            " 47000K .......... .......... .......... .......... .......... 82%  260M 0s\n",
            " 47050K .......... .......... .......... .......... .......... 82%  265M 0s\n",
            " 47100K .......... .......... .......... .......... .......... 82%  302M 0s\n",
            " 47150K .......... .......... .......... .......... .......... 82%  221M 0s\n",
            " 47200K .......... .......... .......... .......... .......... 82%  292M 0s\n",
            " 47250K .......... .......... .......... .......... .......... 82%  275M 0s\n",
            " 47300K .......... .......... .......... .......... .......... 82%  249M 0s\n",
            " 47350K .......... .......... .......... .......... .......... 83% 49.1M 0s\n",
            " 47400K .......... .......... .......... .......... .......... 83%  219M 0s\n",
            " 47450K .......... .......... .......... .......... .......... 83%  253M 0s\n",
            " 47500K .......... .......... .......... .......... .......... 83%  297M 0s\n",
            " 47550K .......... .......... .......... .......... .......... 83%  200M 0s\n",
            " 47600K .......... .......... .......... .......... .......... 83%  239M 0s\n",
            " 47650K .......... .......... .......... .......... .......... 83%  258M 0s\n",
            " 47700K .......... .......... .......... .......... .......... 83%  267M 0s\n",
            " 47750K .......... .......... .......... .......... .......... 83%  274M 0s\n",
            " 47800K .......... .......... .......... .......... .......... 83%  230M 0s\n",
            " 47850K .......... .......... .......... .......... .......... 83% 32.0M 0s\n",
            " 47900K .......... .......... .......... .......... .......... 83%  212M 0s\n",
            " 47950K .......... .......... .......... .......... .......... 84%  179M 0s\n",
            " 48000K .......... .......... .......... .......... .......... 84%  180M 0s\n",
            " 48050K .......... .......... .......... .......... .......... 84%  215M 0s\n",
            " 48100K .......... .......... .......... .......... .......... 84%  212M 0s\n",
            " 48150K .......... .......... .......... .......... .......... 84%  186M 0s\n",
            " 48200K .......... .......... .......... .......... .......... 84%  173M 0s\n",
            " 48250K .......... .......... .......... .......... .......... 84%  205M 0s\n",
            " 48300K .......... .......... .......... .......... .......... 84%  205M 0s\n",
            " 48350K .......... .......... .......... .......... .......... 84%  136M 0s\n",
            " 48400K .......... .......... .......... .......... .......... 84%  183M 0s\n",
            " 48450K .......... .......... .......... .......... .......... 84%  214M 0s\n",
            " 48500K .......... .......... .......... .......... .......... 85%  221M 0s\n",
            " 48550K .......... .......... .......... .......... .......... 85%  163M 0s\n",
            " 48600K .......... .......... .......... .......... .......... 85%  241M 0s\n",
            " 48650K .......... .......... .......... .......... .......... 85%  226M 0s\n",
            " 48700K .......... .......... .......... .......... .......... 85%  257M 0s\n",
            " 48750K .......... .......... .......... .......... .......... 85%  219M 0s\n",
            " 48800K .......... .......... .......... .......... .......... 85%  191M 0s\n",
            " 48850K .......... .......... .......... .......... .......... 85%  226M 0s\n",
            " 48900K .......... .......... .......... .......... .......... 85%  257M 0s\n",
            " 48950K .......... .......... .......... .......... .......... 85%  229M 0s\n",
            " 49000K .......... .......... .......... .......... .......... 85%  226M 0s\n",
            " 49050K .......... .......... .......... .......... .......... 85%  214M 0s\n",
            " 49100K .......... .......... .......... .......... .......... 86%  226M 0s\n",
            " 49150K .......... .......... .......... .......... .......... 86%  195M 0s\n",
            " 49200K .......... .......... .......... .......... .......... 86%  258M 0s\n",
            " 49250K .......... .......... .......... .......... .......... 86%  220M 0s\n",
            " 49300K .......... .......... .......... .......... .......... 86%  227M 0s\n",
            " 49350K .......... .......... .......... .......... .......... 86%  212M 0s\n",
            " 49400K .......... .......... .......... .......... .......... 86%  261M 0s\n",
            " 49450K .......... .......... .......... .......... .......... 86%  222M 0s\n",
            " 49500K .......... .......... .......... .......... .......... 86%  228M 0s\n",
            " 49550K .......... .......... .......... .......... .......... 86%  194M 0s\n",
            " 49600K .......... .......... .......... .......... .......... 86%  246M 0s\n",
            " 49650K .......... .......... .......... .......... .......... 87%  243M 0s\n",
            " 49700K .......... .......... .......... .......... .......... 87%  228M 0s\n",
            " 49750K .......... .......... .......... .......... .......... 87%  203M 0s\n",
            " 49800K .......... .......... .......... .......... .......... 87%  249M 0s\n",
            " 49850K .......... .......... .......... .......... .......... 87%  165M 0s\n",
            " 49900K .......... .......... .......... .......... .......... 87%  212M 0s\n",
            " 49950K .......... .......... .......... .......... .......... 87%  168M 0s\n",
            " 50000K .......... .......... .......... .......... .......... 87%  204M 0s\n",
            " 50050K .......... .......... .......... .......... .......... 87%  238M 0s\n",
            " 50100K .......... .......... .......... .......... .......... 87%  245M 0s\n",
            " 50150K .......... .......... .......... .......... .......... 87%  166M 0s\n",
            " 50200K .......... .......... .......... .......... .......... 88%  222M 0s\n",
            " 50250K .......... .......... .......... .......... .......... 88%  230M 0s\n",
            " 50300K .......... .......... .......... .......... .......... 88%  241M 0s\n",
            " 50350K .......... .......... .......... .......... .......... 88%  142M 0s\n",
            " 50400K .......... .......... .......... .......... .......... 88%  129M 0s\n",
            " 50450K .......... .......... .......... .......... .......... 88%  144M 0s\n",
            " 50500K .......... .......... .......... .......... .......... 88%  132M 0s\n",
            " 50550K .......... .......... .......... .......... .......... 88%  129M 0s\n",
            " 50600K .......... .......... .......... .......... .......... 88%  120M 0s\n",
            " 50650K .......... .......... .......... .......... .......... 88%  152M 0s\n",
            " 50700K .......... .......... .......... .......... .......... 88%  150M 0s\n",
            " 50750K .......... .......... .......... .......... .......... 88%  123M 0s\n",
            " 50800K .......... .......... .......... .......... .......... 89%  218M 0s\n",
            " 50850K .......... .......... .......... .......... .......... 89%  213M 0s\n",
            " 50900K .......... .......... .......... .......... .......... 89%  213M 0s\n",
            " 50950K .......... .......... .......... .......... .......... 89%  166M 0s\n",
            " 51000K .......... .......... .......... .......... .......... 89%  225M 0s\n",
            " 51050K .......... .......... .......... .......... .......... 89%  223M 0s\n",
            " 51100K .......... .......... .......... .......... .......... 89%  200M 0s\n",
            " 51150K .......... .......... .......... .......... .......... 89%  133M 0s\n",
            " 51200K .......... .......... .......... .......... .......... 89%  139M 0s\n",
            " 51250K .......... .......... .......... .......... .......... 89%  146M 0s\n",
            " 51300K .......... .......... .......... .......... .......... 89%  155M 0s\n",
            " 51350K .......... .......... .......... .......... .......... 90%  218M 0s\n",
            " 51400K .......... .......... .......... .......... .......... 90%  303M 0s\n",
            " 51450K .......... .......... .......... .......... .......... 90%  226M 0s\n",
            " 51500K .......... .......... .......... .......... .......... 90%  180M 0s\n",
            " 51550K .......... .......... .......... .......... .......... 90%  137M 0s\n",
            " 51600K .......... .......... .......... .......... .......... 90%  172M 0s\n",
            " 51650K .......... .......... .......... .......... .......... 90%  129M 0s\n",
            " 51700K .......... .......... .......... .......... .......... 90%  166M 0s\n",
            " 51750K .......... .......... .......... .......... .......... 90%  216M 0s\n",
            " 51800K .......... .......... .......... .......... .......... 90%  254M 0s\n",
            " 51850K .......... .......... .......... .......... .......... 90%  281M 0s\n",
            " 51900K .......... .......... .......... .......... .......... 90%  169M 0s\n",
            " 51950K .......... .......... .......... .......... .......... 91%  145M 0s\n",
            " 52000K .......... .......... .......... .......... .......... 91%  173M 0s\n",
            " 52050K .......... .......... .......... .......... .......... 91%  133M 0s\n",
            " 52100K .......... .......... .......... .......... .......... 91%  166M 0s\n",
            " 52150K .......... .......... .......... .......... .......... 91%  162M 0s\n",
            " 52200K .......... .......... .......... .......... .......... 91%  179M 0s\n",
            " 52250K .......... .......... .......... .......... .......... 91%  172M 0s\n",
            " 52300K .......... .......... .......... .......... .......... 91%  176M 0s\n",
            " 52350K .......... .......... .......... .......... .......... 91%  136M 0s\n",
            " 52400K .......... .......... .......... .......... .......... 91%  160M 0s\n",
            " 52450K .......... .......... .......... .......... .......... 91%  162M 0s\n",
            " 52500K .......... .......... .......... .......... .......... 92%  169M 0s\n",
            " 52550K .......... .......... .......... .......... .......... 92%  144M 0s\n",
            " 52600K .......... .......... .......... .......... .......... 92%  202M 0s\n",
            " 52650K .......... .......... .......... .......... .......... 92%  196M 0s\n",
            " 52700K .......... .......... .......... .......... .......... 92%  180M 0s\n",
            " 52750K .......... .......... .......... .......... .......... 92%  167M 0s\n",
            " 52800K .......... .......... .......... .......... .......... 92%  279M 0s\n",
            " 52850K .......... .......... .......... .......... .......... 92%  242M 0s\n",
            " 52900K .......... .......... .......... .......... .......... 92%  245M 0s\n",
            " 52950K .......... .......... .......... .......... .......... 92%  174M 0s\n",
            " 53000K .......... .......... .......... .......... .......... 92%  204M 0s\n",
            " 53050K .......... .......... .......... .......... .......... 92%  277M 0s\n",
            " 53100K .......... .......... .......... .......... .......... 93%  200M 0s\n",
            " 53150K .......... .......... .......... .......... .......... 93% 26.1M 0s\n",
            " 53200K .......... .......... .......... .......... .......... 93%  177M 0s\n",
            " 53250K .......... .......... .......... .......... .......... 93%  167M 0s\n",
            " 53300K .......... .......... .......... .......... .......... 93%  169M 0s\n",
            " 53350K .......... .......... .......... .......... .......... 93%  194M 0s\n",
            " 53400K .......... .......... .......... .......... .......... 93%  196M 0s\n",
            " 53450K .......... .......... .......... .......... .......... 93%  206M 0s\n",
            " 53500K .......... .......... .......... .......... .......... 93%  203M 0s\n",
            " 53550K .......... .......... .......... .......... .......... 93%  155M 0s\n",
            " 53600K .......... .......... .......... .......... .......... 93%  177M 0s\n",
            " 53650K .......... .......... .......... .......... .......... 94%  157M 0s\n",
            " 53700K .......... .......... .......... .......... .......... 94%  223M 0s\n",
            " 53750K .......... .......... .......... .......... .......... 94%  191M 0s\n",
            " 53800K .......... .......... .......... .......... .......... 94%  204M 0s\n",
            " 53850K .......... .......... .......... .......... .......... 94%  170M 0s\n",
            " 53900K .......... .......... .......... .......... .......... 94%  203M 0s\n",
            " 53950K .......... .......... .......... .......... .......... 94%  198M 0s\n",
            " 54000K .......... .......... .......... .......... .......... 94%  147M 0s\n",
            " 54050K .......... .......... .......... .......... .......... 94%  139M 0s\n",
            " 54100K .......... .......... .......... .......... .......... 94%  132M 0s\n",
            " 54150K .......... .......... .......... .......... .......... 94%  107M 0s\n",
            " 54200K .......... .......... .......... .......... .......... 95%  150M 0s\n",
            " 54250K .......... .......... .......... .......... .......... 95%  144M 0s\n",
            " 54300K .......... .......... .......... .......... .......... 95%  149M 0s\n",
            " 54350K .......... .......... .......... .......... .......... 95%  201M 0s\n",
            " 54400K .......... .......... .......... .......... .......... 95%  233M 0s\n",
            " 54450K .......... .......... .......... .......... .......... 95%  207M 0s\n",
            " 54500K .......... .......... .......... .......... .......... 95%  182M 0s\n",
            " 54550K .......... .......... .......... .......... .......... 95%  215M 0s\n",
            " 54600K .......... .......... .......... .......... .......... 95%  242M 0s\n",
            " 54650K .......... .......... .......... .......... .......... 95%  235M 0s\n",
            " 54700K .......... .......... .......... .......... .......... 95%  138M 0s\n",
            " 54750K .......... .......... .......... .......... .......... 95%  121M 0s\n",
            " 54800K .......... .......... .......... .......... .......... 96%  138M 0s\n",
            " 54850K .......... .......... .......... .......... .......... 96%  169M 0s\n",
            " 54900K .......... .......... .......... .......... .......... 96%  205M 0s\n",
            " 54950K .......... .......... .......... .......... .......... 96%  191M 0s\n",
            " 55000K .......... .......... .......... .......... .......... 96%  193M 0s\n",
            " 55050K .......... .......... .......... .......... .......... 96%  205M 0s\n",
            " 55100K .......... .......... .......... .......... .......... 96%  221M 0s\n",
            " 55150K .......... .......... .......... .......... .......... 96%  214M 0s\n",
            " 55200K .......... .......... .......... .......... .......... 96%  249M 0s\n",
            " 55250K .......... .......... .......... .......... .......... 96%  255M 0s\n",
            " 55300K .......... .......... .......... .......... .......... 96%  253M 0s\n",
            " 55350K .......... .......... .......... .......... .......... 97%  197M 0s\n",
            " 55400K .......... .......... .......... .......... .......... 97%  263M 0s\n",
            " 55450K .......... .......... .......... .......... .......... 97%  236M 0s\n",
            " 55500K .......... .......... .......... .......... .......... 97%  211M 0s\n",
            " 55550K .......... .......... .......... .......... .......... 97%  192M 0s\n",
            " 55600K .......... .......... .......... .......... .......... 97%  250M 0s\n",
            " 55650K .......... .......... .......... .......... .......... 97%  222M 0s\n",
            " 55700K .......... .......... .......... .......... .......... 97%  203M 0s\n",
            " 55750K .......... .......... .......... .......... .......... 97%  222M 0s\n",
            " 55800K .......... .......... .......... .......... .......... 97%  222M 0s\n",
            " 55850K .......... .......... .......... .......... .......... 97%  203M 0s\n",
            " 55900K .......... .......... .......... .......... .......... 97%  163M 0s\n",
            " 55950K .......... .......... .......... .......... .......... 98%  119M 0s\n",
            " 56000K .......... .......... .......... .......... .......... 98%  158M 0s\n",
            " 56050K .......... .......... .......... .......... .......... 98%  194M 0s\n",
            " 56100K .......... .......... .......... .......... .......... 98%  206M 0s\n",
            " 56150K .......... .......... .......... .......... .......... 98%  211M 0s\n",
            " 56200K .......... .......... .......... .......... .......... 98%  241M 0s\n",
            " 56250K .......... .......... .......... .......... .......... 98%  222M 0s\n",
            " 56300K .......... .......... .......... .......... .......... 98%  230M 0s\n",
            " 56350K .......... .......... .......... .......... .......... 98%  209M 0s\n",
            " 56400K .......... .......... .......... .......... .......... 98%  230M 0s\n",
            " 56450K .......... .......... .......... .......... .......... 98%  216M 0s\n",
            " 56500K .......... .......... .......... .......... .......... 99%  230M 0s\n",
            " 56550K .......... .......... .......... .......... .......... 99%  224M 0s\n",
            " 56600K .......... .......... .......... .......... .......... 99%  222M 0s\n",
            " 56650K .......... .......... .......... .......... .......... 99%  203M 0s\n",
            " 56700K .......... .......... .......... .......... .......... 99%  222M 0s\n",
            " 56750K .......... .......... .......... .......... .......... 99%  146M 0s\n",
            " 56800K .......... .......... .......... .......... .......... 99%  179M 0s\n",
            " 56850K .......... .......... .......... .......... .......... 99%  177M 0s\n",
            " 56900K .......... .......... .......... .......... .......... 99%  166M 0s\n",
            " 56950K .......... .......... .......... .......... .......... 99%  167M 0s\n",
            " 57000K .......... .......... .......... .......... .......... 99%  185M 0s\n",
            " 57050K .......... .......... .......... .......... ........  100%  230M=0.3s\n",
            "\n",
            "2020-12-11 04:28:19 (161 MB/s) - ‘Miniconda3-4.5.4-Linux-x86_64.sh’ saved [58468498/58468498]\n",
            "\n",
            "Python 3.6.5 :: Anaconda, Inc.\n",
            "bash: line 6: !rm: command not found\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9RvEdyc4Wx7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60faddd3-f987-4525-e03c-4c341759ab64"
      },
      "source": [
        "%%bash\n",
        "conda install --channel defaults conda python=3.6 --yes\n",
        "conda update --channel defaults --all --yes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs: \n",
            "    - conda\n",
            "    - python=3.6\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    urllib3-1.25.11            |             py_0          93 KB\n",
            "    ruamel_yaml-0.15.87        |   py36h7b6447c_1         256 KB\n",
            "    ncurses-6.2                |       he6710b0_1         1.1 MB\n",
            "    conda-package-handling-1.7.2|   py36h03888b9_0         967 KB\n",
            "    six-1.15.0                 |   py36h06a4308_0          27 KB\n",
            "    xz-5.2.5                   |       h7b6447c_0         438 KB\n",
            "    readline-8.0               |       h7b6447c_0         428 KB\n",
            "    idna-2.10                  |             py_0          56 KB\n",
            "    cffi-1.14.4                |   py36h261ae71_0         224 KB\n",
            "    openssl-1.1.1i             |       h27cfd23_0         3.8 MB\n",
            "    _libgcc_mutex-0.1          |             main           3 KB\n",
            "    libgcc-ng-9.1.0            |       hdf63c60_0         8.1 MB\n",
            "    zlib-1.2.11                |       h7b6447c_3         120 KB\n",
            "    libffi-3.3                 |       he6710b0_2          54 KB\n",
            "    pysocks-1.7.1              |   py36h06a4308_0          30 KB\n",
            "    tqdm-4.54.1                |     pyhd3eb1b0_0          54 KB\n",
            "    pycparser-2.20             |             py_2          94 KB\n",
            "    pip-20.3.1                 |   py36h06a4308_0         2.0 MB\n",
            "    python-3.6.12              |       hcff3b4d_2        34.0 MB\n",
            "    cryptography-3.3.1         |   py36h3c74f83_0         638 KB\n",
            "    yaml-0.2.5                 |       h7b6447c_0          87 KB\n",
            "    brotlipy-0.7.0             |py36h27cfd23_1003         349 KB\n",
            "    pycosat-0.6.3              |   py36h27cfd23_0         107 KB\n",
            "    chardet-3.0.4              |py36h06a4308_1003         197 KB\n",
            "    conda-4.9.2                |   py36h06a4308_0         3.1 MB\n",
            "    libstdcxx-ng-9.1.0         |       hdf63c60_0         4.0 MB\n",
            "    tk-8.6.10                  |       hbc83047_0         3.2 MB\n",
            "    requests-2.25.0            |     pyhd3eb1b0_0          51 KB\n",
            "    certifi-2020.12.5          |   py36h06a4308_0         144 KB\n",
            "    sqlite-3.33.0              |       h62c20be_0         2.0 MB\n",
            "    ca-certificates-2020.12.8  |       h06a4308_0         128 KB\n",
            "    ld_impl_linux-64-2.33.1    |       h53a641e_7         645 KB\n",
            "    wheel-0.36.1               |     pyhd3eb1b0_0          31 KB\n",
            "    setuptools-51.0.0          |   py36h06a4308_2         936 KB\n",
            "    pyopenssl-20.0.0           |     pyhd3eb1b0_1          48 KB\n",
            "    libedit-3.1.20191231       |       h14c3975_1         121 KB\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:        67.6 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "    _libgcc_mutex:          0.1-main               \n",
            "    brotlipy:               0.7.0-py36h27cfd23_1003\n",
            "    conda-package-handling: 1.7.2-py36h03888b9_0   \n",
            "    ld_impl_linux-64:       2.33.1-h53a641e_7      \n",
            "    tqdm:                   4.54.1-pyhd3eb1b0_0    \n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "    ca-certificates:        2018.03.07-0            --> 2020.12.8-h06a4308_0    \n",
            "    certifi:                2018.4.16-py36_0        --> 2020.12.5-py36h06a4308_0\n",
            "    cffi:                   1.11.5-py36h9745a5d_0   --> 1.14.4-py36h261ae71_0   \n",
            "    chardet:                3.0.4-py36h0f667ec_1    --> 3.0.4-py36h06a4308_1003 \n",
            "    conda:                  4.5.4-py36_0            --> 4.9.2-py36h06a4308_0    \n",
            "    cryptography:           2.2.2-py36h14c3975_0    --> 3.3.1-py36h3c74f83_0    \n",
            "    idna:                   2.6-py36h82fb2a8_1      --> 2.10-py_0               \n",
            "    libedit:                3.1.20170329-h6b74fdf_2 --> 3.1.20191231-h14c3975_1 \n",
            "    libffi:                 3.2.1-hd88cf55_4        --> 3.3-he6710b0_2          \n",
            "    libgcc-ng:              7.2.0-hdf63c60_3        --> 9.1.0-hdf63c60_0        \n",
            "    libstdcxx-ng:           7.2.0-hdf63c60_3        --> 9.1.0-hdf63c60_0        \n",
            "    ncurses:                6.1-hf484d3e_0          --> 6.2-he6710b0_1          \n",
            "    openssl:                1.0.2o-h20670df_0       --> 1.1.1i-h27cfd23_0       \n",
            "    pip:                    10.0.1-py36_0           --> 20.3.1-py36h06a4308_0   \n",
            "    pycosat:                0.6.3-py36h0a5515d_0    --> 0.6.3-py36h27cfd23_0    \n",
            "    pycparser:              2.18-py36hf9f622e_1     --> 2.20-py_2               \n",
            "    pyopenssl:              18.0.0-py36_0           --> 20.0.0-pyhd3eb1b0_1     \n",
            "    pysocks:                1.6.8-py36_0            --> 1.7.1-py36h06a4308_0    \n",
            "    python:                 3.6.5-hc3d631a_2        --> 3.6.12-hcff3b4d_2       \n",
            "    readline:               7.0-ha6073c6_4          --> 8.0-h7b6447c_0          \n",
            "    requests:               2.18.4-py36he2e5f8d_1   --> 2.25.0-pyhd3eb1b0_0     \n",
            "    ruamel_yaml:            0.15.37-py36h14c3975_2  --> 0.15.87-py36h7b6447c_1  \n",
            "    setuptools:             39.2.0-py36_0           --> 51.0.0-py36h06a4308_2   \n",
            "    six:                    1.11.0-py36h372c433_1   --> 1.15.0-py36h06a4308_0   \n",
            "    sqlite:                 3.23.1-he433501_0       --> 3.33.0-h62c20be_0       \n",
            "    tk:                     8.6.7-hc745277_3        --> 8.6.10-hbc83047_0       \n",
            "    urllib3:                1.22-py36hbe7ace6_0     --> 1.25.11-py_0            \n",
            "    wheel:                  0.31.1-py36_0           --> 0.36.1-pyhd3eb1b0_0     \n",
            "    xz:                     5.2.4-h14c3975_4        --> 5.2.5-h7b6447c_0        \n",
            "    yaml:                   0.1.7-had09818_2        --> 0.2.5-h7b6447c_0        \n",
            "    zlib:                   1.2.11-ha838bed_2       --> 1.2.11-h7b6447c_3       \n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "\n",
            "The following packages will be REMOVED:\n",
            "\n",
            "  asn1crypto-0.24.0-py36_0\n",
            "  conda-env-2.6.0-h36134e3_1\n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rurllib3-1.25.11      |   93 KB |            |   0% \rurllib3-1.25.11      |   93 KB | ########## | 100% \n",
            "\rruamel_yaml-0.15.87  |  256 KB |            |   0% \rruamel_yaml-0.15.87  |  256 KB | ########## | 100% \n",
            "\rncurses-6.2          |  1.1 MB |            |   0% \rncurses-6.2          |  1.1 MB | #######8   |  78% \rncurses-6.2          |  1.1 MB | ########## | 100% \n",
            "\rconda-package-handli |  967 KB |            |   0% \rconda-package-handli |  967 KB | ########9  |  89% \rconda-package-handli |  967 KB | ########## | 100% \n",
            "\rsix-1.15.0           |   27 KB |            |   0% \rsix-1.15.0           |   27 KB | ########## | 100% \n",
            "\rxz-5.2.5             |  438 KB |            |   0% \rxz-5.2.5             |  438 KB | #########4 |  94% \rxz-5.2.5             |  438 KB | ########## | 100% \n",
            "\rreadline-8.0         |  428 KB |            |   0% \rreadline-8.0         |  428 KB | ########## | 100% \n",
            "\ridna-2.10            |   56 KB |            |   0% \ridna-2.10            |   56 KB | ########## | 100% \n",
            "\rcffi-1.14.4          |  224 KB |            |   0% \rcffi-1.14.4          |  224 KB | ########## | 100% \n",
            "\ropenssl-1.1.1i       |  3.8 MB |            |   0% \ropenssl-1.1.1i       |  3.8 MB | #######7   |  77% \ropenssl-1.1.1i       |  3.8 MB | #########8 |  99% \ropenssl-1.1.1i       |  3.8 MB | ########## | 100% \n",
            "\r_libgcc_mutex-0.1    |    3 KB |            |   0% \r_libgcc_mutex-0.1    |    3 KB | ########## | 100% \n",
            "\rlibgcc-ng-9.1.0      |  8.1 MB |            |   0% \rlibgcc-ng-9.1.0      |  8.1 MB | #######5   |  76% \rlibgcc-ng-9.1.0      |  8.1 MB | #########5 |  95% \rlibgcc-ng-9.1.0      |  8.1 MB | ########## | 100% \n",
            "\rzlib-1.2.11          |  120 KB |            |   0% \rzlib-1.2.11          |  120 KB | ########## | 100% \n",
            "\rlibffi-3.3           |   54 KB |            |   0% \rlibffi-3.3           |   54 KB | ########## | 100% \n",
            "\rpysocks-1.7.1        |   30 KB |            |   0% \rpysocks-1.7.1        |   30 KB | ########## | 100% \n",
            "\rtqdm-4.54.1          |   54 KB |            |   0% \rtqdm-4.54.1          |   54 KB | ########## | 100% \n",
            "\rpycparser-2.20       |   94 KB |            |   0% \rpycparser-2.20       |   94 KB | ########## | 100% \n",
            "\rpip-20.3.1           |  2.0 MB |            |   0% \rpip-20.3.1           |  2.0 MB | #######7   |  78% \rpip-20.3.1           |  2.0 MB | #########4 |  94% \rpip-20.3.1           |  2.0 MB | ########## | 100% \n",
            "\rpython-3.6.12        | 34.0 MB |            |   0% \rpython-3.6.12        | 34.0 MB | ##9        |  30% \rpython-3.6.12        | 34.0 MB | #######1   |  71% \rpython-3.6.12        | 34.0 MB | ########9  |  90% \rpython-3.6.12        | 34.0 MB | ########## | 100% \n",
            "\rcryptography-3.3.1   |  638 KB |            |   0% \rcryptography-3.3.1   |  638 KB | ########8  |  88% \rcryptography-3.3.1   |  638 KB | ########## | 100% \n",
            "\ryaml-0.2.5           |   87 KB |            |   0% \ryaml-0.2.5           |   87 KB | ########## | 100% \n",
            "\rbrotlipy-0.7.0       |  349 KB |            |   0% \rbrotlipy-0.7.0       |  349 KB | ########## | 100% \n",
            "\rpycosat-0.6.3        |  107 KB |            |   0% \rpycosat-0.6.3        |  107 KB | ########## | 100% \n",
            "\rchardet-3.0.4        |  197 KB |            |   0% \rchardet-3.0.4        |  197 KB | ########## | 100% \n",
            "\rconda-4.9.2          |  3.1 MB |            |   0% \rconda-4.9.2          |  3.1 MB | #######9   |  79% \rconda-4.9.2          |  3.1 MB | #########5 |  96% \rconda-4.9.2          |  3.1 MB | ########## | 100% \n",
            "\rlibstdcxx-ng-9.1.0   |  4.0 MB |            |   0% \rlibstdcxx-ng-9.1.0   |  4.0 MB | #######7   |  78% \rlibstdcxx-ng-9.1.0   |  4.0 MB | ########## | 100% \n",
            "\rtk-8.6.10            |  3.2 MB |            |   0% \rtk-8.6.10            |  3.2 MB | #######7   |  78% \rtk-8.6.10            |  3.2 MB | ########## | 100% \n",
            "\rrequests-2.25.0      |   51 KB |            |   0% \rrequests-2.25.0      |   51 KB | ########## | 100% \n",
            "\rcertifi-2020.12.5    |  144 KB |            |   0% \rcertifi-2020.12.5    |  144 KB | ########## | 100% \n",
            "\rsqlite-3.33.0        |  2.0 MB |            |   0% \rsqlite-3.33.0        |  2.0 MB | ########   |  80% \rsqlite-3.33.0        |  2.0 MB | ########## | 100% \n",
            "\rca-certificates-2020 |  128 KB |            |   0% \rca-certificates-2020 |  128 KB | ########## | 100% \n",
            "\rld_impl_linux-64-2.3 |  645 KB |            |   0% \rld_impl_linux-64-2.3 |  645 KB | #########6 |  96% \rld_impl_linux-64-2.3 |  645 KB | ########## | 100% \n",
            "\rwheel-0.36.1         |   31 KB |            |   0% \rwheel-0.36.1         |   31 KB | ########## | 100% \n",
            "\rsetuptools-51.0.0    |  936 KB |            |   0% \rsetuptools-51.0.0    |  936 KB | ########1  |  82% \rsetuptools-51.0.0    |  936 KB | ########## | 100% \n",
            "\rpyopenssl-20.0.0     |   48 KB |            |   0% \rpyopenssl-20.0.0     |   48 KB | ########## | 100% \n",
            "\rlibedit-3.1.20191231 |  121 KB |            |   0% \rlibedit-3.1.20191231 |  121 KB | ########## | 100% \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQolOHwM4oXU"
      },
      "source": [
        "import sys\n",
        "sys.path.append(\"/usr/local/lib/python3.6/site-packages\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tubS2t3ez3ZF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e56c47e-ebc0-45af-b817-63029b7be35e"
      },
      "source": [
        "import getpass\n",
        "import o\n",
        "s\n",
        "user = input('Gitlab username: ')\n",
        "password = getpass.getpass('Gitlab password: ')\n",
        "os.environ['GITLAB_AUTH'] = user + ':' + password\n",
        "\n",
        "!git clone https://$GITLAB_AUTH@gitlab.com/mohimanilab/interpretable-activity-prediction.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gitlab username: JosephZheng1998\n",
            "Gitlab password: ··········\n",
            "Cloning into 'interpretable-activity-prediction'...\n",
            "remote: Enumerating objects: 83, done.\u001b[K\n",
            "remote: Counting objects: 100% (83/83), done.\u001b[K\n",
            "remote: Compressing objects: 100% (69/69), done.\u001b[K\n",
            "remote: Total 83 (delta 6), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (83/83), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXV6I4_Z1eyv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00389cf9-3b6b-468f-ea2f-a67fa8c7cf2d"
      },
      "source": [
        "!conda install -c conda-forge rdkit --yes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Solving environment: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - rdkit\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    boost-1.74.0               |   py36h8e82bdb_2         336 KB  conda-forge\n",
            "    boost-cpp-1.74.0           |       h9359b55_0        16.4 MB  conda-forge\n",
            "    bzip2-1.0.8                |       h516909a_3         398 KB  conda-forge\n",
            "    ca-certificates-2020.12.5  |       ha878542_0         137 KB  conda-forge\n",
            "    cairo-1.16.0               |    h3fc0475_1005         1.5 MB  conda-forge\n",
            "    certifi-2020.12.5          |   py36h5fab9bb_0         143 KB  conda-forge\n",
            "    conda-4.9.2                |   py36h5fab9bb_0         3.0 MB  conda-forge\n",
            "    cycler-0.10.0              |             py_2           9 KB  conda-forge\n",
            "    fontconfig-2.13.1          |    h7e3eb15_1002         324 KB  conda-forge\n",
            "    freetype-2.10.4            |       h7ca028e_0         912 KB  conda-forge\n",
            "    glib-2.66.1                |       h92f7085_0         2.9 MB\n",
            "    icu-67.1                   |       he1b5a44_0        12.9 MB  conda-forge\n",
            "    jpeg-9d                    |       h36c2ea0_0         264 KB  conda-forge\n",
            "    kiwisolver-1.3.1           |   py36h51d7077_0          86 KB  conda-forge\n",
            "    lcms2-2.11                 |       hcbb858e_1         434 KB  conda-forge\n",
            "    libblas-3.9.0              |       3_openblas          11 KB  conda-forge\n",
            "    libcblas-3.9.0             |       3_openblas          11 KB  conda-forge\n",
            "    libgfortran-ng-7.5.0       |      hae1eefd_17          22 KB  conda-forge\n",
            "    libgfortran4-7.5.0         |      hae1eefd_17         1.3 MB  conda-forge\n",
            "    libiconv-1.16              |       h516909a_0         1.4 MB  conda-forge\n",
            "    liblapack-3.9.0            |       3_openblas          11 KB  conda-forge\n",
            "    libopenblas-0.3.12         |pthreads_hb3c22a3_1         8.2 MB  conda-forge\n",
            "    libpng-1.6.37              |       h21135ba_2         306 KB  conda-forge\n",
            "    libtiff-4.1.0              |       h4f3a223_6         618 KB  conda-forge\n",
            "    libuuid-2.32.1             |    h14c3975_1000          26 KB  conda-forge\n",
            "    libwebp-base-1.1.0         |       h36c2ea0_3         864 KB  conda-forge\n",
            "    libxcb-1.13                |    h14c3975_1002         396 KB  conda-forge\n",
            "    libxml2-2.9.10             |       h68273f3_2         1.3 MB  conda-forge\n",
            "    lz4-c-1.9.2                |       he1b5a44_3         203 KB  conda-forge\n",
            "    matplotlib-base-3.3.3      |   py36he12231b_0         6.8 MB  conda-forge\n",
            "    numpy-1.19.4               |   py36h8732dcd_1         5.2 MB  conda-forge\n",
            "    olefile-0.46               |     pyh9f0ad1d_1          32 KB  conda-forge\n",
            "    pandas-1.0.1               |   py36hb3f55d8_0        11.1 MB  conda-forge\n",
            "    pcre-8.44                  |       he1b5a44_0         261 KB  conda-forge\n",
            "    pillow-8.0.1               |   py36h10ecd5c_0         687 KB  conda-forge\n",
            "    pixman-0.38.0              |    h516909a_1003         594 KB  conda-forge\n",
            "    pthread-stubs-0.4          |    h36c2ea0_1001           5 KB  conda-forge\n",
            "    pycairo-1.20.0             |   py36h4779a57_1          77 KB  conda-forge\n",
            "    pyparsing-2.4.7            |     pyh9f0ad1d_0          60 KB  conda-forge\n",
            "    python-dateutil-2.8.1      |             py_0         220 KB  conda-forge\n",
            "    python_abi-3.6             |          1_cp36m           4 KB  conda-forge\n",
            "    pytz-2020.4                |     pyhd8ed1ab_0         229 KB  conda-forge\n",
            "    rdkit-2020.09.2            |   py36hf1a5a59_0        25.8 MB  conda-forge\n",
            "    reportlab-3.5.51           |   py36hd14fb90_0         2.2 MB\n",
            "    sqlalchemy-1.3.20          |   py36h8c4c3a4_0         1.8 MB  conda-forge\n",
            "    tornado-6.1                |   py36h1d69622_0         644 KB  conda-forge\n",
            "    xorg-kbproto-1.0.7         |    h14c3975_1002          26 KB  conda-forge\n",
            "    xorg-libice-1.0.10         |       h516909a_0          57 KB  conda-forge\n",
            "    xorg-libsm-1.2.3           |    h84519dc_1000          25 KB  conda-forge\n",
            "    xorg-libx11-1.6.12         |       h516909a_0         917 KB  conda-forge\n",
            "    xorg-libxau-1.0.9          |       h14c3975_0          13 KB  conda-forge\n",
            "    xorg-libxdmcp-1.1.3        |       h516909a_0          18 KB  conda-forge\n",
            "    xorg-libxext-1.3.4         |       h516909a_0          51 KB  conda-forge\n",
            "    xorg-libxrender-0.9.10     |    h516909a_1002          31 KB  conda-forge\n",
            "    xorg-renderproto-0.11.1    |    h14c3975_1002           8 KB  conda-forge\n",
            "    xorg-xextproto-7.3.0       |    h14c3975_1002          27 KB  conda-forge\n",
            "    xorg-xproto-7.0.31         |    h14c3975_1007          72 KB  conda-forge\n",
            "    zstd-1.4.5                 |       h6597ccf_2         712 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       111.7 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  boost              conda-forge/linux-64::boost-1.74.0-py36h8e82bdb_2\n",
            "  boost-cpp          conda-forge/linux-64::boost-cpp-1.74.0-h9359b55_0\n",
            "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h516909a_3\n",
            "  cairo              conda-forge/linux-64::cairo-1.16.0-h3fc0475_1005\n",
            "  cycler             conda-forge/noarch::cycler-0.10.0-py_2\n",
            "  fontconfig         conda-forge/linux-64::fontconfig-2.13.1-h7e3eb15_1002\n",
            "  freetype           conda-forge/linux-64::freetype-2.10.4-h7ca028e_0\n",
            "  glib               pkgs/main/linux-64::glib-2.66.1-h92f7085_0\n",
            "  icu                conda-forge/linux-64::icu-67.1-he1b5a44_0\n",
            "  jpeg               conda-forge/linux-64::jpeg-9d-h36c2ea0_0\n",
            "  kiwisolver         conda-forge/linux-64::kiwisolver-1.3.1-py36h51d7077_0\n",
            "  lcms2              conda-forge/linux-64::lcms2-2.11-hcbb858e_1\n",
            "  libblas            conda-forge/linux-64::libblas-3.9.0-3_openblas\n",
            "  libcblas           conda-forge/linux-64::libcblas-3.9.0-3_openblas\n",
            "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-7.5.0-hae1eefd_17\n",
            "  libgfortran4       conda-forge/linux-64::libgfortran4-7.5.0-hae1eefd_17\n",
            "  libiconv           conda-forge/linux-64::libiconv-1.16-h516909a_0\n",
            "  liblapack          conda-forge/linux-64::liblapack-3.9.0-3_openblas\n",
            "  libopenblas        conda-forge/linux-64::libopenblas-0.3.12-pthreads_hb3c22a3_1\n",
            "  libpng             conda-forge/linux-64::libpng-1.6.37-h21135ba_2\n",
            "  libtiff            conda-forge/linux-64::libtiff-4.1.0-h4f3a223_6\n",
            "  libuuid            conda-forge/linux-64::libuuid-2.32.1-h14c3975_1000\n",
            "  libwebp-base       conda-forge/linux-64::libwebp-base-1.1.0-h36c2ea0_3\n",
            "  libxcb             conda-forge/linux-64::libxcb-1.13-h14c3975_1002\n",
            "  libxml2            conda-forge/linux-64::libxml2-2.9.10-h68273f3_2\n",
            "  lz4-c              conda-forge/linux-64::lz4-c-1.9.2-he1b5a44_3\n",
            "  matplotlib-base    conda-forge/linux-64::matplotlib-base-3.3.3-py36he12231b_0\n",
            "  numpy              conda-forge/linux-64::numpy-1.19.4-py36h8732dcd_1\n",
            "  olefile            conda-forge/noarch::olefile-0.46-pyh9f0ad1d_1\n",
            "  pandas             conda-forge/linux-64::pandas-1.0.1-py36hb3f55d8_0\n",
            "  pcre               conda-forge/linux-64::pcre-8.44-he1b5a44_0\n",
            "  pillow             conda-forge/linux-64::pillow-8.0.1-py36h10ecd5c_0\n",
            "  pixman             conda-forge/linux-64::pixman-0.38.0-h516909a_1003\n",
            "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-h36c2ea0_1001\n",
            "  pycairo            conda-forge/linux-64::pycairo-1.20.0-py36h4779a57_1\n",
            "  pyparsing          conda-forge/noarch::pyparsing-2.4.7-pyh9f0ad1d_0\n",
            "  python-dateutil    conda-forge/noarch::python-dateutil-2.8.1-py_0\n",
            "  python_abi         conda-forge/linux-64::python_abi-3.6-1_cp36m\n",
            "  pytz               conda-forge/noarch::pytz-2020.4-pyhd8ed1ab_0\n",
            "  rdkit              conda-forge/linux-64::rdkit-2020.09.2-py36hf1a5a59_0\n",
            "  reportlab          pkgs/main/linux-64::reportlab-3.5.51-py36hd14fb90_0\n",
            "  sqlalchemy         conda-forge/linux-64::sqlalchemy-1.3.20-py36h8c4c3a4_0\n",
            "  tornado            conda-forge/linux-64::tornado-6.1-py36h1d69622_0\n",
            "  xorg-kbproto       conda-forge/linux-64::xorg-kbproto-1.0.7-h14c3975_1002\n",
            "  xorg-libice        conda-forge/linux-64::xorg-libice-1.0.10-h516909a_0\n",
            "  xorg-libsm         conda-forge/linux-64::xorg-libsm-1.2.3-h84519dc_1000\n",
            "  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.6.12-h516909a_0\n",
            "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.9-h14c3975_0\n",
            "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.3-h516909a_0\n",
            "  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.4-h516909a_0\n",
            "  xorg-libxrender    conda-forge/linux-64::xorg-libxrender-0.9.10-h516909a_1002\n",
            "  xorg-renderproto   conda-forge/linux-64::xorg-renderproto-0.11.1-h14c3975_1002\n",
            "  xorg-xextproto     conda-forge/linux-64::xorg-xextproto-7.3.0-h14c3975_1002\n",
            "  xorg-xproto        conda-forge/linux-64::xorg-xproto-7.0.31-h14c3975_1007\n",
            "  zstd               conda-forge/linux-64::zstd-1.4.5-h6597ccf_2\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  ca-certificates    pkgs/main::ca-certificates-2020.12.8-~ --> conda-forge::ca-certificates-2020.12.5-ha878542_0\n",
            "  certifi            pkgs/main::certifi-2020.12.5-py36h06a~ --> conda-forge::certifi-2020.12.5-py36h5fab9bb_0\n",
            "  conda               pkgs/main::conda-4.9.2-py36h06a4308_0 --> conda-forge::conda-4.9.2-py36h5fab9bb_0\n",
            "\n",
            "\n",
            "\n",
            "Downloading and Extracting Packages\n",
            "sqlalchemy-1.3.20    | 1.8 MB    | : 100% 1.0/1 [00:00<00:00,  1.81it/s]\n",
            "libtiff-4.1.0        | 618 KB    | : 100% 1.0/1 [00:00<00:00,  7.44it/s]\n",
            "certifi-2020.12.5    | 143 KB    | : 100% 1.0/1 [00:00<00:00, 18.28it/s]\n",
            "glib-2.66.1          | 2.9 MB    | : 100% 1.0/1 [00:00<00:00,  3.25it/s]\n",
            "icu-67.1             | 12.9 MB   | : 100% 1.0/1 [00:01<00:00,  1.94s/it]\n",
            "olefile-0.46         | 32 KB     | : 100% 1.0/1 [00:00<00:00, 19.77it/s]\n",
            "xorg-libxdmcp-1.1.3  | 18 KB     | : 100% 1.0/1 [00:00<00:00, 28.05it/s]\n",
            "libwebp-base-1.1.0   | 864 KB    | : 100% 1.0/1 [00:00<00:00,  5.66it/s]\n",
            "boost-1.74.0         | 336 KB    | : 100% 1.0/1 [00:00<00:00,  8.36it/s]\n",
            "xorg-libxau-1.0.9    | 13 KB     | : 100% 1.0/1 [00:00<00:00, 27.88it/s]\n",
            "fontconfig-2.13.1    | 324 KB    | : 100% 1.0/1 [00:00<00:00,  9.59it/s]\n",
            "xorg-libice-1.0.10   | 57 KB     | : 100% 1.0/1 [00:00<00:00, 20.97it/s]\n",
            "xorg-kbproto-1.0.7   | 26 KB     | : 100% 1.0/1 [00:00<00:00, 26.08it/s]\n",
            "libgfortran-ng-7.5.0 | 22 KB     | : 100% 1.0/1 [00:00<00:00, 24.03it/s]\n",
            "pytz-2020.4          | 229 KB    | : 100% 1.0/1 [00:00<00:00,  8.61it/s]\n",
            "python_abi-3.6       | 4 KB      | : 100% 1.0/1 [00:00<00:00, 25.98it/s]\n",
            "ca-certificates-2020 | 137 KB    | : 100% 1.0/1 [00:00<00:00, 16.75it/s]\n",
            "pyparsing-2.4.7      | 60 KB     | : 100% 1.0/1 [00:00<00:00, 20.32it/s]\n",
            "pthread-stubs-0.4    | 5 KB      | : 100% 1.0/1 [00:00<00:00, 26.35it/s]\n",
            "matplotlib-base-3.3. | 6.8 MB    | : 100% 1.0/1 [00:01<00:00,  1.11s/it]\n",
            "boost-cpp-1.74.0     | 16.4 MB   | : 100% 1.0/1 [00:05<00:00,  5.22s/it]\n",
            "xorg-libxext-1.3.4   | 51 KB     | : 100% 1.0/1 [00:00<00:00, 22.01it/s]\n",
            "numpy-1.19.4         | 5.2 MB    | : 100% 1.0/1 [00:01<00:00,  1.04s/it]\n",
            "xorg-renderproto-0.1 | 8 KB      | : 100% 1.0/1 [00:00<00:00, 27.71it/s]\n",
            "xorg-xextproto-7.3.0 | 27 KB     | : 100% 1.0/1 [00:00<00:00, 24.49it/s]\n",
            "xorg-libsm-1.2.3     | 25 KB     | : 100% 1.0/1 [00:00<00:00, 16.14it/s]\n",
            "liblapack-3.9.0      | 11 KB     | : 100% 1.0/1 [00:00<00:00, 25.35it/s]\n",
            "libiconv-1.16        | 1.4 MB    | : 100% 1.0/1 [00:00<00:00,  4.70it/s]\n",
            "conda-4.9.2          | 3.0 MB    | : 100% 1.0/1 [00:00<00:00,  1.68it/s]\n",
            "bzip2-1.0.8          | 398 KB    | : 100% 1.0/1 [00:00<00:00,  9.64it/s]\n",
            "libxcb-1.13          | 396 KB    | : 100% 1.0/1 [00:00<00:00,  6.94it/s]\n",
            "jpeg-9d              | 264 KB    | : 100% 1.0/1 [00:00<00:00, 12.11it/s]\n",
            "libblas-3.9.0        | 11 KB     | : 100% 1.0/1 [00:00<00:00, 24.48it/s]\n",
            "python-dateutil-2.8. | 220 KB    | : 100% 1.0/1 [00:00<00:00, 15.42it/s]\n",
            "libopenblas-0.3.12   | 8.2 MB    | : 100% 1.0/1 [00:01<00:00,  1.36s/it]\n",
            "xorg-libx11-1.6.12   | 917 KB    | : 100% 1.0/1 [00:00<00:00,  5.18it/s]\n",
            "tornado-6.1          | 644 KB    | : 100% 1.0/1 [00:00<00:00,  5.90it/s]\n",
            "reportlab-3.5.51     | 2.2 MB    | : 100% 1.0/1 [00:00<00:00,  7.62it/s]\n",
            "cycler-0.10.0        | 9 KB      | : 100% 1.0/1 [00:00<00:00, 24.91it/s]\n",
            "lz4-c-1.9.2          | 203 KB    | : 100% 1.0/1 [00:00<00:00, 15.63it/s]\n",
            "cairo-1.16.0         | 1.5 MB    | : 100% 1.0/1 [00:00<00:00,  2.98it/s]\n",
            "rdkit-2020.09.2      | 25.8 MB   | : 100% 1.0/1 [00:03<00:00,  3.82s/it]               \n",
            "pixman-0.38.0        | 594 KB    | : 100% 1.0/1 [00:00<00:00,  8.22it/s]\n",
            "libgfortran4-7.5.0   | 1.3 MB    | : 100% 1.0/1 [00:00<00:00,  3.95it/s]\n",
            "pillow-8.0.1         | 687 KB    | : 100% 1.0/1 [00:00<00:00,  6.33it/s]\n",
            "libuuid-2.32.1       | 26 KB     | : 100% 1.0/1 [00:00<00:00, 27.01it/s]\n",
            "lcms2-2.11           | 434 KB    | : 100% 1.0/1 [00:00<00:00,  9.49it/s]\n",
            "zstd-1.4.5           | 712 KB    | : 100% 1.0/1 [00:00<00:00,  7.55it/s]\n",
            "pycairo-1.20.0       | 77 KB     | : 100% 1.0/1 [00:00<00:00, 22.81it/s]\n",
            "pandas-1.0.1         | 11.1 MB   | : 100% 1.0/1 [00:02<00:00,  2.15s/it]               \n",
            "libxml2-2.9.10       | 1.3 MB    | : 100% 1.0/1 [00:00<00:00,  2.97it/s]\n",
            "freetype-2.10.4      | 912 KB    | : 100% 1.0/1 [00:00<00:00,  6.03it/s]\n",
            "xorg-libxrender-0.9. | 31 KB     | : 100% 1.0/1 [00:00<00:00, 28.02it/s]\n",
            "pcre-8.44            | 261 KB    | : 100% 1.0/1 [00:00<00:00, 10.03it/s]\n",
            "kiwisolver-1.3.1     | 86 KB     | : 100% 1.0/1 [00:00<00:00, 24.40it/s]\n",
            "xorg-xproto-7.0.31   | 72 KB     | : 100% 1.0/1 [00:00<00:00, 19.85it/s]\n",
            "libcblas-3.9.0       | 11 KB     | : 100% 1.0/1 [00:00<00:00, 25.19it/s]\n",
            "libpng-1.6.37        | 306 KB    | : 100% 1.0/1 [00:00<00:00, 11.42it/s]\n",
            "Preparing transaction: | \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n",
            "Verifying transaction: - \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\bdone\n",
            "Executing transaction: \\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\bdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeeGRF0U3U16"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCOEX2qhzxw1"
      },
      "source": [
        "import sys\n",
        "sys.path.append(\"/usr/local/lib/python3.6/site-packages\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmR6VMnLx87J"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from rdkit import Chem, DataStructs\n",
        "from rdkit.Chem import AllChem"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kqY5UP2M5Pd"
      },
      "source": [
        "def convert_smiles_to_numpy(smiles, radius, num_bits):\n",
        "    mol = Chem.MolFromSmiles(smiles)\n",
        "    features_vec = AllChem.GetMorganFingerprintAsBitVect(mol, radius, nBits=num_bits)\n",
        "    features = np.zeros((1,))\n",
        "    DataStructs.ConvertToNumpyArray(features_vec, features)\n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3bs0t2JGAgk"
      },
      "source": [
        "training_set = pd.read_csv('interpretable-activity-prediction/data/training_set.csv')\n",
        "training_set = training_set.loc[:,['SMILES', 'Activity']]\n",
        "testing_set = pd.read_csv('interpretable-activity-prediction/data/test_set_filtered.csv')\n",
        "testing_set = testing_set.loc[:,['SMILES', 'Activity']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d--CkPM2HVG4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfd6b6d5-959c-4111-e0db-ea0b6b7232db"
      },
      "source": [
        "training_set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SMILES</th>\n",
              "      <th>Activity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cc1cc(O)c(C(=O)NC(C(=O)NC2C(=O)N3C(C(=O)O)=C(C...</td>\n",
              "      <td>Active</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CON=C1CN(c2nc3c(cc2F)c(=O)c(C(=O)O)cn3C2CC2)CC...</td>\n",
              "      <td>Active</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CCC(C)CCCCC(=O)NC(CCN)C(=O)NC(C(=O)NC(CCN)C(=O...</td>\n",
              "      <td>Active</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cl.N=C(N)n1cccn1</td>\n",
              "      <td>Active</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Cl.Cl.N=C(NCCCCCCNC(=N)NC(=N)Nc1ccc(Cl)cc1)NC(...</td>\n",
              "      <td>Active</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2330</th>\n",
              "      <td>C=CC1(C)CC(=O)C2(O)C(C)(O1)C(OC(C)=O)C(O)C1C(C...</td>\n",
              "      <td>Inactive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2331</th>\n",
              "      <td>O=S(=O)([O-])c1cc(O)c2c(N=Nc3ccc(Nc4ccccc4)c4c...</td>\n",
              "      <td>Inactive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2332</th>\n",
              "      <td>Nc1ccc(S(=O)(=O)c2ccc(N)cc2)cc1</td>\n",
              "      <td>Inactive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2333</th>\n",
              "      <td>Cc1cc(-c2ccc(N=Nc3ccc4c(S(=O)(=O)[O-])cc(S(=O)...</td>\n",
              "      <td>Inactive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2334</th>\n",
              "      <td>C=Cc1c(C)c2cc3[nH]c(cc4nc(cc5[nH]c(cc1n2)c(C)c...</td>\n",
              "      <td>Inactive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2335 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 SMILES  Activity\n",
              "0     Cc1cc(O)c(C(=O)NC(C(=O)NC2C(=O)N3C(C(=O)O)=C(C...    Active\n",
              "1     CON=C1CN(c2nc3c(cc2F)c(=O)c(C(=O)O)cn3C2CC2)CC...    Active\n",
              "2     CCC(C)CCCCC(=O)NC(CCN)C(=O)NC(C(=O)NC(CCN)C(=O...    Active\n",
              "3                                      Cl.N=C(N)n1cccn1    Active\n",
              "4     Cl.Cl.N=C(NCCCCCCNC(=N)NC(=N)Nc1ccc(Cl)cc1)NC(...    Active\n",
              "...                                                 ...       ...\n",
              "2330  C=CC1(C)CC(=O)C2(O)C(C)(O1)C(OC(C)=O)C(O)C1C(C...  Inactive\n",
              "2331  O=S(=O)([O-])c1cc(O)c2c(N=Nc3ccc(Nc4ccccc4)c4c...  Inactive\n",
              "2332                    Nc1ccc(S(=O)(=O)c2ccc(N)cc2)cc1  Inactive\n",
              "2333  Cc1cc(-c2ccc(N=Nc3ccc4c(S(=O)(=O)[O-])cc(S(=O)...  Inactive\n",
              "2334  C=Cc1c(C)c2cc3[nH]c(cc4nc(cc5[nH]c(cc1n2)c(C)c...  Inactive\n",
              "\n",
              "[2335 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkuPFGcc10Bu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c3752dc-2d60-4f25-bbb8-9bee9905621d"
      },
      "source": [
        "testing_set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SMILES</th>\n",
              "      <th>Activity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CO\\N=C(\\C(=O)NC1C2SCC(CSc3nnnn3C)=C(N2C1=O)C(O...</td>\n",
              "      <td>Active</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CC1Sc2c(C(O)=O)c(=O)c3cc(F)c(cc3n12)N1CCNCC1</td>\n",
              "      <td>Active</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CN(C)CCn1nnnc1SCC1=C(N2[C@H](SC1)[C@H](NC(=O)C...</td>\n",
              "      <td>Active</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CO\\N=C(/C(=O)N[C@H]1[C@H]2SCC(CSc3nc(=O)c(O)nn...</td>\n",
              "      <td>Active</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CNC1CCCN(C1)c1c(F)cc2c(c1OC)n(cc(C(O)=O)c2=O)C...</td>\n",
              "      <td>Active</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>C(Oc1ccccc1C1CC1)C1=NCCN1</td>\n",
              "      <td>Inactive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td>CCOc1ccc(NC(C)=Nc2ccc(OCC)cc2)cc1</td>\n",
              "      <td>Inactive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>CC[C@@H]1CN2C(=N1)c1[nH]c(nc1N(C)C2=O)-c1ccccc1</td>\n",
              "      <td>Inactive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>N=C(NNc1ccccc1)c1ccccc1</td>\n",
              "      <td>Inactive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>CS(=O)(=O)Nc1c(O)ccc2C(CCCc12)C1=NCCN1</td>\n",
              "      <td>Inactive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>162 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                SMILES  Activity\n",
              "0    CO\\N=C(\\C(=O)NC1C2SCC(CSc3nnnn3C)=C(N2C1=O)C(O...    Active\n",
              "1         CC1Sc2c(C(O)=O)c(=O)c3cc(F)c(cc3n12)N1CCNCC1    Active\n",
              "2    CN(C)CCn1nnnc1SCC1=C(N2[C@H](SC1)[C@H](NC(=O)C...    Active\n",
              "3    CO\\N=C(/C(=O)N[C@H]1[C@H]2SCC(CSc3nc(=O)c(O)nn...    Active\n",
              "4    CNC1CCCN(C1)c1c(F)cc2c(c1OC)n(cc(C(O)=O)c2=O)C...    Active\n",
              "..                                                 ...       ...\n",
              "157                          C(Oc1ccccc1C1CC1)C1=NCCN1  Inactive\n",
              "158                  CCOc1ccc(NC(C)=Nc2ccc(OCC)cc2)cc1  Inactive\n",
              "159    CC[C@@H]1CN2C(=N1)c1[nH]c(nc1N(C)C2=O)-c1ccccc1  Inactive\n",
              "160                            N=C(NNc1ccccc1)c1ccccc1  Inactive\n",
              "161             CS(=O)(=O)Nc1c(O)ccc2C(CCCc12)C1=NCCN1  Inactive\n",
              "\n",
              "[162 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3oUgJkmImkq"
      },
      "source": [
        "radius = 2\n",
        "num_bits = 2048\n",
        "\n",
        "training_x = np.array([convert_smiles_to_numpy(smiles, radius, num_bits) for smiles in training_set['SMILES']])\n",
        "x_test = np.array([convert_smiles_to_numpy(smiles, radius, num_bits) for smiles in testing_set['SMILES']])\n",
        "training_y = ((training_set['Activity'] == 'Active') * 1.0).to_numpy()\n",
        "y_test = ((testing_set['Activity'] == 'Active') * 1.0).to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSIrTCTw4C4_"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLVPpWRo4KtF"
      },
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(training_x, training_y, test_size=0.2, random_state=23)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAg3C9i8RceZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7784d5e-ceb9-43b5-f820-3cddb46ff099"
      },
      "source": [
        "print('Active train:', np.sum(y_train == 1))\n",
        "print('Inactive train:', np.sum(y_train == 0))\n",
        "print('Active val:', np.sum(y_val == 1))\n",
        "print('Inactive val:', np.sum(y_val == 0))\n",
        "print('Active test:', np.sum(y_test == 1))\n",
        "print('Inactive test:', np.sum(y_test == 0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Active train: 99\n",
            "Inactive train: 1769\n",
            "Active val: 21\n",
            "Inactive val: 446\n",
            "Active test: 53\n",
            "Inactive test: 109\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRP-FitX3fQr"
      },
      "source": [
        "# Dataset and Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVsJuKnY3eVV"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import time\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hPcu0IEW45c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f3d0f66-1c1b-4b95-aeda-ddd24d06561b"
      },
      "source": [
        "cuda = torch.cuda.is_available()\n",
        "device = torch.device('cuda' if cuda else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fh4lvHUk3We9"
      },
      "source": [
        "class MyMLPDataset(Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        self.X = torch.from_numpy(X)\n",
        "        self.Y = torch.from_numpy(Y)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        X = self.X[index].float()\n",
        "        Y = self.Y[index].long()\n",
        "        return X, Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpAvKCsxG13l"
      },
      "source": [
        "class MyTDNNDataset(Dataset):\n",
        "    def __init__(self, X, Y):\n",
        "        self.X = torch.from_numpy(X)\n",
        "        self.Y = torch.from_numpy(Y)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        X = self.X[index].unsqueeze(0).float()\n",
        "        Y = self.Y[index].long()\n",
        "        return X, Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WIyCZlb534Pq"
      },
      "source": [
        "def get_mlp_loader(train_data, train_labels, val_data, val_labels, test_data, test_labels, cuda, batch_size):\n",
        "    if cuda:\n",
        "        loader_args = dict(batch_size=batch_size, num_workers=16, pin_memory=True)\n",
        "    else:\n",
        "        loader_args = dict(batch_size=64)\n",
        "    train_dataset = MyMLPDataset(train_data, train_labels)\n",
        "    train_loader = DataLoader(train_dataset, shuffle=True, **loader_args)\n",
        "    val_dataset = MyMLPDataset(val_data, val_labels)\n",
        "    val_loader = DataLoader(val_dataset, shuffle=False, **loader_args)\n",
        "    test_dataset = MyMLPDataset(test_data, test_labels)\n",
        "    test_loader = DataLoader(test_dataset, shuffle=False, **loader_args)\n",
        "    return train_loader, val_loader, test_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88NFSbjBG-f3"
      },
      "source": [
        "def get_tdnn_loader(train_data, train_labels, val_data, val_labels, test_data, test_labels, cuda, batch_size):\n",
        "    if cuda:\n",
        "        loader_args = dict(batch_size=batch_size, num_workers=16, pin_memory=True)\n",
        "    else:\n",
        "        loader_args = dict(batch_size=64)\n",
        "    train_dataset = MyTDNNDataset(train_data, train_labels)\n",
        "    train_loader = DataLoader(train_dataset, shuffle=True, **loader_args)\n",
        "    val_dataset = MyTDNNDataset(val_data, val_labels)\n",
        "    val_loader = DataLoader(val_dataset, shuffle=False, **loader_args)\n",
        "    test_dataset = MyTDNNDataset(test_data, test_labels)\n",
        "    test_loader = DataLoader(test_dataset, shuffle=False, **loader_args)\n",
        "    return train_loader, val_loader, test_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ac60F9xNEqOK"
      },
      "source": [
        "# Training and Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7CT0OXpNbvP"
      },
      "source": [
        "def train(model, train_loader, optimizer, criterion, device, epoch, empty_cache=False):\n",
        "    start = time.time()\n",
        "    model.train()\n",
        "    avg_loss = 0.0\n",
        "    train_loss = []\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_num, (x, y) in enumerate(train_loader):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        output = model(x)\n",
        "        loss = criterion(output, y)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        avg_loss += loss.item()\n",
        "        train_loss.extend([loss.item()]*x.size()[0])\n",
        "\n",
        "        predicted = torch.max(output.data, 1)[1]\n",
        "        total += y.size(0)\n",
        "        correct += (predicted == y).sum().item()\n",
        "\n",
        "        if batch_num % 50 == 49:\n",
        "            print('Epoch: {}\\tBatch: {}\\tAvg-Loss: {:.4f}\\tElapsed Time: {:.4f}'.\n",
        "                  format(epoch+1, batch_num+1, avg_loss/50, time.time()-start))\n",
        "            avg_loss = 0.0    \n",
        "        \n",
        "        if empty_cache:\n",
        "            torch.cuda.empty_cache()\n",
        "            del x\n",
        "            del y\n",
        "            del loss\n",
        "        \n",
        "    end = time.time()\n",
        "    print('Epoch: {}\\tTraining Time: {:.4f}'.format(epoch+1, end-start))\n",
        "    return np.mean(train_loss), correct / total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjHmvO6bNbvR"
      },
      "source": [
        "def valid(model, val_loader, criterion, device, epoch, empty_cache=False):\n",
        "    start = time.time()\n",
        "    model.eval()\n",
        "    val_loss = []\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_num, (x, y) in enumerate(val_loader):\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            output = model(x)\n",
        "            \n",
        "            loss = criterion(output, y)\n",
        "            val_loss.extend([loss.item()]*x.size()[0])\n",
        "\n",
        "            predicted = torch.max(output.data, 1)[1]\n",
        "            total += y.size(0)\n",
        "            correct += (predicted == y).sum().item()\n",
        "\n",
        "            if empty_cache:\n",
        "                torch.cuda.empty_cache()\n",
        "                del x\n",
        "                del y\n",
        "                del loss\n",
        "    \n",
        "    model.train()\n",
        "    end = time.time()\n",
        "    if epoch is None:\n",
        "        print('Final Validation Time: {:.4f}'.format(end-start))\n",
        "    else:\n",
        "        print('Epoch: {}\\tValidation Time: {:.4f}'.format(epoch+1, end-start))\n",
        "    return np.mean(val_loss), correct / total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "90Q-75R2PFvh"
      },
      "source": [
        "def test(model, test_loader, device, empty_cache):\n",
        "    start = time.time()\n",
        "    model.eval()\n",
        "    predicted_test = []\n",
        "    with torch.no_grad():\n",
        "        for i, (x, y) in enumerate(test_loader):\n",
        "            x = x.to(device)\n",
        "            output = model(x)\n",
        "            predicted = torch.max(output.data, 1)[1]\n",
        "            predicted_test.extend(predicted.cpu().detach().numpy())\n",
        "            \n",
        "            if empty_cache:\n",
        "                torch.cuda.empty_cache()\n",
        "                del x\n",
        "    \n",
        "    end = time.time()\n",
        "    print('Testing Time: {:.4f}'.format(end-start))\n",
        "    return predicted_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zsD0NSjhNbvV"
      },
      "source": [
        "def train_model(model, model_name, train_loader, val_loader, optimizer, criterion, scheduler, device, start_epoch, num_epochs, train_losses, valid_losses, empty_cache=False):\n",
        "    for epoch in range(start_epoch, num_epochs):\n",
        "        print(\"Epoch: {}\\tLearning Rate: {}\".format(epoch+1, optimizer.param_groups[0]['lr']))\n",
        "        \n",
        "        train_loss, train_acc = train(model, train_loader, optimizer, criterion, device, epoch, empty_cache)\n",
        "        print('Epoch: {}\\tTrain Loss: {:.5f}\\tTrain Accuracy: {:.5f}'.format(epoch+1, train_loss, train_acc))\n",
        "        train_losses.append(train_loss)\n",
        "        \n",
        "        val_loss, val_acc = valid(model, val_loader, criterion, device, epoch, empty_cache)\n",
        "        print('Epoch: {}\\tVal Loss: {:.5f}\\tVal Accuracy: {:.5f}'.format(epoch+1, val_loss, val_acc))\n",
        "        valid_losses.append(val_loss)\n",
        "        \n",
        "        scheduler.step(val_loss)\n",
        "    \n",
        "    return train_losses, valid_losses"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ODPXV1BNbvX"
      },
      "source": [
        "def training_plot(a, b):\n",
        "    plt.figure(1)\n",
        "    plt.plot(a, 'b', label=\"train\")\n",
        "    plt.plot(b, 'g', label=\"valid\")\n",
        "    plt.title('Training/Valid Loss')\n",
        "    plt.legend()\n",
        "    plt.savefig('Loss Plot.png')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5rCSWuOEfLH"
      },
      "source": [
        "# Linear Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQ2Dhx7aEhp8"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPVRRKKUEnOk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a81331d-4b86-48dd-adee-12e5a6e13530"
      },
      "source": [
        "linear = make_pipeline(StandardScaler(), SGDClassifier(max_iter=1000, tol=1e-3))\n",
        "linear.fit(x_train, y_train)\n",
        "train_predict = linear.predict(x_train)\n",
        "train_acc = np.mean(train_predict == y_train)\n",
        "print('Train Accuracy: {:.5f}'.format(train_acc))\n",
        "val_predict = linear.predict(x_val)\n",
        "val_acc = np.mean(val_predict == y_val)\n",
        "print('Val Accuracy: {:.5f}'.format(val_acc))\n",
        "test_predict = linear.predict(x_test)\n",
        "test_acc = np.mean(test_predict == y_test)\n",
        "print('Test Accuracy: {:.5f}'.format(test_acc))\n",
        "auc = roc_auc_score(y_test, test_predict)\n",
        "print('AUC Score: {:.5f}'.format(auc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy: 0.99518\n",
            "Val Accuracy: 0.96788\n",
            "Test Accuracy: 0.71605\n",
            "AUC Score: 0.59997\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOFnYcKtLEHJ"
      },
      "source": [
        "# SVM Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nx5aO3NiLEHL"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0t0uOatLEHP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33c21358-3663-4696-e6ef-8432f4465634"
      },
      "source": [
        "svm = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
        "svm.fit(x_train, y_train)\n",
        "train_predict = svm.predict(x_train)\n",
        "train_acc = np.mean(train_predict == y_train)\n",
        "print('Train Accuracy: {:.5f}'.format(train_acc))\n",
        "val_predict = svm.predict(x_val)\n",
        "val_acc = np.mean(val_predict == y_val)\n",
        "print('Val Accuracy: {:.5f}'.format(val_acc))\n",
        "test_predict = svm.predict(x_test)\n",
        "test_acc = np.mean(test_predict == y_test)\n",
        "print('Test Accuracy: {:.5f}'.format(test_acc))\n",
        "auc = roc_auc_score(y_test, test_predict)\n",
        "print('AUC Score: {:.5f}'.format(auc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Accuracy: 0.97859\n",
            "Val Accuracy: 0.96146\n",
            "Test Accuracy: 0.72222\n",
            "AUC Score: 0.59486\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ca-s9wHj7VjR"
      },
      "source": [
        "# MLP Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRYiIUTI7h86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "451040a0-2324-469e-dedd-565a3f72d218"
      },
      "source": [
        "mlp = nn.Sequential(\n",
        "    nn.Linear(2048, 1024),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.BatchNorm1d(1024),\n",
        "    nn.Linear(1024, 512),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.BatchNorm1d(512),\n",
        "    nn.Linear(512, 256),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.BatchNorm1d(256),\n",
        "    nn.Linear(256, 128),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.BatchNorm1d(128),\n",
        "    nn.Linear(128, 2)\n",
        ")\n",
        "mlp.to(device)\n",
        "print(mlp)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (3): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (4): ReLU(inplace=True)\n",
            "  (5): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (6): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (7): ReLU(inplace=True)\n",
            "  (8): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (9): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (10): ReLU(inplace=True)\n",
            "  (11): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (12): Linear(in_features=128, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6fxnfhSp77cg"
      },
      "source": [
        "num_epochs = 100\n",
        "\n",
        "model_name = 'Simple_MLP'\n",
        "\n",
        "lr = 1e-3\n",
        "weight_decay = 5e-6\n",
        "\n",
        "start_epoch = 0\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "empty_cache = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fjQBCTF405m"
      },
      "source": [
        "batch_size = 64\n",
        "train_loader, val_loader, test_loader = get_mlp_loader(x_train, y_train, x_val, y_val, x_test, y_test, cuda, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_ppbD4173bS"
      },
      "source": [
        "optimizer = optim.Adam(mlp.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.8, patience=1, verbose=True)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-luNcCSJ8Cm3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "967d907b-fb7c-45a9-fbb1-c99ce6acdfa2"
      },
      "source": [
        "train_losses, valid_losses = train_model(mlp, model_name, train_loader, val_loader, optimizer, criterion, scheduler,\n",
        "                                         device, start_epoch, num_epochs, train_losses, valid_losses, empty_cache)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\tLearning Rate: 0.001\n",
            "Epoch: 1\tTraining Time: 0.8772\n",
            "Epoch: 1\tTrain Loss: 0.65151\tTrain Accuracy: 0.69700\n",
            "Epoch: 1\tValidation Time: 0.5354\n",
            "Epoch: 1\tVal Loss: 0.39697\tVal Accuracy: 0.97430\n",
            "Epoch: 2\tLearning Rate: 0.001\n",
            "Epoch: 2\tTraining Time: 0.7853\n",
            "Epoch: 2\tTrain Loss: 0.45070\tTrain Accuracy: 0.90418\n",
            "Epoch: 2\tValidation Time: 0.5376\n",
            "Epoch: 2\tVal Loss: 0.25869\tVal Accuracy: 0.96788\n",
            "Epoch: 3\tLearning Rate: 0.001\n",
            "Epoch: 3\tTraining Time: 0.7976\n",
            "Epoch: 3\tTrain Loss: 0.32381\tTrain Accuracy: 0.95182\n",
            "Epoch: 3\tValidation Time: 0.5396\n",
            "Epoch: 3\tVal Loss: 0.31176\tVal Accuracy: 0.96360\n",
            "Epoch: 4\tLearning Rate: 0.001\n",
            "Epoch: 4\tTraining Time: 0.7944\n",
            "Epoch: 4\tTrain Loss: 0.21414\tTrain Accuracy: 0.96788\n",
            "Epoch: 4\tValidation Time: 0.5529\n",
            "Epoch: 4\tVal Loss: 0.20038\tVal Accuracy: 0.95075\n",
            "Epoch: 5\tLearning Rate: 0.001\n",
            "Epoch: 5\tTraining Time: 0.8100\n",
            "Epoch: 5\tTrain Loss: 0.11662\tTrain Accuracy: 0.98287\n",
            "Epoch: 5\tValidation Time: 0.5581\n",
            "Epoch: 5\tVal Loss: 0.13393\tVal Accuracy: 0.97430\n",
            "Epoch: 6\tLearning Rate: 0.001\n",
            "Epoch: 6\tTraining Time: 0.8017\n",
            "Epoch: 6\tTrain Loss: 0.08819\tTrain Accuracy: 0.98019\n",
            "Epoch: 6\tValidation Time: 0.5431\n",
            "Epoch: 6\tVal Loss: 0.12532\tVal Accuracy: 0.97002\n",
            "Epoch: 7\tLearning Rate: 0.001\n",
            "Epoch: 7\tTraining Time: 0.8211\n",
            "Epoch: 7\tTrain Loss: 0.05895\tTrain Accuracy: 0.99143\n",
            "Epoch: 7\tValidation Time: 0.5394\n",
            "Epoch: 7\tVal Loss: 0.12171\tVal Accuracy: 0.97002\n",
            "Epoch: 8\tLearning Rate: 0.001\n",
            "Epoch: 8\tTraining Time: 0.7749\n",
            "Epoch: 8\tTrain Loss: 0.03601\tTrain Accuracy: 0.99197\n",
            "Epoch: 8\tValidation Time: 0.5453\n",
            "Epoch: 8\tVal Loss: 0.07858\tVal Accuracy: 0.97859\n",
            "Epoch: 9\tLearning Rate: 0.001\n",
            "Epoch: 9\tTraining Time: 0.7944\n",
            "Epoch: 9\tTrain Loss: 0.02697\tTrain Accuracy: 0.99518\n",
            "Epoch: 9\tValidation Time: 0.5341\n",
            "Epoch: 9\tVal Loss: 0.08517\tVal Accuracy: 0.97859\n",
            "Epoch: 10\tLearning Rate: 0.001\n",
            "Epoch: 10\tTraining Time: 0.7947\n",
            "Epoch: 10\tTrain Loss: 0.02383\tTrain Accuracy: 0.99732\n",
            "Epoch: 10\tValidation Time: 0.5604\n",
            "Epoch: 10\tVal Loss: 0.08698\tVal Accuracy: 0.97859\n",
            "Epoch    10: reducing learning rate of group 0 to 8.0000e-04.\n",
            "Epoch: 11\tLearning Rate: 0.0008\n",
            "Epoch: 11\tTraining Time: 0.7891\n",
            "Epoch: 11\tTrain Loss: 0.01419\tTrain Accuracy: 0.99786\n",
            "Epoch: 11\tValidation Time: 0.5584\n",
            "Epoch: 11\tVal Loss: 0.09332\tVal Accuracy: 0.97859\n",
            "Epoch: 12\tLearning Rate: 0.0008\n",
            "Epoch: 12\tTraining Time: 0.8110\n",
            "Epoch: 12\tTrain Loss: 0.01555\tTrain Accuracy: 0.99732\n",
            "Epoch: 12\tValidation Time: 0.5517\n",
            "Epoch: 12\tVal Loss: 0.09125\tVal Accuracy: 0.97859\n",
            "Epoch    12: reducing learning rate of group 0 to 6.4000e-04.\n",
            "Epoch: 13\tLearning Rate: 0.00064\n",
            "Epoch: 13\tTraining Time: 0.7875\n",
            "Epoch: 13\tTrain Loss: 0.01104\tTrain Accuracy: 0.99839\n",
            "Epoch: 13\tValidation Time: 0.5433\n",
            "Epoch: 13\tVal Loss: 0.09804\tVal Accuracy: 0.97430\n",
            "Epoch: 14\tLearning Rate: 0.00064\n",
            "Epoch: 14\tTraining Time: 0.8024\n",
            "Epoch: 14\tTrain Loss: 0.00810\tTrain Accuracy: 0.99946\n",
            "Epoch: 14\tValidation Time: 0.5452\n",
            "Epoch: 14\tVal Loss: 0.09143\tVal Accuracy: 0.98073\n",
            "Epoch    14: reducing learning rate of group 0 to 5.1200e-04.\n",
            "Epoch: 15\tLearning Rate: 0.0005120000000000001\n",
            "Epoch: 15\tTraining Time: 0.8281\n",
            "Epoch: 15\tTrain Loss: 0.00481\tTrain Accuracy: 1.00000\n",
            "Epoch: 15\tValidation Time: 0.5353\n",
            "Epoch: 15\tVal Loss: 0.09663\tVal Accuracy: 0.97645\n",
            "Epoch: 16\tLearning Rate: 0.0005120000000000001\n",
            "Epoch: 16\tTraining Time: 0.7965\n",
            "Epoch: 16\tTrain Loss: 0.00555\tTrain Accuracy: 0.99946\n",
            "Epoch: 16\tValidation Time: 0.5537\n",
            "Epoch: 16\tVal Loss: 0.09945\tVal Accuracy: 0.97859\n",
            "Epoch    16: reducing learning rate of group 0 to 4.0960e-04.\n",
            "Epoch: 17\tLearning Rate: 0.0004096000000000001\n",
            "Epoch: 17\tTraining Time: 0.8038\n",
            "Epoch: 17\tTrain Loss: 0.00683\tTrain Accuracy: 0.99893\n",
            "Epoch: 17\tValidation Time: 0.5533\n",
            "Epoch: 17\tVal Loss: 0.10751\tVal Accuracy: 0.97645\n",
            "Epoch: 18\tLearning Rate: 0.0004096000000000001\n",
            "Epoch: 18\tTraining Time: 0.7897\n",
            "Epoch: 18\tTrain Loss: 0.00656\tTrain Accuracy: 0.99946\n",
            "Epoch: 18\tValidation Time: 0.5487\n",
            "Epoch: 18\tVal Loss: 0.10558\tVal Accuracy: 0.97859\n",
            "Epoch    18: reducing learning rate of group 0 to 3.2768e-04.\n",
            "Epoch: 19\tLearning Rate: 0.0003276800000000001\n",
            "Epoch: 19\tTraining Time: 0.8105\n",
            "Epoch: 19\tTrain Loss: 0.00352\tTrain Accuracy: 1.00000\n",
            "Epoch: 19\tValidation Time: 0.5364\n",
            "Epoch: 19\tVal Loss: 0.10765\tVal Accuracy: 0.98073\n",
            "Epoch: 20\tLearning Rate: 0.0003276800000000001\n",
            "Epoch: 20\tTraining Time: 0.7768\n",
            "Epoch: 20\tTrain Loss: 0.00330\tTrain Accuracy: 1.00000\n",
            "Epoch: 20\tValidation Time: 0.5655\n",
            "Epoch: 20\tVal Loss: 0.10253\tVal Accuracy: 0.97859\n",
            "Epoch    20: reducing learning rate of group 0 to 2.6214e-04.\n",
            "Epoch: 21\tLearning Rate: 0.0002621440000000001\n",
            "Epoch: 21\tTraining Time: 0.8122\n",
            "Epoch: 21\tTrain Loss: 0.00367\tTrain Accuracy: 0.99946\n",
            "Epoch: 21\tValidation Time: 0.5355\n",
            "Epoch: 21\tVal Loss: 0.10299\tVal Accuracy: 0.97859\n",
            "Epoch: 22\tLearning Rate: 0.0002621440000000001\n",
            "Epoch: 22\tTraining Time: 0.7959\n",
            "Epoch: 22\tTrain Loss: 0.00857\tTrain Accuracy: 0.99893\n",
            "Epoch: 22\tValidation Time: 0.5445\n",
            "Epoch: 22\tVal Loss: 0.12753\tVal Accuracy: 0.97645\n",
            "Epoch    22: reducing learning rate of group 0 to 2.0972e-04.\n",
            "Epoch: 23\tLearning Rate: 0.00020971520000000012\n",
            "Epoch: 23\tTraining Time: 0.7789\n",
            "Epoch: 23\tTrain Loss: 0.00441\tTrain Accuracy: 0.99893\n",
            "Epoch: 23\tValidation Time: 0.5425\n",
            "Epoch: 23\tVal Loss: 0.12001\tVal Accuracy: 0.97859\n",
            "Epoch: 24\tLearning Rate: 0.00020971520000000012\n",
            "Epoch: 24\tTraining Time: 0.7751\n",
            "Epoch: 24\tTrain Loss: 0.00277\tTrain Accuracy: 1.00000\n",
            "Epoch: 24\tValidation Time: 0.5348\n",
            "Epoch: 24\tVal Loss: 0.10945\tVal Accuracy: 0.98073\n",
            "Epoch    24: reducing learning rate of group 0 to 1.6777e-04.\n",
            "Epoch: 25\tLearning Rate: 0.0001677721600000001\n",
            "Epoch: 25\tTraining Time: 0.8048\n",
            "Epoch: 25\tTrain Loss: 0.00283\tTrain Accuracy: 1.00000\n",
            "Epoch: 25\tValidation Time: 0.5552\n",
            "Epoch: 25\tVal Loss: 0.11341\tVal Accuracy: 0.97859\n",
            "Epoch: 26\tLearning Rate: 0.0001677721600000001\n",
            "Epoch: 26\tTraining Time: 0.7835\n",
            "Epoch: 26\tTrain Loss: 0.00259\tTrain Accuracy: 1.00000\n",
            "Epoch: 26\tValidation Time: 0.5383\n",
            "Epoch: 26\tVal Loss: 0.11049\tVal Accuracy: 0.97859\n",
            "Epoch    26: reducing learning rate of group 0 to 1.3422e-04.\n",
            "Epoch: 27\tLearning Rate: 0.00013421772800000008\n",
            "Epoch: 27\tTraining Time: 0.8118\n",
            "Epoch: 27\tTrain Loss: 0.00340\tTrain Accuracy: 0.99946\n",
            "Epoch: 27\tValidation Time: 0.5528\n",
            "Epoch: 27\tVal Loss: 0.11581\tVal Accuracy: 0.97859\n",
            "Epoch: 28\tLearning Rate: 0.00013421772800000008\n",
            "Epoch: 28\tTraining Time: 0.8295\n",
            "Epoch: 28\tTrain Loss: 0.00341\tTrain Accuracy: 0.99946\n",
            "Epoch: 28\tValidation Time: 0.5387\n",
            "Epoch: 28\tVal Loss: 0.11651\tVal Accuracy: 0.97645\n",
            "Epoch    28: reducing learning rate of group 0 to 1.0737e-04.\n",
            "Epoch: 29\tLearning Rate: 0.00010737418240000007\n",
            "Epoch: 29\tTraining Time: 0.7904\n",
            "Epoch: 29\tTrain Loss: 0.00235\tTrain Accuracy: 1.00000\n",
            "Epoch: 29\tValidation Time: 0.5488\n",
            "Epoch: 29\tVal Loss: 0.11984\tVal Accuracy: 0.97645\n",
            "Epoch: 30\tLearning Rate: 0.00010737418240000007\n",
            "Epoch: 30\tTraining Time: 0.7934\n",
            "Epoch: 30\tTrain Loss: 0.00227\tTrain Accuracy: 1.00000\n",
            "Epoch: 30\tValidation Time: 0.5621\n",
            "Epoch: 30\tVal Loss: 0.11952\tVal Accuracy: 0.97430\n",
            "Epoch    30: reducing learning rate of group 0 to 8.5899e-05.\n",
            "Epoch: 31\tLearning Rate: 8.589934592000007e-05\n",
            "Epoch: 31\tTraining Time: 0.8259\n",
            "Epoch: 31\tTrain Loss: 0.00255\tTrain Accuracy: 1.00000\n",
            "Epoch: 31\tValidation Time: 0.5478\n",
            "Epoch: 31\tVal Loss: 0.11842\tVal Accuracy: 0.97859\n",
            "Epoch: 32\tLearning Rate: 8.589934592000007e-05\n",
            "Epoch: 32\tTraining Time: 0.8038\n",
            "Epoch: 32\tTrain Loss: 0.00219\tTrain Accuracy: 1.00000\n",
            "Epoch: 32\tValidation Time: 0.5514\n",
            "Epoch: 32\tVal Loss: 0.11982\tVal Accuracy: 0.97645\n",
            "Epoch    32: reducing learning rate of group 0 to 6.8719e-05.\n",
            "Epoch: 33\tLearning Rate: 6.871947673600006e-05\n",
            "Epoch: 33\tTraining Time: 0.7878\n",
            "Epoch: 33\tTrain Loss: 0.00261\tTrain Accuracy: 1.00000\n",
            "Epoch: 33\tValidation Time: 0.5523\n",
            "Epoch: 33\tVal Loss: 0.11689\tVal Accuracy: 0.97859\n",
            "Epoch: 34\tLearning Rate: 6.871947673600006e-05\n",
            "Epoch: 34\tTraining Time: 0.8012\n",
            "Epoch: 34\tTrain Loss: 0.00306\tTrain Accuracy: 1.00000\n",
            "Epoch: 34\tValidation Time: 0.5536\n",
            "Epoch: 34\tVal Loss: 0.11878\tVal Accuracy: 0.97645\n",
            "Epoch    34: reducing learning rate of group 0 to 5.4976e-05.\n",
            "Epoch: 35\tLearning Rate: 5.497558138880005e-05\n",
            "Epoch: 35\tTraining Time: 0.8235\n",
            "Epoch: 35\tTrain Loss: 0.00215\tTrain Accuracy: 1.00000\n",
            "Epoch: 35\tValidation Time: 0.5547\n",
            "Epoch: 35\tVal Loss: 0.11107\tVal Accuracy: 0.97645\n",
            "Epoch: 36\tLearning Rate: 5.497558138880005e-05\n",
            "Epoch: 36\tTraining Time: 0.8210\n",
            "Epoch: 36\tTrain Loss: 0.00224\tTrain Accuracy: 1.00000\n",
            "Epoch: 36\tValidation Time: 0.5569\n",
            "Epoch: 36\tVal Loss: 0.11188\tVal Accuracy: 0.97859\n",
            "Epoch    36: reducing learning rate of group 0 to 4.3980e-05.\n",
            "Epoch: 37\tLearning Rate: 4.3980465111040044e-05\n",
            "Epoch: 37\tTraining Time: 0.7941\n",
            "Epoch: 37\tTrain Loss: 0.00221\tTrain Accuracy: 1.00000\n",
            "Epoch: 37\tValidation Time: 0.5412\n",
            "Epoch: 37\tVal Loss: 0.11076\tVal Accuracy: 0.97859\n",
            "Epoch: 38\tLearning Rate: 4.3980465111040044e-05\n",
            "Epoch: 38\tTraining Time: 0.8125\n",
            "Epoch: 38\tTrain Loss: 0.00195\tTrain Accuracy: 1.00000\n",
            "Epoch: 38\tValidation Time: 0.6209\n",
            "Epoch: 38\tVal Loss: 0.11504\tVal Accuracy: 0.97216\n",
            "Epoch    38: reducing learning rate of group 0 to 3.5184e-05.\n",
            "Epoch: 39\tLearning Rate: 3.5184372088832036e-05\n",
            "Epoch: 39\tTraining Time: 0.8221\n",
            "Epoch: 39\tTrain Loss: 0.00749\tTrain Accuracy: 0.99946\n",
            "Epoch: 39\tValidation Time: 0.5530\n",
            "Epoch: 39\tVal Loss: 0.11494\tVal Accuracy: 0.97645\n",
            "Epoch: 40\tLearning Rate: 3.5184372088832036e-05\n",
            "Epoch: 40\tTraining Time: 0.8701\n",
            "Epoch: 40\tTrain Loss: 0.00224\tTrain Accuracy: 1.00000\n",
            "Epoch: 40\tValidation Time: 0.5682\n",
            "Epoch: 40\tVal Loss: 0.12004\tVal Accuracy: 0.97430\n",
            "Epoch    40: reducing learning rate of group 0 to 2.8147e-05.\n",
            "Epoch: 41\tLearning Rate: 2.814749767106563e-05\n",
            "Epoch: 41\tTraining Time: 0.8509\n",
            "Epoch: 41\tTrain Loss: 0.00206\tTrain Accuracy: 1.00000\n",
            "Epoch: 41\tValidation Time: 0.5663\n",
            "Epoch: 41\tVal Loss: 0.11990\tVal Accuracy: 0.97645\n",
            "Epoch: 42\tLearning Rate: 2.814749767106563e-05\n",
            "Epoch: 42\tTraining Time: 0.8228\n",
            "Epoch: 42\tTrain Loss: 0.00223\tTrain Accuracy: 1.00000\n",
            "Epoch: 42\tValidation Time: 0.5692\n",
            "Epoch: 42\tVal Loss: 0.11745\tVal Accuracy: 0.98073\n",
            "Epoch    42: reducing learning rate of group 0 to 2.2518e-05.\n",
            "Epoch: 43\tLearning Rate: 2.2517998136852506e-05\n",
            "Epoch: 43\tTraining Time: 0.8137\n",
            "Epoch: 43\tTrain Loss: 0.00239\tTrain Accuracy: 1.00000\n",
            "Epoch: 43\tValidation Time: 0.5714\n",
            "Epoch: 43\tVal Loss: 0.11923\tVal Accuracy: 0.97645\n",
            "Epoch: 44\tLearning Rate: 2.2517998136852506e-05\n",
            "Epoch: 44\tTraining Time: 0.8197\n",
            "Epoch: 44\tTrain Loss: 0.00229\tTrain Accuracy: 1.00000\n",
            "Epoch: 44\tValidation Time: 0.5604\n",
            "Epoch: 44\tVal Loss: 0.11954\tVal Accuracy: 0.97430\n",
            "Epoch    44: reducing learning rate of group 0 to 1.8014e-05.\n",
            "Epoch: 45\tLearning Rate: 1.8014398509482006e-05\n",
            "Epoch: 45\tTraining Time: 0.8473\n",
            "Epoch: 45\tTrain Loss: 0.00244\tTrain Accuracy: 1.00000\n",
            "Epoch: 45\tValidation Time: 0.5622\n",
            "Epoch: 45\tVal Loss: 0.11873\tVal Accuracy: 0.97216\n",
            "Epoch: 46\tLearning Rate: 1.8014398509482006e-05\n",
            "Epoch: 46\tTraining Time: 0.8411\n",
            "Epoch: 46\tTrain Loss: 0.00221\tTrain Accuracy: 1.00000\n",
            "Epoch: 46\tValidation Time: 0.5573\n",
            "Epoch: 46\tVal Loss: 0.12218\tVal Accuracy: 0.97430\n",
            "Epoch    46: reducing learning rate of group 0 to 1.4412e-05.\n",
            "Epoch: 47\tLearning Rate: 1.4411518807585605e-05\n",
            "Epoch: 47\tTraining Time: 0.8346\n",
            "Epoch: 47\tTrain Loss: 0.00241\tTrain Accuracy: 1.00000\n",
            "Epoch: 47\tValidation Time: 0.5543\n",
            "Epoch: 47\tVal Loss: 0.11856\tVal Accuracy: 0.97645\n",
            "Epoch: 48\tLearning Rate: 1.4411518807585605e-05\n",
            "Epoch: 48\tTraining Time: 0.8081\n",
            "Epoch: 48\tTrain Loss: 0.00226\tTrain Accuracy: 1.00000\n",
            "Epoch: 48\tValidation Time: 0.5516\n",
            "Epoch: 48\tVal Loss: 0.12077\tVal Accuracy: 0.97430\n",
            "Epoch    48: reducing learning rate of group 0 to 1.1529e-05.\n",
            "Epoch: 49\tLearning Rate: 1.1529215046068485e-05\n",
            "Epoch: 49\tTraining Time: 0.7931\n",
            "Epoch: 49\tTrain Loss: 0.00221\tTrain Accuracy: 1.00000\n",
            "Epoch: 49\tValidation Time: 0.5589\n",
            "Epoch: 49\tVal Loss: 0.12049\tVal Accuracy: 0.97216\n",
            "Epoch: 50\tLearning Rate: 1.1529215046068485e-05\n",
            "Epoch: 50\tTraining Time: 0.8307\n",
            "Epoch: 50\tTrain Loss: 0.00249\tTrain Accuracy: 1.00000\n",
            "Epoch: 50\tValidation Time: 0.5557\n",
            "Epoch: 50\tVal Loss: 0.11835\tVal Accuracy: 0.97430\n",
            "Epoch    50: reducing learning rate of group 0 to 9.2234e-06.\n",
            "Epoch: 51\tLearning Rate: 9.223372036854789e-06\n",
            "Epoch: 51\tTraining Time: 0.8376\n",
            "Epoch: 51\tTrain Loss: 0.00216\tTrain Accuracy: 1.00000\n",
            "Epoch: 51\tValidation Time: 0.5415\n",
            "Epoch: 51\tVal Loss: 0.12297\tVal Accuracy: 0.97430\n",
            "Epoch: 52\tLearning Rate: 9.223372036854789e-06\n",
            "Epoch: 52\tTraining Time: 0.8064\n",
            "Epoch: 52\tTrain Loss: 0.00238\tTrain Accuracy: 1.00000\n",
            "Epoch: 52\tValidation Time: 0.5423\n",
            "Epoch: 52\tVal Loss: 0.12631\tVal Accuracy: 0.97216\n",
            "Epoch    52: reducing learning rate of group 0 to 7.3787e-06.\n",
            "Epoch: 53\tLearning Rate: 7.378697629483831e-06\n",
            "Epoch: 53\tTraining Time: 0.7862\n",
            "Epoch: 53\tTrain Loss: 0.00221\tTrain Accuracy: 1.00000\n",
            "Epoch: 53\tValidation Time: 0.5388\n",
            "Epoch: 53\tVal Loss: 0.11642\tVal Accuracy: 0.97645\n",
            "Epoch: 54\tLearning Rate: 7.378697629483831e-06\n",
            "Epoch: 54\tTraining Time: 0.7695\n",
            "Epoch: 54\tTrain Loss: 0.00224\tTrain Accuracy: 1.00000\n",
            "Epoch: 54\tValidation Time: 0.5282\n",
            "Epoch: 54\tVal Loss: 0.12045\tVal Accuracy: 0.97430\n",
            "Epoch    54: reducing learning rate of group 0 to 5.9030e-06.\n",
            "Epoch: 55\tLearning Rate: 5.902958103587065e-06\n",
            "Epoch: 55\tTraining Time: 0.8091\n",
            "Epoch: 55\tTrain Loss: 0.00221\tTrain Accuracy: 1.00000\n",
            "Epoch: 55\tValidation Time: 0.5784\n",
            "Epoch: 55\tVal Loss: 0.11807\tVal Accuracy: 0.98073\n",
            "Epoch: 56\tLearning Rate: 5.902958103587065e-06\n",
            "Epoch: 56\tTraining Time: 0.8069\n",
            "Epoch: 56\tTrain Loss: 0.00216\tTrain Accuracy: 1.00000\n",
            "Epoch: 56\tValidation Time: 0.5579\n",
            "Epoch: 56\tVal Loss: 0.12385\tVal Accuracy: 0.97216\n",
            "Epoch    56: reducing learning rate of group 0 to 4.7224e-06.\n",
            "Epoch: 57\tLearning Rate: 4.722366482869652e-06\n",
            "Epoch: 57\tTraining Time: 0.8209\n",
            "Epoch: 57\tTrain Loss: 0.00197\tTrain Accuracy: 1.00000\n",
            "Epoch: 57\tValidation Time: 0.5389\n",
            "Epoch: 57\tVal Loss: 0.12690\tVal Accuracy: 0.97216\n",
            "Epoch: 58\tLearning Rate: 4.722366482869652e-06\n",
            "Epoch: 58\tTraining Time: 0.7643\n",
            "Epoch: 58\tTrain Loss: 0.00240\tTrain Accuracy: 1.00000\n",
            "Epoch: 58\tValidation Time: 0.5385\n",
            "Epoch: 58\tVal Loss: 0.12277\tVal Accuracy: 0.97645\n",
            "Epoch    58: reducing learning rate of group 0 to 3.7779e-06.\n",
            "Epoch: 59\tLearning Rate: 3.777893186295722e-06\n",
            "Epoch: 59\tTraining Time: 0.8360\n",
            "Epoch: 59\tTrain Loss: 0.00192\tTrain Accuracy: 1.00000\n",
            "Epoch: 59\tValidation Time: 0.5507\n",
            "Epoch: 59\tVal Loss: 0.12253\tVal Accuracy: 0.97430\n",
            "Epoch: 60\tLearning Rate: 3.777893186295722e-06\n",
            "Epoch: 60\tTraining Time: 0.8015\n",
            "Epoch: 60\tTrain Loss: 0.00202\tTrain Accuracy: 1.00000\n",
            "Epoch: 60\tValidation Time: 0.5437\n",
            "Epoch: 60\tVal Loss: 0.12415\tVal Accuracy: 0.97430\n",
            "Epoch    60: reducing learning rate of group 0 to 3.0223e-06.\n",
            "Epoch: 61\tLearning Rate: 3.022314549036578e-06\n",
            "Epoch: 61\tTraining Time: 0.8127\n",
            "Epoch: 61\tTrain Loss: 0.00201\tTrain Accuracy: 1.00000\n",
            "Epoch: 61\tValidation Time: 0.5372\n",
            "Epoch: 61\tVal Loss: 0.11889\tVal Accuracy: 0.97430\n",
            "Epoch: 62\tLearning Rate: 3.022314549036578e-06\n",
            "Epoch: 62\tTraining Time: 0.8068\n",
            "Epoch: 62\tTrain Loss: 0.00219\tTrain Accuracy: 1.00000\n",
            "Epoch: 62\tValidation Time: 0.5396\n",
            "Epoch: 62\tVal Loss: 0.12150\tVal Accuracy: 0.97216\n",
            "Epoch    62: reducing learning rate of group 0 to 2.4179e-06.\n",
            "Epoch: 63\tLearning Rate: 2.4178516392292624e-06\n",
            "Epoch: 63\tTraining Time: 0.7892\n",
            "Epoch: 63\tTrain Loss: 0.00206\tTrain Accuracy: 1.00000\n",
            "Epoch: 63\tValidation Time: 0.5370\n",
            "Epoch: 63\tVal Loss: 0.12251\tVal Accuracy: 0.97216\n",
            "Epoch: 64\tLearning Rate: 2.4178516392292624e-06\n",
            "Epoch: 64\tTraining Time: 0.7867\n",
            "Epoch: 64\tTrain Loss: 0.00191\tTrain Accuracy: 1.00000\n",
            "Epoch: 64\tValidation Time: 0.5389\n",
            "Epoch: 64\tVal Loss: 0.12729\tVal Accuracy: 0.97430\n",
            "Epoch    64: reducing learning rate of group 0 to 1.9343e-06.\n",
            "Epoch: 65\tLearning Rate: 1.93428131138341e-06\n",
            "Epoch: 65\tTraining Time: 0.7809\n",
            "Epoch: 65\tTrain Loss: 0.00195\tTrain Accuracy: 1.00000\n",
            "Epoch: 65\tValidation Time: 0.5412\n",
            "Epoch: 65\tVal Loss: 0.12000\tVal Accuracy: 0.97430\n",
            "Epoch: 66\tLearning Rate: 1.93428131138341e-06\n",
            "Epoch: 66\tTraining Time: 0.7974\n",
            "Epoch: 66\tTrain Loss: 0.00200\tTrain Accuracy: 1.00000\n",
            "Epoch: 66\tValidation Time: 0.5410\n",
            "Epoch: 66\tVal Loss: 0.11947\tVal Accuracy: 0.97430\n",
            "Epoch    66: reducing learning rate of group 0 to 1.5474e-06.\n",
            "Epoch: 67\tLearning Rate: 1.547425049106728e-06\n",
            "Epoch: 67\tTraining Time: 0.7750\n",
            "Epoch: 67\tTrain Loss: 0.00234\tTrain Accuracy: 1.00000\n",
            "Epoch: 67\tValidation Time: 0.5318\n",
            "Epoch: 67\tVal Loss: 0.12392\tVal Accuracy: 0.97430\n",
            "Epoch: 68\tLearning Rate: 1.547425049106728e-06\n",
            "Epoch: 68\tTraining Time: 0.7736\n",
            "Epoch: 68\tTrain Loss: 0.00234\tTrain Accuracy: 1.00000\n",
            "Epoch: 68\tValidation Time: 0.5436\n",
            "Epoch: 68\tVal Loss: 0.12099\tVal Accuracy: 0.97645\n",
            "Epoch    68: reducing learning rate of group 0 to 1.2379e-06.\n",
            "Epoch: 69\tLearning Rate: 1.2379400392853825e-06\n",
            "Epoch: 69\tTraining Time: 0.7810\n",
            "Epoch: 69\tTrain Loss: 0.00206\tTrain Accuracy: 1.00000\n",
            "Epoch: 69\tValidation Time: 0.5533\n",
            "Epoch: 69\tVal Loss: 0.12230\tVal Accuracy: 0.97430\n",
            "Epoch: 70\tLearning Rate: 1.2379400392853825e-06\n",
            "Epoch: 70\tTraining Time: 0.7869\n",
            "Epoch: 70\tTrain Loss: 0.00252\tTrain Accuracy: 1.00000\n",
            "Epoch: 70\tValidation Time: 0.5498\n",
            "Epoch: 70\tVal Loss: 0.11995\tVal Accuracy: 0.97430\n",
            "Epoch    70: reducing learning rate of group 0 to 9.9035e-07.\n",
            "Epoch: 71\tLearning Rate: 9.90352031428306e-07\n",
            "Epoch: 71\tTraining Time: 0.7870\n",
            "Epoch: 71\tTrain Loss: 0.00214\tTrain Accuracy: 1.00000\n",
            "Epoch: 71\tValidation Time: 0.5386\n",
            "Epoch: 71\tVal Loss: 0.11947\tVal Accuracy: 0.97430\n",
            "Epoch: 72\tLearning Rate: 9.90352031428306e-07\n",
            "Epoch: 72\tTraining Time: 0.8287\n",
            "Epoch: 72\tTrain Loss: 0.00188\tTrain Accuracy: 1.00000\n",
            "Epoch: 72\tValidation Time: 0.5427\n",
            "Epoch: 72\tVal Loss: 0.12166\tVal Accuracy: 0.97430\n",
            "Epoch    72: reducing learning rate of group 0 to 7.9228e-07.\n",
            "Epoch: 73\tLearning Rate: 7.922816251426449e-07\n",
            "Epoch: 73\tTraining Time: 0.8094\n",
            "Epoch: 73\tTrain Loss: 0.00209\tTrain Accuracy: 1.00000\n",
            "Epoch: 73\tValidation Time: 0.5549\n",
            "Epoch: 73\tVal Loss: 0.11875\tVal Accuracy: 0.97645\n",
            "Epoch: 74\tLearning Rate: 7.922816251426449e-07\n",
            "Epoch: 74\tTraining Time: 0.8369\n",
            "Epoch: 74\tTrain Loss: 0.00252\tTrain Accuracy: 1.00000\n",
            "Epoch: 74\tValidation Time: 0.5563\n",
            "Epoch: 74\tVal Loss: 0.12299\tVal Accuracy: 0.97430\n",
            "Epoch    74: reducing learning rate of group 0 to 6.3383e-07.\n",
            "Epoch: 75\tLearning Rate: 6.338253001141159e-07\n",
            "Epoch: 75\tTraining Time: 0.7915\n",
            "Epoch: 75\tTrain Loss: 0.00202\tTrain Accuracy: 1.00000\n",
            "Epoch: 75\tValidation Time: 0.5455\n",
            "Epoch: 75\tVal Loss: 0.11849\tVal Accuracy: 0.97645\n",
            "Epoch: 76\tLearning Rate: 6.338253001141159e-07\n",
            "Epoch: 76\tTraining Time: 0.7943\n",
            "Epoch: 76\tTrain Loss: 0.00200\tTrain Accuracy: 1.00000\n",
            "Epoch: 76\tValidation Time: 0.5496\n",
            "Epoch: 76\tVal Loss: 0.12083\tVal Accuracy: 0.97216\n",
            "Epoch    76: reducing learning rate of group 0 to 5.0706e-07.\n",
            "Epoch: 77\tLearning Rate: 5.070602400912927e-07\n",
            "Epoch: 77\tTraining Time: 0.7857\n",
            "Epoch: 77\tTrain Loss: 0.00245\tTrain Accuracy: 1.00000\n",
            "Epoch: 77\tValidation Time: 0.5375\n",
            "Epoch: 77\tVal Loss: 0.12492\tVal Accuracy: 0.97216\n",
            "Epoch: 78\tLearning Rate: 5.070602400912927e-07\n",
            "Epoch: 78\tTraining Time: 0.7997\n",
            "Epoch: 78\tTrain Loss: 0.00223\tTrain Accuracy: 1.00000\n",
            "Epoch: 78\tValidation Time: 0.5358\n",
            "Epoch: 78\tVal Loss: 0.11993\tVal Accuracy: 0.97645\n",
            "Epoch    78: reducing learning rate of group 0 to 4.0565e-07.\n",
            "Epoch: 79\tLearning Rate: 4.0564819207303424e-07\n",
            "Epoch: 79\tTraining Time: 0.7840\n",
            "Epoch: 79\tTrain Loss: 0.00198\tTrain Accuracy: 1.00000\n",
            "Epoch: 79\tValidation Time: 0.5479\n",
            "Epoch: 79\tVal Loss: 0.12177\tVal Accuracy: 0.97430\n",
            "Epoch: 80\tLearning Rate: 4.0564819207303424e-07\n",
            "Epoch: 80\tTraining Time: 0.7932\n",
            "Epoch: 80\tTrain Loss: 0.00214\tTrain Accuracy: 1.00000\n",
            "Epoch: 80\tValidation Time: 0.5479\n",
            "Epoch: 80\tVal Loss: 0.11626\tVal Accuracy: 0.97859\n",
            "Epoch    80: reducing learning rate of group 0 to 3.2452e-07.\n",
            "Epoch: 81\tLearning Rate: 3.245185536584274e-07\n",
            "Epoch: 81\tTraining Time: 0.8355\n",
            "Epoch: 81\tTrain Loss: 0.00223\tTrain Accuracy: 1.00000\n",
            "Epoch: 81\tValidation Time: 0.5376\n",
            "Epoch: 81\tVal Loss: 0.12810\tVal Accuracy: 0.97430\n",
            "Epoch: 82\tLearning Rate: 3.245185536584274e-07\n",
            "Epoch: 82\tTraining Time: 0.7887\n",
            "Epoch: 82\tTrain Loss: 0.00188\tTrain Accuracy: 1.00000\n",
            "Epoch: 82\tValidation Time: 0.5855\n",
            "Epoch: 82\tVal Loss: 0.12221\tVal Accuracy: 0.97430\n",
            "Epoch    82: reducing learning rate of group 0 to 2.5961e-07.\n",
            "Epoch: 83\tLearning Rate: 2.5961484292674195e-07\n",
            "Epoch: 83\tTraining Time: 0.7966\n",
            "Epoch: 83\tTrain Loss: 0.00225\tTrain Accuracy: 1.00000\n",
            "Epoch: 83\tValidation Time: 0.5385\n",
            "Epoch: 83\tVal Loss: 0.12234\tVal Accuracy: 0.97216\n",
            "Epoch: 84\tLearning Rate: 2.5961484292674195e-07\n",
            "Epoch: 84\tTraining Time: 0.7922\n",
            "Epoch: 84\tTrain Loss: 0.00218\tTrain Accuracy: 1.00000\n",
            "Epoch: 84\tValidation Time: 0.5456\n",
            "Epoch: 84\tVal Loss: 0.11881\tVal Accuracy: 0.97430\n",
            "Epoch    84: reducing learning rate of group 0 to 2.0769e-07.\n",
            "Epoch: 85\tLearning Rate: 2.0769187434139356e-07\n",
            "Epoch: 85\tTraining Time: 0.7962\n",
            "Epoch: 85\tTrain Loss: 0.00247\tTrain Accuracy: 1.00000\n",
            "Epoch: 85\tValidation Time: 0.5427\n",
            "Epoch: 85\tVal Loss: 0.11982\tVal Accuracy: 0.97645\n",
            "Epoch: 86\tLearning Rate: 2.0769187434139356e-07\n",
            "Epoch: 86\tTraining Time: 0.7915\n",
            "Epoch: 86\tTrain Loss: 0.00211\tTrain Accuracy: 1.00000\n",
            "Epoch: 86\tValidation Time: 0.5429\n",
            "Epoch: 86\tVal Loss: 0.11938\tVal Accuracy: 0.97430\n",
            "Epoch    86: reducing learning rate of group 0 to 1.6615e-07.\n",
            "Epoch: 87\tLearning Rate: 1.6615349947311486e-07\n",
            "Epoch: 87\tTraining Time: 0.8197\n",
            "Epoch: 87\tTrain Loss: 0.00248\tTrain Accuracy: 1.00000\n",
            "Epoch: 87\tValidation Time: 0.5514\n",
            "Epoch: 87\tVal Loss: 0.11894\tVal Accuracy: 0.97645\n",
            "Epoch: 88\tLearning Rate: 1.6615349947311486e-07\n",
            "Epoch: 88\tTraining Time: 0.8064\n",
            "Epoch: 88\tTrain Loss: 0.00186\tTrain Accuracy: 1.00000\n",
            "Epoch: 88\tValidation Time: 0.5614\n",
            "Epoch: 88\tVal Loss: 0.11820\tVal Accuracy: 0.97645\n",
            "Epoch    88: reducing learning rate of group 0 to 1.3292e-07.\n",
            "Epoch: 89\tLearning Rate: 1.329227995784919e-07\n",
            "Epoch: 89\tTraining Time: 0.7890\n",
            "Epoch: 89\tTrain Loss: 0.00196\tTrain Accuracy: 1.00000\n",
            "Epoch: 89\tValidation Time: 0.5478\n",
            "Epoch: 89\tVal Loss: 0.12088\tVal Accuracy: 0.97430\n",
            "Epoch: 90\tLearning Rate: 1.329227995784919e-07\n",
            "Epoch: 90\tTraining Time: 0.8086\n",
            "Epoch: 90\tTrain Loss: 0.00212\tTrain Accuracy: 1.00000\n",
            "Epoch: 90\tValidation Time: 0.5512\n",
            "Epoch: 90\tVal Loss: 0.12596\tVal Accuracy: 0.97216\n",
            "Epoch    90: reducing learning rate of group 0 to 1.0634e-07.\n",
            "Epoch: 91\tLearning Rate: 1.0633823966279352e-07\n",
            "Epoch: 91\tTraining Time: 0.8166\n",
            "Epoch: 91\tTrain Loss: 0.00241\tTrain Accuracy: 1.00000\n",
            "Epoch: 91\tValidation Time: 0.5498\n",
            "Epoch: 91\tVal Loss: 0.12136\tVal Accuracy: 0.97430\n",
            "Epoch: 92\tLearning Rate: 1.0633823966279352e-07\n",
            "Epoch: 92\tTraining Time: 0.8154\n",
            "Epoch: 92\tTrain Loss: 0.00229\tTrain Accuracy: 1.00000\n",
            "Epoch: 92\tValidation Time: 0.5429\n",
            "Epoch: 92\tVal Loss: 0.12315\tVal Accuracy: 0.97216\n",
            "Epoch    92: reducing learning rate of group 0 to 8.5071e-08.\n",
            "Epoch: 93\tLearning Rate: 8.507059173023481e-08\n",
            "Epoch: 93\tTraining Time: 0.8005\n",
            "Epoch: 93\tTrain Loss: 0.00240\tTrain Accuracy: 1.00000\n",
            "Epoch: 93\tValidation Time: 0.5399\n",
            "Epoch: 93\tVal Loss: 0.11881\tVal Accuracy: 0.97645\n",
            "Epoch: 94\tLearning Rate: 8.507059173023481e-08\n",
            "Epoch: 94\tTraining Time: 0.8299\n",
            "Epoch: 94\tTrain Loss: 0.00217\tTrain Accuracy: 1.00000\n",
            "Epoch: 94\tValidation Time: 0.5399\n",
            "Epoch: 94\tVal Loss: 0.11899\tVal Accuracy: 0.97645\n",
            "Epoch    94: reducing learning rate of group 0 to 6.8056e-08.\n",
            "Epoch: 95\tLearning Rate: 6.805647338418785e-08\n",
            "Epoch: 95\tTraining Time: 0.7844\n",
            "Epoch: 95\tTrain Loss: 0.00219\tTrain Accuracy: 1.00000\n",
            "Epoch: 95\tValidation Time: 0.5442\n",
            "Epoch: 95\tVal Loss: 0.11879\tVal Accuracy: 0.97430\n",
            "Epoch: 96\tLearning Rate: 6.805647338418785e-08\n",
            "Epoch: 96\tTraining Time: 0.8026\n",
            "Epoch: 96\tTrain Loss: 0.00234\tTrain Accuracy: 1.00000\n",
            "Epoch: 96\tValidation Time: 0.5425\n",
            "Epoch: 96\tVal Loss: 0.12485\tVal Accuracy: 0.97216\n",
            "Epoch    96: reducing learning rate of group 0 to 5.4445e-08.\n",
            "Epoch: 97\tLearning Rate: 5.4445178707350285e-08\n",
            "Epoch: 97\tTraining Time: 0.7883\n",
            "Epoch: 97\tTrain Loss: 0.00212\tTrain Accuracy: 1.00000\n",
            "Epoch: 97\tValidation Time: 0.5391\n",
            "Epoch: 97\tVal Loss: 0.11869\tVal Accuracy: 0.97430\n",
            "Epoch: 98\tLearning Rate: 5.4445178707350285e-08\n",
            "Epoch: 98\tTraining Time: 0.7863\n",
            "Epoch: 98\tTrain Loss: 0.00201\tTrain Accuracy: 1.00000\n",
            "Epoch: 98\tValidation Time: 0.5393\n",
            "Epoch: 98\tVal Loss: 0.12193\tVal Accuracy: 0.97216\n",
            "Epoch    98: reducing learning rate of group 0 to 4.3556e-08.\n",
            "Epoch: 99\tLearning Rate: 4.355614296588023e-08\n",
            "Epoch: 99\tTraining Time: 0.8267\n",
            "Epoch: 99\tTrain Loss: 0.00206\tTrain Accuracy: 1.00000\n",
            "Epoch: 99\tValidation Time: 0.5428\n",
            "Epoch: 99\tVal Loss: 0.12173\tVal Accuracy: 0.97645\n",
            "Epoch: 100\tLearning Rate: 4.355614296588023e-08\n",
            "Epoch: 100\tTraining Time: 0.8036\n",
            "Epoch: 100\tTrain Loss: 0.00210\tTrain Accuracy: 1.00000\n",
            "Epoch: 100\tValidation Time: 0.5392\n",
            "Epoch: 100\tVal Loss: 0.12081\tVal Accuracy: 0.97430\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "do5qo5jITG3w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "474cdf28-f8fa-4f5c-d2ff-fad6c78710f4"
      },
      "source": [
        "training_plot(train_losses, valid_losses)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBcRRp9OAkDa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7734400e-a31c-4cd6-cfc8-0f9fd298aa84"
      },
      "source": [
        "test_loss, test_acc = valid(mlp, test_loader, criterion, device, None, empty_cache)\n",
        "print('Test Loss: {:.5f}\\tTest Accuracy: {:.5f}'.format(test_loss, test_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final Validation Time: 0.5428\n",
            "Test Loss: 1.62900\tTest Accuracy: 0.84568\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OruVdrzvNrnZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c28e1050-35c0-4f57-f3f5-5c72dc086683"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "test_predict = test(mlp, test_loader, device, empty_cache)\n",
        "auc = roc_auc_score(y_test, test_predict)\n",
        "print('AUC Score: {:.5f}'.format(auc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing Time: 0.5258\n",
            "AUC Score: 0.81262\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQMIc-ge_NCP"
      },
      "source": [
        "# TDNN With Padding Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dL93xh0U_S_h",
        "outputId": "fd4fd998-2966-4e51-997e-41e574b5acfa"
      },
      "source": [
        "tdnn = nn.Sequential(\n",
        "    nn.Conv1d(in_channels=1, out_channels=1, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Conv1d(in_channels=1, out_channels=1, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Conv1d(in_channels=1, out_channels=1, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Conv1d(in_channels=1, out_channels=1, kernel_size=3, stride=2, padding=1),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(128, 2)\n",
        ")\n",
        "tdnn.to(device)\n",
        "print(tdnn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Conv1d(1, 1, kernel_size=(3,), stride=(2,), padding=(1,))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): Conv1d(1, 1, kernel_size=(3,), stride=(2,), padding=(1,))\n",
            "  (3): ReLU(inplace=True)\n",
            "  (4): Conv1d(1, 1, kernel_size=(3,), stride=(2,), padding=(1,))\n",
            "  (5): ReLU(inplace=True)\n",
            "  (6): Conv1d(1, 1, kernel_size=(3,), stride=(2,), padding=(1,))\n",
            "  (7): ReLU(inplace=True)\n",
            "  (8): Flatten(start_dim=1, end_dim=-1)\n",
            "  (9): Linear(in_features=128, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lNw_XcAGdKE"
      },
      "source": [
        "num_epochs = 100\n",
        "\n",
        "model_name = 'Simple_TDNN'\n",
        "\n",
        "lr = 1e-3\n",
        "weight_decay = 5e-6\n",
        "\n",
        "start_epoch = 0\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "empty_cache = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCmiJil4HRl1"
      },
      "source": [
        "batch_size = 64\n",
        "train_loader, val_loader, test_loader = get_tdnn_loader(x_train, y_train, x_val, y_val, x_test, y_test, cuda, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLzfjw9PGdKE"
      },
      "source": [
        "optimizer = optim.Adam(tdnn.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.8, patience=1, verbose=True)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlfijYMJGdKE",
        "outputId": "c6fdeba7-1b94-4dc6-8a1b-9df1526c855f"
      },
      "source": [
        "train_losses, valid_losses = train_model(tdnn, model_name, train_loader, val_loader, optimizer, criterion, scheduler,\n",
        "                                         device, start_epoch, num_epochs, train_losses, valid_losses, empty_cache)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\tLearning Rate: 0.001\n",
            "Epoch: 1\tTraining Time: 0.9052\n",
            "Epoch: 1\tTrain Loss: 0.64154\tTrain Accuracy: 0.94700\n",
            "Epoch: 1\tValidation Time: 0.5434\n",
            "Epoch: 1\tVal Loss: 0.62718\tVal Accuracy: 0.95503\n",
            "Epoch: 2\tLearning Rate: 0.001\n",
            "Epoch: 2\tTraining Time: 0.8859\n",
            "Epoch: 2\tTrain Loss: 0.61714\tTrain Accuracy: 0.94700\n",
            "Epoch: 2\tValidation Time: 0.5565\n",
            "Epoch: 2\tVal Loss: 0.60307\tVal Accuracy: 0.95503\n",
            "Epoch: 3\tLearning Rate: 0.001\n",
            "Epoch: 3\tTraining Time: 0.8901\n",
            "Epoch: 3\tTrain Loss: 0.59402\tTrain Accuracy: 0.94700\n",
            "Epoch: 3\tValidation Time: 0.5519\n",
            "Epoch: 3\tVal Loss: 0.58015\tVal Accuracy: 0.95503\n",
            "Epoch: 4\tLearning Rate: 0.001\n",
            "Epoch: 4\tTraining Time: 0.9044\n",
            "Epoch: 4\tTrain Loss: 0.57223\tTrain Accuracy: 0.94700\n",
            "Epoch: 4\tValidation Time: 0.5447\n",
            "Epoch: 4\tVal Loss: 0.55836\tVal Accuracy: 0.95503\n",
            "Epoch: 5\tLearning Rate: 0.001\n",
            "Epoch: 5\tTraining Time: 0.8882\n",
            "Epoch: 5\tTrain Loss: 0.55155\tTrain Accuracy: 0.94700\n",
            "Epoch: 5\tValidation Time: 0.5461\n",
            "Epoch: 5\tVal Loss: 0.53806\tVal Accuracy: 0.95503\n",
            "Epoch: 6\tLearning Rate: 0.001\n",
            "Epoch: 6\tTraining Time: 0.8953\n",
            "Epoch: 6\tTrain Loss: 0.53214\tTrain Accuracy: 0.94700\n",
            "Epoch: 6\tValidation Time: 0.5405\n",
            "Epoch: 6\tVal Loss: 0.51875\tVal Accuracy: 0.95503\n",
            "Epoch: 7\tLearning Rate: 0.001\n",
            "Epoch: 7\tTraining Time: 0.8887\n",
            "Epoch: 7\tTrain Loss: 0.51372\tTrain Accuracy: 0.94700\n",
            "Epoch: 7\tValidation Time: 0.5573\n",
            "Epoch: 7\tVal Loss: 0.50041\tVal Accuracy: 0.95503\n",
            "Epoch: 8\tLearning Rate: 0.001\n",
            "Epoch: 8\tTraining Time: 0.8732\n",
            "Epoch: 8\tTrain Loss: 0.49637\tTrain Accuracy: 0.94700\n",
            "Epoch: 8\tValidation Time: 0.5494\n",
            "Epoch: 8\tVal Loss: 0.48319\tVal Accuracy: 0.95503\n",
            "Epoch: 9\tLearning Rate: 0.001\n",
            "Epoch: 9\tTraining Time: 0.8871\n",
            "Epoch: 9\tTrain Loss: 0.48005\tTrain Accuracy: 0.94700\n",
            "Epoch: 9\tValidation Time: 0.5504\n",
            "Epoch: 9\tVal Loss: 0.46686\tVal Accuracy: 0.95503\n",
            "Epoch: 10\tLearning Rate: 0.001\n",
            "Epoch: 10\tTraining Time: 0.8789\n",
            "Epoch: 10\tTrain Loss: 0.46458\tTrain Accuracy: 0.94700\n",
            "Epoch: 10\tValidation Time: 0.5608\n",
            "Epoch: 10\tVal Loss: 0.45156\tVal Accuracy: 0.95503\n",
            "Epoch: 11\tLearning Rate: 0.001\n",
            "Epoch: 11\tTraining Time: 0.8817\n",
            "Epoch: 11\tTrain Loss: 0.45000\tTrain Accuracy: 0.94700\n",
            "Epoch: 11\tValidation Time: 0.5528\n",
            "Epoch: 11\tVal Loss: 0.43693\tVal Accuracy: 0.95503\n",
            "Epoch: 12\tLearning Rate: 0.001\n",
            "Epoch: 12\tTraining Time: 0.9124\n",
            "Epoch: 12\tTrain Loss: 0.43623\tTrain Accuracy: 0.94700\n",
            "Epoch: 12\tValidation Time: 0.5555\n",
            "Epoch: 12\tVal Loss: 0.42329\tVal Accuracy: 0.95503\n",
            "Epoch: 13\tLearning Rate: 0.001\n",
            "Epoch: 13\tTraining Time: 0.8894\n",
            "Epoch: 13\tTrain Loss: 0.42321\tTrain Accuracy: 0.94700\n",
            "Epoch: 13\tValidation Time: 0.5384\n",
            "Epoch: 13\tVal Loss: 0.41038\tVal Accuracy: 0.95503\n",
            "Epoch: 14\tLearning Rate: 0.001\n",
            "Epoch: 14\tTraining Time: 0.9039\n",
            "Epoch: 14\tTrain Loss: 0.41113\tTrain Accuracy: 0.94700\n",
            "Epoch: 14\tValidation Time: 0.5364\n",
            "Epoch: 14\tVal Loss: 0.39820\tVal Accuracy: 0.95503\n",
            "Epoch: 15\tLearning Rate: 0.001\n",
            "Epoch: 15\tTraining Time: 0.8601\n",
            "Epoch: 15\tTrain Loss: 0.39963\tTrain Accuracy: 0.94700\n",
            "Epoch: 15\tValidation Time: 0.5433\n",
            "Epoch: 15\tVal Loss: 0.38674\tVal Accuracy: 0.95503\n",
            "Epoch: 16\tLearning Rate: 0.001\n",
            "Epoch: 16\tTraining Time: 0.8715\n",
            "Epoch: 16\tTrain Loss: 0.38876\tTrain Accuracy: 0.94700\n",
            "Epoch: 16\tValidation Time: 0.5290\n",
            "Epoch: 16\tVal Loss: 0.37580\tVal Accuracy: 0.95503\n",
            "Epoch: 17\tLearning Rate: 0.001\n",
            "Epoch: 17\tTraining Time: 0.8791\n",
            "Epoch: 17\tTrain Loss: 0.37854\tTrain Accuracy: 0.94700\n",
            "Epoch: 17\tValidation Time: 0.5672\n",
            "Epoch: 17\tVal Loss: 0.36554\tVal Accuracy: 0.95503\n",
            "Epoch: 18\tLearning Rate: 0.001\n",
            "Epoch: 18\tTraining Time: 0.8794\n",
            "Epoch: 18\tTrain Loss: 0.36894\tTrain Accuracy: 0.94700\n",
            "Epoch: 18\tValidation Time: 0.5475\n",
            "Epoch: 18\tVal Loss: 0.35587\tVal Accuracy: 0.95503\n",
            "Epoch: 19\tLearning Rate: 0.001\n",
            "Epoch: 19\tTraining Time: 0.8867\n",
            "Epoch: 19\tTrain Loss: 0.35986\tTrain Accuracy: 0.94700\n",
            "Epoch: 19\tValidation Time: 0.5447\n",
            "Epoch: 19\tVal Loss: 0.34680\tVal Accuracy: 0.95503\n",
            "Epoch: 20\tLearning Rate: 0.001\n",
            "Epoch: 20\tTraining Time: 0.8660\n",
            "Epoch: 20\tTrain Loss: 0.35134\tTrain Accuracy: 0.94700\n",
            "Epoch: 20\tValidation Time: 0.5468\n",
            "Epoch: 20\tVal Loss: 0.33800\tVal Accuracy: 0.95503\n",
            "Epoch: 21\tLearning Rate: 0.001\n",
            "Epoch: 21\tTraining Time: 0.8723\n",
            "Epoch: 21\tTrain Loss: 0.34318\tTrain Accuracy: 0.94700\n",
            "Epoch: 21\tValidation Time: 0.5480\n",
            "Epoch: 21\tVal Loss: 0.33004\tVal Accuracy: 0.95503\n",
            "Epoch: 22\tLearning Rate: 0.001\n",
            "Epoch: 22\tTraining Time: 0.8801\n",
            "Epoch: 22\tTrain Loss: 0.33565\tTrain Accuracy: 0.94700\n",
            "Epoch: 22\tValidation Time: 0.5498\n",
            "Epoch: 22\tVal Loss: 0.32236\tVal Accuracy: 0.95503\n",
            "Epoch: 23\tLearning Rate: 0.001\n",
            "Epoch: 23\tTraining Time: 0.8801\n",
            "Epoch: 23\tTrain Loss: 0.32843\tTrain Accuracy: 0.94700\n",
            "Epoch: 23\tValidation Time: 0.5451\n",
            "Epoch: 23\tVal Loss: 0.31507\tVal Accuracy: 0.95503\n",
            "Epoch: 24\tLearning Rate: 0.001\n",
            "Epoch: 24\tTraining Time: 0.8952\n",
            "Epoch: 24\tTrain Loss: 0.32170\tTrain Accuracy: 0.94700\n",
            "Epoch: 24\tValidation Time: 0.5888\n",
            "Epoch: 24\tVal Loss: 0.30801\tVal Accuracy: 0.95503\n",
            "Epoch: 25\tLearning Rate: 0.001\n",
            "Epoch: 25\tTraining Time: 0.8853\n",
            "Epoch: 25\tTrain Loss: 0.31525\tTrain Accuracy: 0.94700\n",
            "Epoch: 25\tValidation Time: 0.5754\n",
            "Epoch: 25\tVal Loss: 0.30164\tVal Accuracy: 0.95503\n",
            "Epoch: 26\tLearning Rate: 0.001\n",
            "Epoch: 26\tTraining Time: 0.9002\n",
            "Epoch: 26\tTrain Loss: 0.30926\tTrain Accuracy: 0.94700\n",
            "Epoch: 26\tValidation Time: 0.5557\n",
            "Epoch: 26\tVal Loss: 0.29567\tVal Accuracy: 0.95503\n",
            "Epoch: 27\tLearning Rate: 0.001\n",
            "Epoch: 27\tTraining Time: 0.8824\n",
            "Epoch: 27\tTrain Loss: 0.30360\tTrain Accuracy: 0.94700\n",
            "Epoch: 27\tValidation Time: 0.5512\n",
            "Epoch: 27\tVal Loss: 0.28982\tVal Accuracy: 0.95503\n",
            "Epoch: 28\tLearning Rate: 0.001\n",
            "Epoch: 28\tTraining Time: 0.8721\n",
            "Epoch: 28\tTrain Loss: 0.29822\tTrain Accuracy: 0.94700\n",
            "Epoch: 28\tValidation Time: 0.5442\n",
            "Epoch: 28\tVal Loss: 0.28424\tVal Accuracy: 0.95503\n",
            "Epoch: 29\tLearning Rate: 0.001\n",
            "Epoch: 29\tTraining Time: 0.8531\n",
            "Epoch: 29\tTrain Loss: 0.29312\tTrain Accuracy: 0.94700\n",
            "Epoch: 29\tValidation Time: 0.6191\n",
            "Epoch: 29\tVal Loss: 0.27903\tVal Accuracy: 0.95503\n",
            "Epoch: 30\tLearning Rate: 0.001\n",
            "Epoch: 30\tTraining Time: 0.8824\n",
            "Epoch: 30\tTrain Loss: 0.28831\tTrain Accuracy: 0.94700\n",
            "Epoch: 30\tValidation Time: 0.5504\n",
            "Epoch: 30\tVal Loss: 0.27415\tVal Accuracy: 0.95503\n",
            "Epoch: 31\tLearning Rate: 0.001\n",
            "Epoch: 31\tTraining Time: 0.8877\n",
            "Epoch: 31\tTrain Loss: 0.28383\tTrain Accuracy: 0.94700\n",
            "Epoch: 31\tValidation Time: 0.5475\n",
            "Epoch: 31\tVal Loss: 0.26961\tVal Accuracy: 0.95503\n",
            "Epoch: 32\tLearning Rate: 0.001\n",
            "Epoch: 32\tTraining Time: 0.8696\n",
            "Epoch: 32\tTrain Loss: 0.27977\tTrain Accuracy: 0.94700\n",
            "Epoch: 32\tValidation Time: 0.5456\n",
            "Epoch: 32\tVal Loss: 0.26529\tVal Accuracy: 0.95503\n",
            "Epoch: 33\tLearning Rate: 0.001\n",
            "Epoch: 33\tTraining Time: 0.8664\n",
            "Epoch: 33\tTrain Loss: 0.27572\tTrain Accuracy: 0.94700\n",
            "Epoch: 33\tValidation Time: 0.5473\n",
            "Epoch: 33\tVal Loss: 0.26116\tVal Accuracy: 0.95503\n",
            "Epoch: 34\tLearning Rate: 0.001\n",
            "Epoch: 34\tTraining Time: 0.9072\n",
            "Epoch: 34\tTrain Loss: 0.27192\tTrain Accuracy: 0.94700\n",
            "Epoch: 34\tValidation Time: 0.5603\n",
            "Epoch: 34\tVal Loss: 0.25719\tVal Accuracy: 0.95503\n",
            "Epoch: 35\tLearning Rate: 0.001\n",
            "Epoch: 35\tTraining Time: 0.8921\n",
            "Epoch: 35\tTrain Loss: 0.26835\tTrain Accuracy: 0.94700\n",
            "Epoch: 35\tValidation Time: 0.5491\n",
            "Epoch: 35\tVal Loss: 0.25348\tVal Accuracy: 0.95503\n",
            "Epoch: 36\tLearning Rate: 0.001\n",
            "Epoch: 36\tTraining Time: 0.8768\n",
            "Epoch: 36\tTrain Loss: 0.26495\tTrain Accuracy: 0.94700\n",
            "Epoch: 36\tValidation Time: 0.5475\n",
            "Epoch: 36\tVal Loss: 0.24993\tVal Accuracy: 0.95503\n",
            "Epoch: 37\tLearning Rate: 0.001\n",
            "Epoch: 37\tTraining Time: 0.8930\n",
            "Epoch: 37\tTrain Loss: 0.26170\tTrain Accuracy: 0.94700\n",
            "Epoch: 37\tValidation Time: 0.5553\n",
            "Epoch: 37\tVal Loss: 0.24662\tVal Accuracy: 0.95503\n",
            "Epoch: 38\tLearning Rate: 0.001\n",
            "Epoch: 38\tTraining Time: 0.8840\n",
            "Epoch: 38\tTrain Loss: 0.25867\tTrain Accuracy: 0.94700\n",
            "Epoch: 38\tValidation Time: 0.5487\n",
            "Epoch: 38\tVal Loss: 0.24343\tVal Accuracy: 0.95503\n",
            "Epoch: 39\tLearning Rate: 0.001\n",
            "Epoch: 39\tTraining Time: 0.8825\n",
            "Epoch: 39\tTrain Loss: 0.25580\tTrain Accuracy: 0.94700\n",
            "Epoch: 39\tValidation Time: 0.5489\n",
            "Epoch: 39\tVal Loss: 0.24036\tVal Accuracy: 0.95503\n",
            "Epoch: 40\tLearning Rate: 0.001\n",
            "Epoch: 40\tTraining Time: 0.8853\n",
            "Epoch: 40\tTrain Loss: 0.25312\tTrain Accuracy: 0.94700\n",
            "Epoch: 40\tValidation Time: 0.5476\n",
            "Epoch: 40\tVal Loss: 0.23753\tVal Accuracy: 0.95503\n",
            "Epoch: 41\tLearning Rate: 0.001\n",
            "Epoch: 41\tTraining Time: 0.8856\n",
            "Epoch: 41\tTrain Loss: 0.25052\tTrain Accuracy: 0.94700\n",
            "Epoch: 41\tValidation Time: 0.5566\n",
            "Epoch: 41\tVal Loss: 0.23491\tVal Accuracy: 0.95503\n",
            "Epoch: 42\tLearning Rate: 0.001\n",
            "Epoch: 42\tTraining Time: 0.9011\n",
            "Epoch: 42\tTrain Loss: 0.24817\tTrain Accuracy: 0.94700\n",
            "Epoch: 42\tValidation Time: 0.5982\n",
            "Epoch: 42\tVal Loss: 0.23232\tVal Accuracy: 0.95503\n",
            "Epoch: 43\tLearning Rate: 0.001\n",
            "Epoch: 43\tTraining Time: 0.9130\n",
            "Epoch: 43\tTrain Loss: 0.24589\tTrain Accuracy: 0.94700\n",
            "Epoch: 43\tValidation Time: 0.5462\n",
            "Epoch: 43\tVal Loss: 0.22996\tVal Accuracy: 0.95503\n",
            "Epoch: 44\tLearning Rate: 0.001\n",
            "Epoch: 44\tTraining Time: 0.9050\n",
            "Epoch: 44\tTrain Loss: 0.24375\tTrain Accuracy: 0.94700\n",
            "Epoch: 44\tValidation Time: 0.5632\n",
            "Epoch: 44\tVal Loss: 0.22773\tVal Accuracy: 0.95503\n",
            "Epoch: 45\tLearning Rate: 0.001\n",
            "Epoch: 45\tTraining Time: 0.8890\n",
            "Epoch: 45\tTrain Loss: 0.24172\tTrain Accuracy: 0.94700\n",
            "Epoch: 45\tValidation Time: 0.5407\n",
            "Epoch: 45\tVal Loss: 0.22547\tVal Accuracy: 0.95503\n",
            "Epoch: 46\tLearning Rate: 0.001\n",
            "Epoch: 46\tTraining Time: 0.9088\n",
            "Epoch: 46\tTrain Loss: 0.23975\tTrain Accuracy: 0.94700\n",
            "Epoch: 46\tValidation Time: 0.5698\n",
            "Epoch: 46\tVal Loss: 0.22337\tVal Accuracy: 0.95503\n",
            "Epoch: 47\tLearning Rate: 0.001\n",
            "Epoch: 47\tTraining Time: 0.9213\n",
            "Epoch: 47\tTrain Loss: 0.23793\tTrain Accuracy: 0.94700\n",
            "Epoch: 47\tValidation Time: 0.5623\n",
            "Epoch: 47\tVal Loss: 0.22145\tVal Accuracy: 0.95503\n",
            "Epoch: 48\tLearning Rate: 0.001\n",
            "Epoch: 48\tTraining Time: 0.9006\n",
            "Epoch: 48\tTrain Loss: 0.23623\tTrain Accuracy: 0.94700\n",
            "Epoch: 48\tValidation Time: 0.5434\n",
            "Epoch: 48\tVal Loss: 0.21961\tVal Accuracy: 0.95503\n",
            "Epoch: 49\tLearning Rate: 0.001\n",
            "Epoch: 49\tTraining Time: 0.8913\n",
            "Epoch: 49\tTrain Loss: 0.23458\tTrain Accuracy: 0.94700\n",
            "Epoch: 49\tValidation Time: 0.5703\n",
            "Epoch: 49\tVal Loss: 0.21782\tVal Accuracy: 0.95503\n",
            "Epoch: 50\tLearning Rate: 0.001\n",
            "Epoch: 50\tTraining Time: 0.8848\n",
            "Epoch: 50\tTrain Loss: 0.23304\tTrain Accuracy: 0.94700\n",
            "Epoch: 50\tValidation Time: 0.5536\n",
            "Epoch: 50\tVal Loss: 0.21605\tVal Accuracy: 0.95503\n",
            "Epoch: 51\tLearning Rate: 0.001\n",
            "Epoch: 51\tTraining Time: 0.8868\n",
            "Epoch: 51\tTrain Loss: 0.23163\tTrain Accuracy: 0.94700\n",
            "Epoch: 51\tValidation Time: 0.5392\n",
            "Epoch: 51\tVal Loss: 0.21458\tVal Accuracy: 0.95503\n",
            "Epoch: 52\tLearning Rate: 0.001\n",
            "Epoch: 52\tTraining Time: 0.8891\n",
            "Epoch: 52\tTrain Loss: 0.23029\tTrain Accuracy: 0.94700\n",
            "Epoch: 52\tValidation Time: 0.5442\n",
            "Epoch: 52\tVal Loss: 0.21311\tVal Accuracy: 0.95503\n",
            "Epoch: 53\tLearning Rate: 0.001\n",
            "Epoch: 53\tTraining Time: 0.8811\n",
            "Epoch: 53\tTrain Loss: 0.22903\tTrain Accuracy: 0.94700\n",
            "Epoch: 53\tValidation Time: 0.5530\n",
            "Epoch: 53\tVal Loss: 0.21163\tVal Accuracy: 0.95503\n",
            "Epoch: 54\tLearning Rate: 0.001\n",
            "Epoch: 54\tTraining Time: 0.9043\n",
            "Epoch: 54\tTrain Loss: 0.22776\tTrain Accuracy: 0.94700\n",
            "Epoch: 54\tValidation Time: 0.5440\n",
            "Epoch: 54\tVal Loss: 0.21035\tVal Accuracy: 0.95503\n",
            "Epoch: 55\tLearning Rate: 0.001\n",
            "Epoch: 55\tTraining Time: 0.8820\n",
            "Epoch: 55\tTrain Loss: 0.22659\tTrain Accuracy: 0.94700\n",
            "Epoch: 55\tValidation Time: 0.5437\n",
            "Epoch: 55\tVal Loss: 0.20901\tVal Accuracy: 0.95503\n",
            "Epoch: 56\tLearning Rate: 0.001\n",
            "Epoch: 56\tTraining Time: 0.8672\n",
            "Epoch: 56\tTrain Loss: 0.22546\tTrain Accuracy: 0.94700\n",
            "Epoch: 56\tValidation Time: 0.5427\n",
            "Epoch: 56\tVal Loss: 0.20771\tVal Accuracy: 0.95503\n",
            "Epoch: 57\tLearning Rate: 0.001\n",
            "Epoch: 57\tTraining Time: 0.8809\n",
            "Epoch: 57\tTrain Loss: 0.22439\tTrain Accuracy: 0.94700\n",
            "Epoch: 57\tValidation Time: 0.5653\n",
            "Epoch: 57\tVal Loss: 0.20659\tVal Accuracy: 0.95503\n",
            "Epoch: 58\tLearning Rate: 0.001\n",
            "Epoch: 58\tTraining Time: 0.8963\n",
            "Epoch: 58\tTrain Loss: 0.22341\tTrain Accuracy: 0.94700\n",
            "Epoch: 58\tValidation Time: 0.5394\n",
            "Epoch: 58\tVal Loss: 0.20540\tVal Accuracy: 0.95503\n",
            "Epoch: 59\tLearning Rate: 0.001\n",
            "Epoch: 59\tTraining Time: 0.8791\n",
            "Epoch: 59\tTrain Loss: 0.22243\tTrain Accuracy: 0.94700\n",
            "Epoch: 59\tValidation Time: 0.5505\n",
            "Epoch: 59\tVal Loss: 0.20431\tVal Accuracy: 0.95503\n",
            "Epoch: 60\tLearning Rate: 0.001\n",
            "Epoch: 60\tTraining Time: 0.8845\n",
            "Epoch: 60\tTrain Loss: 0.22154\tTrain Accuracy: 0.94700\n",
            "Epoch: 60\tValidation Time: 0.5649\n",
            "Epoch: 60\tVal Loss: 0.20326\tVal Accuracy: 0.95503\n",
            "Epoch: 61\tLearning Rate: 0.001\n",
            "Epoch: 61\tTraining Time: 0.8746\n",
            "Epoch: 61\tTrain Loss: 0.22071\tTrain Accuracy: 0.94700\n",
            "Epoch: 61\tValidation Time: 0.5511\n",
            "Epoch: 61\tVal Loss: 0.20239\tVal Accuracy: 0.95503\n",
            "Epoch: 62\tLearning Rate: 0.001\n",
            "Epoch: 62\tTraining Time: 0.9145\n",
            "Epoch: 62\tTrain Loss: 0.21995\tTrain Accuracy: 0.94700\n",
            "Epoch: 62\tValidation Time: 0.5730\n",
            "Epoch: 62\tVal Loss: 0.20151\tVal Accuracy: 0.95503\n",
            "Epoch: 63\tLearning Rate: 0.001\n",
            "Epoch: 63\tTraining Time: 0.8637\n",
            "Epoch: 63\tTrain Loss: 0.21920\tTrain Accuracy: 0.94700\n",
            "Epoch: 63\tValidation Time: 0.5529\n",
            "Epoch: 63\tVal Loss: 0.20059\tVal Accuracy: 0.95503\n",
            "Epoch: 64\tLearning Rate: 0.001\n",
            "Epoch: 64\tTraining Time: 0.8780\n",
            "Epoch: 64\tTrain Loss: 0.21845\tTrain Accuracy: 0.94700\n",
            "Epoch: 64\tValidation Time: 0.5484\n",
            "Epoch: 64\tVal Loss: 0.19976\tVal Accuracy: 0.95503\n",
            "Epoch: 65\tLearning Rate: 0.001\n",
            "Epoch: 65\tTraining Time: 0.8993\n",
            "Epoch: 65\tTrain Loss: 0.21778\tTrain Accuracy: 0.94700\n",
            "Epoch: 65\tValidation Time: 0.5554\n",
            "Epoch: 65\tVal Loss: 0.19901\tVal Accuracy: 0.95503\n",
            "Epoch: 66\tLearning Rate: 0.001\n",
            "Epoch: 66\tTraining Time: 0.9157\n",
            "Epoch: 66\tTrain Loss: 0.21715\tTrain Accuracy: 0.94700\n",
            "Epoch: 66\tValidation Time: 0.5758\n",
            "Epoch: 66\tVal Loss: 0.19823\tVal Accuracy: 0.95503\n",
            "Epoch: 67\tLearning Rate: 0.001\n",
            "Epoch: 67\tTraining Time: 0.9040\n",
            "Epoch: 67\tTrain Loss: 0.21656\tTrain Accuracy: 0.94700\n",
            "Epoch: 67\tValidation Time: 0.5708\n",
            "Epoch: 67\tVal Loss: 0.19750\tVal Accuracy: 0.95503\n",
            "Epoch: 68\tLearning Rate: 0.001\n",
            "Epoch: 68\tTraining Time: 0.9098\n",
            "Epoch: 68\tTrain Loss: 0.21599\tTrain Accuracy: 0.94700\n",
            "Epoch: 68\tValidation Time: 0.5923\n",
            "Epoch: 68\tVal Loss: 0.19687\tVal Accuracy: 0.95503\n",
            "Epoch: 69\tLearning Rate: 0.001\n",
            "Epoch: 69\tTraining Time: 0.9272\n",
            "Epoch: 69\tTrain Loss: 0.21549\tTrain Accuracy: 0.94700\n",
            "Epoch: 69\tValidation Time: 0.5625\n",
            "Epoch: 69\tVal Loss: 0.19621\tVal Accuracy: 0.95503\n",
            "Epoch: 70\tLearning Rate: 0.001\n",
            "Epoch: 70\tTraining Time: 0.9098\n",
            "Epoch: 70\tTrain Loss: 0.21497\tTrain Accuracy: 0.94700\n",
            "Epoch: 70\tValidation Time: 0.6165\n",
            "Epoch: 70\tVal Loss: 0.19567\tVal Accuracy: 0.95503\n",
            "Epoch: 71\tLearning Rate: 0.001\n",
            "Epoch: 71\tTraining Time: 0.9982\n",
            "Epoch: 71\tTrain Loss: 0.21455\tTrain Accuracy: 0.94700\n",
            "Epoch: 71\tValidation Time: 0.5780\n",
            "Epoch: 71\tVal Loss: 0.19509\tVal Accuracy: 0.95503\n",
            "Epoch: 72\tLearning Rate: 0.001\n",
            "Epoch: 72\tTraining Time: 0.9345\n",
            "Epoch: 72\tTrain Loss: 0.21407\tTrain Accuracy: 0.94700\n",
            "Epoch: 72\tValidation Time: 0.6010\n",
            "Epoch: 72\tVal Loss: 0.19454\tVal Accuracy: 0.95503\n",
            "Epoch: 73\tLearning Rate: 0.001\n",
            "Epoch: 73\tTraining Time: 0.9498\n",
            "Epoch: 73\tTrain Loss: 0.21367\tTrain Accuracy: 0.94700\n",
            "Epoch: 73\tValidation Time: 0.5789\n",
            "Epoch: 73\tVal Loss: 0.19399\tVal Accuracy: 0.95503\n",
            "Epoch: 74\tLearning Rate: 0.001\n",
            "Epoch: 74\tTraining Time: 0.9258\n",
            "Epoch: 74\tTrain Loss: 0.21326\tTrain Accuracy: 0.94700\n",
            "Epoch: 74\tValidation Time: 0.5511\n",
            "Epoch: 74\tVal Loss: 0.19353\tVal Accuracy: 0.95503\n",
            "Epoch: 75\tLearning Rate: 0.001\n",
            "Epoch: 75\tTraining Time: 0.8842\n",
            "Epoch: 75\tTrain Loss: 0.21290\tTrain Accuracy: 0.94700\n",
            "Epoch: 75\tValidation Time: 0.5675\n",
            "Epoch: 75\tVal Loss: 0.19304\tVal Accuracy: 0.95503\n",
            "Epoch: 76\tLearning Rate: 0.001\n",
            "Epoch: 76\tTraining Time: 0.9466\n",
            "Epoch: 76\tTrain Loss: 0.21253\tTrain Accuracy: 0.94700\n",
            "Epoch: 76\tValidation Time: 0.6016\n",
            "Epoch: 76\tVal Loss: 0.19255\tVal Accuracy: 0.95503\n",
            "Epoch: 77\tLearning Rate: 0.001\n",
            "Epoch: 77\tTraining Time: 0.9133\n",
            "Epoch: 77\tTrain Loss: 0.21218\tTrain Accuracy: 0.94700\n",
            "Epoch: 77\tValidation Time: 0.6098\n",
            "Epoch: 77\tVal Loss: 0.19208\tVal Accuracy: 0.95503\n",
            "Epoch: 78\tLearning Rate: 0.001\n",
            "Epoch: 78\tTraining Time: 0.9088\n",
            "Epoch: 78\tTrain Loss: 0.21182\tTrain Accuracy: 0.94700\n",
            "Epoch: 78\tValidation Time: 0.5925\n",
            "Epoch: 78\tVal Loss: 0.19169\tVal Accuracy: 0.95503\n",
            "Epoch: 79\tLearning Rate: 0.001\n",
            "Epoch: 79\tTraining Time: 0.9365\n",
            "Epoch: 79\tTrain Loss: 0.21154\tTrain Accuracy: 0.94700\n",
            "Epoch: 79\tValidation Time: 0.5801\n",
            "Epoch: 79\tVal Loss: 0.19125\tVal Accuracy: 0.95503\n",
            "Epoch: 80\tLearning Rate: 0.001\n",
            "Epoch: 80\tTraining Time: 0.9366\n",
            "Epoch: 80\tTrain Loss: 0.21125\tTrain Accuracy: 0.94700\n",
            "Epoch: 80\tValidation Time: 0.5932\n",
            "Epoch: 80\tVal Loss: 0.19096\tVal Accuracy: 0.95503\n",
            "Epoch: 81\tLearning Rate: 0.001\n",
            "Epoch: 81\tTraining Time: 0.8975\n",
            "Epoch: 81\tTrain Loss: 0.21099\tTrain Accuracy: 0.94700\n",
            "Epoch: 81\tValidation Time: 0.5470\n",
            "Epoch: 81\tVal Loss: 0.19060\tVal Accuracy: 0.95503\n",
            "Epoch: 82\tLearning Rate: 0.001\n",
            "Epoch: 82\tTraining Time: 0.9031\n",
            "Epoch: 82\tTrain Loss: 0.21075\tTrain Accuracy: 0.94700\n",
            "Epoch: 82\tValidation Time: 0.5681\n",
            "Epoch: 82\tVal Loss: 0.19025\tVal Accuracy: 0.95503\n",
            "Epoch: 83\tLearning Rate: 0.001\n",
            "Epoch: 83\tTraining Time: 0.8817\n",
            "Epoch: 83\tTrain Loss: 0.21052\tTrain Accuracy: 0.94700\n",
            "Epoch: 83\tValidation Time: 0.5646\n",
            "Epoch: 83\tVal Loss: 0.18997\tVal Accuracy: 0.95503\n",
            "Epoch: 84\tLearning Rate: 0.001\n",
            "Epoch: 84\tTraining Time: 0.9056\n",
            "Epoch: 84\tTrain Loss: 0.21029\tTrain Accuracy: 0.94700\n",
            "Epoch: 84\tValidation Time: 0.5867\n",
            "Epoch: 84\tVal Loss: 0.18964\tVal Accuracy: 0.95503\n",
            "Epoch: 85\tLearning Rate: 0.001\n",
            "Epoch: 85\tTraining Time: 0.9277\n",
            "Epoch: 85\tTrain Loss: 0.21009\tTrain Accuracy: 0.94700\n",
            "Epoch: 85\tValidation Time: 0.5817\n",
            "Epoch: 85\tVal Loss: 0.18936\tVal Accuracy: 0.95503\n",
            "Epoch: 86\tLearning Rate: 0.001\n",
            "Epoch: 86\tTraining Time: 0.9371\n",
            "Epoch: 86\tTrain Loss: 0.20989\tTrain Accuracy: 0.94700\n",
            "Epoch: 86\tValidation Time: 0.6064\n",
            "Epoch: 86\tVal Loss: 0.18904\tVal Accuracy: 0.95503\n",
            "Epoch: 87\tLearning Rate: 0.001\n",
            "Epoch: 87\tTraining Time: 0.8959\n",
            "Epoch: 87\tTrain Loss: 0.20971\tTrain Accuracy: 0.94700\n",
            "Epoch: 87\tValidation Time: 0.5612\n",
            "Epoch: 87\tVal Loss: 0.18878\tVal Accuracy: 0.95503\n",
            "Epoch: 88\tLearning Rate: 0.001\n",
            "Epoch: 88\tTraining Time: 0.9074\n",
            "Epoch: 88\tTrain Loss: 0.20952\tTrain Accuracy: 0.94700\n",
            "Epoch: 88\tValidation Time: 0.5671\n",
            "Epoch: 88\tVal Loss: 0.18857\tVal Accuracy: 0.95503\n",
            "Epoch: 89\tLearning Rate: 0.001\n",
            "Epoch: 89\tTraining Time: 0.9193\n",
            "Epoch: 89\tTrain Loss: 0.20937\tTrain Accuracy: 0.94700\n",
            "Epoch: 89\tValidation Time: 0.5774\n",
            "Epoch: 89\tVal Loss: 0.18833\tVal Accuracy: 0.95503\n",
            "Epoch: 90\tLearning Rate: 0.001\n",
            "Epoch: 90\tTraining Time: 0.9083\n",
            "Epoch: 90\tTrain Loss: 0.20923\tTrain Accuracy: 0.94700\n",
            "Epoch: 90\tValidation Time: 0.5694\n",
            "Epoch: 90\tVal Loss: 0.18811\tVal Accuracy: 0.95503\n",
            "Epoch: 91\tLearning Rate: 0.001\n",
            "Epoch: 91\tTraining Time: 0.9206\n",
            "Epoch: 91\tTrain Loss: 0.20908\tTrain Accuracy: 0.94700\n",
            "Epoch: 91\tValidation Time: 0.5517\n",
            "Epoch: 91\tVal Loss: 0.18789\tVal Accuracy: 0.95503\n",
            "Epoch: 92\tLearning Rate: 0.001\n",
            "Epoch: 92\tTraining Time: 0.8742\n",
            "Epoch: 92\tTrain Loss: 0.20894\tTrain Accuracy: 0.94700\n",
            "Epoch: 92\tValidation Time: 0.5724\n",
            "Epoch: 92\tVal Loss: 0.18767\tVal Accuracy: 0.95503\n",
            "Epoch: 93\tLearning Rate: 0.001\n",
            "Epoch: 93\tTraining Time: 0.8963\n",
            "Epoch: 93\tTrain Loss: 0.20881\tTrain Accuracy: 0.94700\n",
            "Epoch: 93\tValidation Time: 0.5665\n",
            "Epoch: 93\tVal Loss: 0.18751\tVal Accuracy: 0.95503\n",
            "Epoch: 94\tLearning Rate: 0.001\n",
            "Epoch: 94\tTraining Time: 0.9110\n",
            "Epoch: 94\tTrain Loss: 0.20874\tTrain Accuracy: 0.94700\n",
            "Epoch: 94\tValidation Time: 0.5812\n",
            "Epoch: 94\tVal Loss: 0.18738\tVal Accuracy: 0.95503\n",
            "Epoch: 95\tLearning Rate: 0.001\n",
            "Epoch: 95\tTraining Time: 0.9221\n",
            "Epoch: 95\tTrain Loss: 0.20863\tTrain Accuracy: 0.94700\n",
            "Epoch: 95\tValidation Time: 0.5970\n",
            "Epoch: 95\tVal Loss: 0.18722\tVal Accuracy: 0.95503\n",
            "Epoch: 96\tLearning Rate: 0.001\n",
            "Epoch: 96\tTraining Time: 0.9077\n",
            "Epoch: 96\tTrain Loss: 0.20852\tTrain Accuracy: 0.94700\n",
            "Epoch: 96\tValidation Time: 0.5710\n",
            "Epoch: 96\tVal Loss: 0.18703\tVal Accuracy: 0.95503\n",
            "Epoch: 97\tLearning Rate: 0.001\n",
            "Epoch: 97\tTraining Time: 0.9192\n",
            "Epoch: 97\tTrain Loss: 0.20843\tTrain Accuracy: 0.94700\n",
            "Epoch: 97\tValidation Time: 0.5646\n",
            "Epoch: 97\tVal Loss: 0.18685\tVal Accuracy: 0.95503\n",
            "Epoch: 98\tLearning Rate: 0.001\n",
            "Epoch: 98\tTraining Time: 0.9295\n",
            "Epoch: 98\tTrain Loss: 0.20832\tTrain Accuracy: 0.94700\n",
            "Epoch: 98\tValidation Time: 0.6045\n",
            "Epoch: 98\tVal Loss: 0.18671\tVal Accuracy: 0.95503\n",
            "Epoch: 99\tLearning Rate: 0.001\n",
            "Epoch: 99\tTraining Time: 0.9230\n",
            "Epoch: 99\tTrain Loss: 0.20823\tTrain Accuracy: 0.94700\n",
            "Epoch: 99\tValidation Time: 0.5822\n",
            "Epoch: 99\tVal Loss: 0.18655\tVal Accuracy: 0.95503\n",
            "Epoch: 100\tLearning Rate: 0.001\n",
            "Epoch: 100\tTraining Time: 0.9059\n",
            "Epoch: 100\tTrain Loss: 0.20815\tTrain Accuracy: 0.94700\n",
            "Epoch: 100\tValidation Time: 0.5739\n",
            "Epoch: 100\tVal Loss: 0.18639\tVal Accuracy: 0.95503\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEuKlzg4GdKE",
        "outputId": "51d123b2-d4a0-4400-e9c2-1cd257f1d6bd"
      },
      "source": [
        "training_plot(train_losses, valid_losses)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CjvnJMrDGdKE",
        "outputId": "81c9af90-0f4f-48fd-e4af-e167887ce6a9"
      },
      "source": [
        "test_loss, test_acc = valid(tdnn, test_loader, criterion, device, None, empty_cache)\n",
        "print('Test Loss: {:.5f}\\tTest Accuracy: {:.5f}'.format(test_loss, test_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final Validation Time: 0.5708\n",
            "Test Loss: 0.94938\tTest Accuracy: 0.67284\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYhIzld_GdKE",
        "outputId": "7d83f554-f7ec-4698-c1b2-4594179aa079"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "test_predict = test(tdnn, test_loader, device, empty_cache)\n",
        "auc = roc_auc_score(y_test, test_predict)\n",
        "print('AUC Score: {:.5f}'.format(auc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing Time: 0.5661\n",
            "AUC Score: 0.50000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72nDNZwNOZCE"
      },
      "source": [
        "# TDNN Without Padding Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BCwGvSavOZCE",
        "outputId": "55183e3d-84b7-41ca-9aa7-6b01989efc0a"
      },
      "source": [
        "tdnn = nn.Sequential(\n",
        "    nn.Conv1d(in_channels=1, out_channels=1, kernel_size=2, stride=2),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Conv1d(in_channels=1, out_channels=1, kernel_size=2, stride=2),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Conv1d(in_channels=1, out_channels=1, kernel_size=2, stride=2),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Conv1d(in_channels=1, out_channels=1, kernel_size=2, stride=2),\n",
        "    nn.ReLU(inplace=True),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(128, 2)\n",
        ")\n",
        "tdnn.to(device)\n",
        "print(tdnn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): Conv1d(1, 1, kernel_size=(2,), stride=(2,))\n",
            "  (1): ReLU(inplace=True)\n",
            "  (2): Conv1d(1, 1, kernel_size=(2,), stride=(2,))\n",
            "  (3): ReLU(inplace=True)\n",
            "  (4): Conv1d(1, 1, kernel_size=(2,), stride=(2,))\n",
            "  (5): ReLU(inplace=True)\n",
            "  (6): Conv1d(1, 1, kernel_size=(2,), stride=(2,))\n",
            "  (7): ReLU(inplace=True)\n",
            "  (8): Flatten(start_dim=1, end_dim=-1)\n",
            "  (9): Linear(in_features=128, out_features=2, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpsOvoaPOZCF"
      },
      "source": [
        "num_epochs = 100\n",
        "\n",
        "model_name = 'Simple_TDNN'\n",
        "\n",
        "lr = 0.15\n",
        "weight_decay = 5e-5\n",
        "momentum = 0.9\n",
        "\n",
        "start_epoch = 0\n",
        "train_losses = []\n",
        "valid_losses = []\n",
        "\n",
        "empty_cache = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_PFl5AEOZCF"
      },
      "source": [
        "batch_size = 64\n",
        "train_loader, val_loader, test_loader = get_tdnn_loader(x_train, y_train, x_val, y_val, x_test, y_test, cuda, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q54tU7BNOZCF"
      },
      "source": [
        "optimizer = optim.SGD(tdnn.parameters(), lr=lr, weight_decay=weight_decay, momentum=momentum)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.8, patience=1, verbose=True)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACCFmGwTOZCF",
        "outputId": "06d39323-a472-409e-cc78-69daac810ef0"
      },
      "source": [
        "train_losses, valid_losses = train_model(tdnn, model_name, train_loader, val_loader, optimizer, criterion, scheduler,\n",
        "                                         device, start_epoch, num_epochs, train_losses, valid_losses, empty_cache)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1\tLearning Rate: 0.15\n",
            "Epoch: 1\tTraining Time: 0.9402\n",
            "Epoch: 1\tTrain Loss: 0.30110\tTrain Accuracy: 0.91381\n",
            "Epoch: 1\tValidation Time: 0.5693\n",
            "Epoch: 1\tVal Loss: 0.20157\tVal Accuracy: 0.95503\n",
            "Epoch: 2\tLearning Rate: 0.15\n",
            "Epoch: 2\tTraining Time: 0.9103\n",
            "Epoch: 2\tTrain Loss: 0.21669\tTrain Accuracy: 0.94700\n",
            "Epoch: 2\tValidation Time: 0.5802\n",
            "Epoch: 2\tVal Loss: 0.18573\tVal Accuracy: 0.95503\n",
            "Epoch: 3\tLearning Rate: 0.15\n",
            "Epoch: 3\tTraining Time: 0.9016\n",
            "Epoch: 3\tTrain Loss: 0.20801\tTrain Accuracy: 0.94700\n",
            "Epoch: 3\tValidation Time: 0.5850\n",
            "Epoch: 3\tVal Loss: 0.18348\tVal Accuracy: 0.95503\n",
            "Epoch: 4\tLearning Rate: 0.15\n",
            "Epoch: 4\tTraining Time: 0.9029\n",
            "Epoch: 4\tTrain Loss: 0.20760\tTrain Accuracy: 0.94700\n",
            "Epoch: 4\tValidation Time: 0.5619\n",
            "Epoch: 4\tVal Loss: 0.18467\tVal Accuracy: 0.95503\n",
            "Epoch: 5\tLearning Rate: 0.15\n",
            "Epoch: 5\tTraining Time: 0.9105\n",
            "Epoch: 5\tTrain Loss: 0.20771\tTrain Accuracy: 0.94700\n",
            "Epoch: 5\tValidation Time: 0.5631\n",
            "Epoch: 5\tVal Loss: 0.18458\tVal Accuracy: 0.95503\n",
            "Epoch     5: reducing learning rate of group 0 to 1.2000e-01.\n",
            "Epoch: 6\tLearning Rate: 0.12\n",
            "Epoch: 6\tTraining Time: 0.8799\n",
            "Epoch: 6\tTrain Loss: 0.20751\tTrain Accuracy: 0.94700\n",
            "Epoch: 6\tValidation Time: 0.5453\n",
            "Epoch: 6\tVal Loss: 0.18399\tVal Accuracy: 0.95503\n",
            "Epoch: 7\tLearning Rate: 0.12\n",
            "Epoch: 7\tTraining Time: 0.8898\n",
            "Epoch: 7\tTrain Loss: 0.20750\tTrain Accuracy: 0.94700\n",
            "Epoch: 7\tValidation Time: 0.5515\n",
            "Epoch: 7\tVal Loss: 0.18427\tVal Accuracy: 0.95503\n",
            "Epoch     7: reducing learning rate of group 0 to 9.6000e-02.\n",
            "Epoch: 8\tLearning Rate: 0.096\n",
            "Epoch: 8\tTraining Time: 0.9021\n",
            "Epoch: 8\tTrain Loss: 0.20762\tTrain Accuracy: 0.94700\n",
            "Epoch: 8\tValidation Time: 0.5653\n",
            "Epoch: 8\tVal Loss: 0.18399\tVal Accuracy: 0.95503\n",
            "Epoch: 9\tLearning Rate: 0.096\n",
            "Epoch: 9\tTraining Time: 0.8956\n",
            "Epoch: 9\tTrain Loss: 0.20757\tTrain Accuracy: 0.94700\n",
            "Epoch: 9\tValidation Time: 0.5642\n",
            "Epoch: 9\tVal Loss: 0.18395\tVal Accuracy: 0.95503\n",
            "Epoch     9: reducing learning rate of group 0 to 7.6800e-02.\n",
            "Epoch: 10\tLearning Rate: 0.07680000000000001\n",
            "Epoch: 10\tTraining Time: 0.8999\n",
            "Epoch: 10\tTrain Loss: 0.20756\tTrain Accuracy: 0.94700\n",
            "Epoch: 10\tValidation Time: 0.5819\n",
            "Epoch: 10\tVal Loss: 0.18464\tVal Accuracy: 0.95503\n",
            "Epoch: 11\tLearning Rate: 0.07680000000000001\n",
            "Epoch: 11\tTraining Time: 0.9000\n",
            "Epoch: 11\tTrain Loss: 0.20758\tTrain Accuracy: 0.94700\n",
            "Epoch: 11\tValidation Time: 0.5613\n",
            "Epoch: 11\tVal Loss: 0.18471\tVal Accuracy: 0.95503\n",
            "Epoch    11: reducing learning rate of group 0 to 6.1440e-02.\n",
            "Epoch: 12\tLearning Rate: 0.06144000000000001\n",
            "Epoch: 12\tTraining Time: 0.8761\n",
            "Epoch: 12\tTrain Loss: 0.20745\tTrain Accuracy: 0.94700\n",
            "Epoch: 12\tValidation Time: 0.5526\n",
            "Epoch: 12\tVal Loss: 0.18402\tVal Accuracy: 0.95503\n",
            "Epoch: 13\tLearning Rate: 0.06144000000000001\n",
            "Epoch: 13\tTraining Time: 0.8913\n",
            "Epoch: 13\tTrain Loss: 0.20758\tTrain Accuracy: 0.94700\n",
            "Epoch: 13\tValidation Time: 0.5606\n",
            "Epoch: 13\tVal Loss: 0.18442\tVal Accuracy: 0.95503\n",
            "Epoch    13: reducing learning rate of group 0 to 4.9152e-02.\n",
            "Epoch: 14\tLearning Rate: 0.04915200000000001\n",
            "Epoch: 14\tTraining Time: 0.8855\n",
            "Epoch: 14\tTrain Loss: 0.20760\tTrain Accuracy: 0.94700\n",
            "Epoch: 14\tValidation Time: 0.5669\n",
            "Epoch: 14\tVal Loss: 0.18463\tVal Accuracy: 0.95503\n",
            "Epoch: 15\tLearning Rate: 0.04915200000000001\n",
            "Epoch: 15\tTraining Time: 0.9056\n",
            "Epoch: 15\tTrain Loss: 0.20768\tTrain Accuracy: 0.94700\n",
            "Epoch: 15\tValidation Time: 0.5607\n",
            "Epoch: 15\tVal Loss: 0.18386\tVal Accuracy: 0.95503\n",
            "Epoch    15: reducing learning rate of group 0 to 3.9322e-02.\n",
            "Epoch: 16\tLearning Rate: 0.03932160000000001\n",
            "Epoch: 16\tTraining Time: 0.9155\n",
            "Epoch: 16\tTrain Loss: 0.20749\tTrain Accuracy: 0.94700\n",
            "Epoch: 16\tValidation Time: 0.5513\n",
            "Epoch: 16\tVal Loss: 0.18390\tVal Accuracy: 0.95503\n",
            "Epoch: 17\tLearning Rate: 0.03932160000000001\n",
            "Epoch: 17\tTraining Time: 0.8968\n",
            "Epoch: 17\tTrain Loss: 0.20733\tTrain Accuracy: 0.94700\n",
            "Epoch: 17\tValidation Time: 0.5798\n",
            "Epoch: 17\tVal Loss: 0.18414\tVal Accuracy: 0.95503\n",
            "Epoch    17: reducing learning rate of group 0 to 3.1457e-02.\n",
            "Epoch: 18\tLearning Rate: 0.03145728000000001\n",
            "Epoch: 18\tTraining Time: 0.9043\n",
            "Epoch: 18\tTrain Loss: 0.20738\tTrain Accuracy: 0.94700\n",
            "Epoch: 18\tValidation Time: 0.5600\n",
            "Epoch: 18\tVal Loss: 0.18391\tVal Accuracy: 0.95503\n",
            "Epoch: 19\tLearning Rate: 0.03145728000000001\n",
            "Epoch: 19\tTraining Time: 0.9020\n",
            "Epoch: 19\tTrain Loss: 0.20733\tTrain Accuracy: 0.94700\n",
            "Epoch: 19\tValidation Time: 0.5581\n",
            "Epoch: 19\tVal Loss: 0.18407\tVal Accuracy: 0.95503\n",
            "Epoch    19: reducing learning rate of group 0 to 2.5166e-02.\n",
            "Epoch: 20\tLearning Rate: 0.02516582400000001\n",
            "Epoch: 20\tTraining Time: 0.9172\n",
            "Epoch: 20\tTrain Loss: 0.20734\tTrain Accuracy: 0.94700\n",
            "Epoch: 20\tValidation Time: 0.5770\n",
            "Epoch: 20\tVal Loss: 0.18397\tVal Accuracy: 0.95503\n",
            "Epoch: 21\tLearning Rate: 0.02516582400000001\n",
            "Epoch: 21\tTraining Time: 0.9608\n",
            "Epoch: 21\tTrain Loss: 0.20738\tTrain Accuracy: 0.94700\n",
            "Epoch: 21\tValidation Time: 0.5810\n",
            "Epoch: 21\tVal Loss: 0.18389\tVal Accuracy: 0.95503\n",
            "Epoch    21: reducing learning rate of group 0 to 2.0133e-02.\n",
            "Epoch: 22\tLearning Rate: 0.02013265920000001\n",
            "Epoch: 22\tTraining Time: 0.8726\n",
            "Epoch: 22\tTrain Loss: 0.20730\tTrain Accuracy: 0.94700\n",
            "Epoch: 22\tValidation Time: 0.5777\n",
            "Epoch: 22\tVal Loss: 0.18417\tVal Accuracy: 0.95503\n",
            "Epoch: 23\tLearning Rate: 0.02013265920000001\n",
            "Epoch: 23\tTraining Time: 0.9146\n",
            "Epoch: 23\tTrain Loss: 0.20733\tTrain Accuracy: 0.94700\n",
            "Epoch: 23\tValidation Time: 0.5717\n",
            "Epoch: 23\tVal Loss: 0.18407\tVal Accuracy: 0.95503\n",
            "Epoch    23: reducing learning rate of group 0 to 1.6106e-02.\n",
            "Epoch: 24\tLearning Rate: 0.01610612736000001\n",
            "Epoch: 24\tTraining Time: 0.8971\n",
            "Epoch: 24\tTrain Loss: 0.20726\tTrain Accuracy: 0.94700\n",
            "Epoch: 24\tValidation Time: 0.5525\n",
            "Epoch: 24\tVal Loss: 0.18422\tVal Accuracy: 0.95503\n",
            "Epoch: 25\tLearning Rate: 0.01610612736000001\n",
            "Epoch: 25\tTraining Time: 0.8804\n",
            "Epoch: 25\tTrain Loss: 0.20732\tTrain Accuracy: 0.94700\n",
            "Epoch: 25\tValidation Time: 0.5694\n",
            "Epoch: 25\tVal Loss: 0.18425\tVal Accuracy: 0.95503\n",
            "Epoch    25: reducing learning rate of group 0 to 1.2885e-02.\n",
            "Epoch: 26\tLearning Rate: 0.01288490188800001\n",
            "Epoch: 26\tTraining Time: 0.8903\n",
            "Epoch: 26\tTrain Loss: 0.20728\tTrain Accuracy: 0.94700\n",
            "Epoch: 26\tValidation Time: 0.5652\n",
            "Epoch: 26\tVal Loss: 0.18425\tVal Accuracy: 0.95503\n",
            "Epoch: 27\tLearning Rate: 0.01288490188800001\n",
            "Epoch: 27\tTraining Time: 0.9002\n",
            "Epoch: 27\tTrain Loss: 0.20730\tTrain Accuracy: 0.94700\n",
            "Epoch: 27\tValidation Time: 0.5603\n",
            "Epoch: 27\tVal Loss: 0.18410\tVal Accuracy: 0.95503\n",
            "Epoch    27: reducing learning rate of group 0 to 1.0308e-02.\n",
            "Epoch: 28\tLearning Rate: 0.010307921510400008\n",
            "Epoch: 28\tTraining Time: 0.8730\n",
            "Epoch: 28\tTrain Loss: 0.20731\tTrain Accuracy: 0.94700\n",
            "Epoch: 28\tValidation Time: 0.5569\n",
            "Epoch: 28\tVal Loss: 0.18403\tVal Accuracy: 0.95503\n",
            "Epoch: 29\tLearning Rate: 0.010307921510400008\n",
            "Epoch: 29\tTraining Time: 0.8915\n",
            "Epoch: 29\tTrain Loss: 0.20730\tTrain Accuracy: 0.94700\n",
            "Epoch: 29\tValidation Time: 0.5675\n",
            "Epoch: 29\tVal Loss: 0.18399\tVal Accuracy: 0.95503\n",
            "Epoch    29: reducing learning rate of group 0 to 8.2463e-03.\n",
            "Epoch: 30\tLearning Rate: 0.008246337208320006\n",
            "Epoch: 30\tTraining Time: 0.9132\n",
            "Epoch: 30\tTrain Loss: 0.20730\tTrain Accuracy: 0.94700\n",
            "Epoch: 30\tValidation Time: 0.5630\n",
            "Epoch: 30\tVal Loss: 0.18407\tVal Accuracy: 0.95503\n",
            "Epoch: 31\tLearning Rate: 0.008246337208320006\n",
            "Epoch: 31\tTraining Time: 0.8988\n",
            "Epoch: 31\tTrain Loss: 0.20726\tTrain Accuracy: 0.94700\n",
            "Epoch: 31\tValidation Time: 0.5405\n",
            "Epoch: 31\tVal Loss: 0.18406\tVal Accuracy: 0.95503\n",
            "Epoch    31: reducing learning rate of group 0 to 6.5971e-03.\n",
            "Epoch: 32\tLearning Rate: 0.006597069766656006\n",
            "Epoch: 32\tTraining Time: 0.9030\n",
            "Epoch: 32\tTrain Loss: 0.20727\tTrain Accuracy: 0.94700\n",
            "Epoch: 32\tValidation Time: 0.5456\n",
            "Epoch: 32\tVal Loss: 0.18405\tVal Accuracy: 0.95503\n",
            "Epoch: 33\tLearning Rate: 0.006597069766656006\n",
            "Epoch: 33\tTraining Time: 0.8822\n",
            "Epoch: 33\tTrain Loss: 0.20729\tTrain Accuracy: 0.94700\n",
            "Epoch: 33\tValidation Time: 0.5365\n",
            "Epoch: 33\tVal Loss: 0.18405\tVal Accuracy: 0.95503\n",
            "Epoch    33: reducing learning rate of group 0 to 5.2777e-03.\n",
            "Epoch: 34\tLearning Rate: 0.005277655813324805\n",
            "Epoch: 34\tTraining Time: 0.9116\n",
            "Epoch: 34\tTrain Loss: 0.20728\tTrain Accuracy: 0.94700\n",
            "Epoch: 34\tValidation Time: 0.5685\n",
            "Epoch: 34\tVal Loss: 0.18405\tVal Accuracy: 0.95503\n",
            "Epoch: 35\tLearning Rate: 0.005277655813324805\n",
            "Epoch: 35\tTraining Time: 0.8902\n",
            "Epoch: 35\tTrain Loss: 0.20727\tTrain Accuracy: 0.94700\n",
            "Epoch: 35\tValidation Time: 0.5555\n",
            "Epoch: 35\tVal Loss: 0.18405\tVal Accuracy: 0.95503\n",
            "Epoch    35: reducing learning rate of group 0 to 4.2221e-03.\n",
            "Epoch: 36\tLearning Rate: 0.004222124650659844\n",
            "Epoch: 36\tTraining Time: 0.8905\n",
            "Epoch: 36\tTrain Loss: 0.20726\tTrain Accuracy: 0.94700\n",
            "Epoch: 36\tValidation Time: 0.5588\n",
            "Epoch: 36\tVal Loss: 0.18406\tVal Accuracy: 0.95503\n",
            "Epoch: 37\tLearning Rate: 0.004222124650659844\n",
            "Epoch: 37\tTraining Time: 0.8931\n",
            "Epoch: 37\tTrain Loss: 0.20726\tTrain Accuracy: 0.94700\n",
            "Epoch: 37\tValidation Time: 0.5635\n",
            "Epoch: 37\tVal Loss: 0.18406\tVal Accuracy: 0.95503\n",
            "Epoch    37: reducing learning rate of group 0 to 3.3777e-03.\n",
            "Epoch: 38\tLearning Rate: 0.0033776997205278757\n",
            "Epoch: 38\tTraining Time: 0.8758\n",
            "Epoch: 38\tTrain Loss: 0.20726\tTrain Accuracy: 0.94700\n",
            "Epoch: 38\tValidation Time: 0.5604\n",
            "Epoch: 38\tVal Loss: 0.18410\tVal Accuracy: 0.95503\n",
            "Epoch: 39\tLearning Rate: 0.0033776997205278757\n",
            "Epoch: 39\tTraining Time: 0.8959\n",
            "Epoch: 39\tTrain Loss: 0.20726\tTrain Accuracy: 0.94700\n",
            "Epoch: 39\tValidation Time: 0.5642\n",
            "Epoch: 39\tVal Loss: 0.18410\tVal Accuracy: 0.95503\n",
            "Epoch    39: reducing learning rate of group 0 to 2.7022e-03.\n",
            "Epoch: 40\tLearning Rate: 0.0027021597764223006\n",
            "Epoch: 40\tTraining Time: 0.8901\n",
            "Epoch: 40\tTrain Loss: 0.20726\tTrain Accuracy: 0.94700\n",
            "Epoch: 40\tValidation Time: 0.5577\n",
            "Epoch: 40\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch: 41\tLearning Rate: 0.0027021597764223006\n",
            "Epoch: 41\tTraining Time: 0.8839\n",
            "Epoch: 41\tTrain Loss: 0.20726\tTrain Accuracy: 0.94700\n",
            "Epoch: 41\tValidation Time: 0.5656\n",
            "Epoch: 41\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch    41: reducing learning rate of group 0 to 2.1617e-03.\n",
            "Epoch: 42\tLearning Rate: 0.0021617278211378405\n",
            "Epoch: 42\tTraining Time: 0.8917\n",
            "Epoch: 42\tTrain Loss: 0.20726\tTrain Accuracy: 0.94700\n",
            "Epoch: 42\tValidation Time: 0.5490\n",
            "Epoch: 42\tVal Loss: 0.18409\tVal Accuracy: 0.95503\n",
            "Epoch: 43\tLearning Rate: 0.0021617278211378405\n",
            "Epoch: 43\tTraining Time: 0.8930\n",
            "Epoch: 43\tTrain Loss: 0.20726\tTrain Accuracy: 0.94700\n",
            "Epoch: 43\tValidation Time: 0.5620\n",
            "Epoch: 43\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch    43: reducing learning rate of group 0 to 1.7294e-03.\n",
            "Epoch: 44\tLearning Rate: 0.0017293822569102724\n",
            "Epoch: 44\tTraining Time: 0.8894\n",
            "Epoch: 44\tTrain Loss: 0.20726\tTrain Accuracy: 0.94700\n",
            "Epoch: 44\tValidation Time: 0.5538\n",
            "Epoch: 44\tVal Loss: 0.18412\tVal Accuracy: 0.95503\n",
            "Epoch: 45\tLearning Rate: 0.0017293822569102724\n",
            "Epoch: 45\tTraining Time: 0.8884\n",
            "Epoch: 45\tTrain Loss: 0.20726\tTrain Accuracy: 0.94700\n",
            "Epoch: 45\tValidation Time: 0.5588\n",
            "Epoch: 45\tVal Loss: 0.18413\tVal Accuracy: 0.95503\n",
            "Epoch    45: reducing learning rate of group 0 to 1.3835e-03.\n",
            "Epoch: 46\tLearning Rate: 0.001383505805528218\n",
            "Epoch: 46\tTraining Time: 0.9117\n",
            "Epoch: 46\tTrain Loss: 0.20726\tTrain Accuracy: 0.94700\n",
            "Epoch: 46\tValidation Time: 0.5755\n",
            "Epoch: 46\tVal Loss: 0.18413\tVal Accuracy: 0.95503\n",
            "Epoch: 47\tLearning Rate: 0.001383505805528218\n",
            "Epoch: 47\tTraining Time: 0.9031\n",
            "Epoch: 47\tTrain Loss: 0.20726\tTrain Accuracy: 0.94700\n",
            "Epoch: 47\tValidation Time: 0.5579\n",
            "Epoch: 47\tVal Loss: 0.18410\tVal Accuracy: 0.95503\n",
            "Epoch    47: reducing learning rate of group 0 to 1.1068e-03.\n",
            "Epoch: 48\tLearning Rate: 0.0011068046444225744\n",
            "Epoch: 48\tTraining Time: 0.8998\n",
            "Epoch: 48\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 48\tValidation Time: 0.5696\n",
            "Epoch: 48\tVal Loss: 0.18409\tVal Accuracy: 0.95503\n",
            "Epoch: 49\tLearning Rate: 0.0011068046444225744\n",
            "Epoch: 49\tTraining Time: 0.9116\n",
            "Epoch: 49\tTrain Loss: 0.20726\tTrain Accuracy: 0.94700\n",
            "Epoch: 49\tValidation Time: 0.5698\n",
            "Epoch: 49\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch    49: reducing learning rate of group 0 to 8.8544e-04.\n",
            "Epoch: 50\tLearning Rate: 0.0008854437155380595\n",
            "Epoch: 50\tTraining Time: 0.8779\n",
            "Epoch: 50\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 50\tValidation Time: 0.5700\n",
            "Epoch: 50\tVal Loss: 0.18410\tVal Accuracy: 0.95503\n",
            "Epoch: 51\tLearning Rate: 0.0008854437155380595\n",
            "Epoch: 51\tTraining Time: 0.9047\n",
            "Epoch: 51\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 51\tValidation Time: 0.5638\n",
            "Epoch: 51\tVal Loss: 0.18413\tVal Accuracy: 0.95503\n",
            "Epoch    51: reducing learning rate of group 0 to 7.0835e-04.\n",
            "Epoch: 52\tLearning Rate: 0.0007083549724304477\n",
            "Epoch: 52\tTraining Time: 0.8935\n",
            "Epoch: 52\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 52\tValidation Time: 0.5691\n",
            "Epoch: 52\tVal Loss: 0.18412\tVal Accuracy: 0.95503\n",
            "Epoch: 53\tLearning Rate: 0.0007083549724304477\n",
            "Epoch: 53\tTraining Time: 0.9044\n",
            "Epoch: 53\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 53\tValidation Time: 0.5666\n",
            "Epoch: 53\tVal Loss: 0.18412\tVal Accuracy: 0.95503\n",
            "Epoch    53: reducing learning rate of group 0 to 5.6668e-04.\n",
            "Epoch: 54\tLearning Rate: 0.0005666839779443582\n",
            "Epoch: 54\tTraining Time: 0.9422\n",
            "Epoch: 54\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 54\tValidation Time: 0.5901\n",
            "Epoch: 54\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch: 55\tLearning Rate: 0.0005666839779443582\n",
            "Epoch: 55\tTraining Time: 0.9338\n",
            "Epoch: 55\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 55\tValidation Time: 0.5784\n",
            "Epoch: 55\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch    55: reducing learning rate of group 0 to 4.5335e-04.\n",
            "Epoch: 56\tLearning Rate: 0.0004533471823554866\n",
            "Epoch: 56\tTraining Time: 0.9052\n",
            "Epoch: 56\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 56\tValidation Time: 0.5838\n",
            "Epoch: 56\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch: 57\tLearning Rate: 0.0004533471823554866\n",
            "Epoch: 57\tTraining Time: 0.9245\n",
            "Epoch: 57\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 57\tValidation Time: 0.5603\n",
            "Epoch: 57\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch    57: reducing learning rate of group 0 to 3.6268e-04.\n",
            "Epoch: 58\tLearning Rate: 0.0003626777458843893\n",
            "Epoch: 58\tTraining Time: 0.9091\n",
            "Epoch: 58\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 58\tValidation Time: 0.6061\n",
            "Epoch: 58\tVal Loss: 0.18410\tVal Accuracy: 0.95503\n",
            "Epoch: 59\tLearning Rate: 0.0003626777458843893\n",
            "Epoch: 59\tTraining Time: 0.9268\n",
            "Epoch: 59\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 59\tValidation Time: 0.5870\n",
            "Epoch: 59\tVal Loss: 0.18410\tVal Accuracy: 0.95503\n",
            "Epoch    59: reducing learning rate of group 0 to 2.9014e-04.\n",
            "Epoch: 60\tLearning Rate: 0.00029014219670751146\n",
            "Epoch: 60\tTraining Time: 0.9224\n",
            "Epoch: 60\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 60\tValidation Time: 0.5781\n",
            "Epoch: 60\tVal Loss: 0.18410\tVal Accuracy: 0.95503\n",
            "Epoch: 61\tLearning Rate: 0.00029014219670751146\n",
            "Epoch: 61\tTraining Time: 0.8793\n",
            "Epoch: 61\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 61\tValidation Time: 0.5629\n",
            "Epoch: 61\tVal Loss: 0.18410\tVal Accuracy: 0.95503\n",
            "Epoch    61: reducing learning rate of group 0 to 2.3211e-04.\n",
            "Epoch: 62\tLearning Rate: 0.00023211375736600917\n",
            "Epoch: 62\tTraining Time: 0.8920\n",
            "Epoch: 62\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 62\tValidation Time: 0.5426\n",
            "Epoch: 62\tVal Loss: 0.18410\tVal Accuracy: 0.95503\n",
            "Epoch: 63\tLearning Rate: 0.00023211375736600917\n",
            "Epoch: 63\tTraining Time: 0.8959\n",
            "Epoch: 63\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 63\tValidation Time: 0.5542\n",
            "Epoch: 63\tVal Loss: 0.18410\tVal Accuracy: 0.95503\n",
            "Epoch    63: reducing learning rate of group 0 to 1.8569e-04.\n",
            "Epoch: 64\tLearning Rate: 0.00018569100589280735\n",
            "Epoch: 64\tTraining Time: 0.8814\n",
            "Epoch: 64\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 64\tValidation Time: 0.5622\n",
            "Epoch: 64\tVal Loss: 0.18410\tVal Accuracy: 0.95503\n",
            "Epoch: 65\tLearning Rate: 0.00018569100589280735\n",
            "Epoch: 65\tTraining Time: 0.9059\n",
            "Epoch: 65\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 65\tValidation Time: 0.5418\n",
            "Epoch: 65\tVal Loss: 0.18410\tVal Accuracy: 0.95503\n",
            "Epoch    65: reducing learning rate of group 0 to 1.4855e-04.\n",
            "Epoch: 66\tLearning Rate: 0.0001485528047142459\n",
            "Epoch: 66\tTraining Time: 0.8832\n",
            "Epoch: 66\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 66\tValidation Time: 0.5660\n",
            "Epoch: 66\tVal Loss: 0.18410\tVal Accuracy: 0.95503\n",
            "Epoch: 67\tLearning Rate: 0.0001485528047142459\n",
            "Epoch: 67\tTraining Time: 0.8997\n",
            "Epoch: 67\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 67\tValidation Time: 0.5622\n",
            "Epoch: 67\tVal Loss: 0.18410\tVal Accuracy: 0.95503\n",
            "Epoch    67: reducing learning rate of group 0 to 1.1884e-04.\n",
            "Epoch: 68\tLearning Rate: 0.00011884224377139673\n",
            "Epoch: 68\tTraining Time: 0.8967\n",
            "Epoch: 68\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 68\tValidation Time: 0.5644\n",
            "Epoch: 68\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch: 69\tLearning Rate: 0.00011884224377139673\n",
            "Epoch: 69\tTraining Time: 0.8885\n",
            "Epoch: 69\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 69\tValidation Time: 0.5651\n",
            "Epoch: 69\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch    69: reducing learning rate of group 0 to 9.5074e-05.\n",
            "Epoch: 70\tLearning Rate: 9.50737950171174e-05\n",
            "Epoch: 70\tTraining Time: 0.9127\n",
            "Epoch: 70\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 70\tValidation Time: 0.5664\n",
            "Epoch: 70\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch: 71\tLearning Rate: 9.50737950171174e-05\n",
            "Epoch: 71\tTraining Time: 0.8961\n",
            "Epoch: 71\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 71\tValidation Time: 0.5725\n",
            "Epoch: 71\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch    71: reducing learning rate of group 0 to 7.6059e-05.\n",
            "Epoch: 72\tLearning Rate: 7.605903601369392e-05\n",
            "Epoch: 72\tTraining Time: 0.9048\n",
            "Epoch: 72\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 72\tValidation Time: 0.5553\n",
            "Epoch: 72\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch: 73\tLearning Rate: 7.605903601369392e-05\n",
            "Epoch: 73\tTraining Time: 0.9078\n",
            "Epoch: 73\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 73\tValidation Time: 0.5668\n",
            "Epoch: 73\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch    73: reducing learning rate of group 0 to 6.0847e-05.\n",
            "Epoch: 74\tLearning Rate: 6.084722881095514e-05\n",
            "Epoch: 74\tTraining Time: 0.8921\n",
            "Epoch: 74\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 74\tValidation Time: 0.5486\n",
            "Epoch: 74\tVal Loss: 0.18410\tVal Accuracy: 0.95503\n",
            "Epoch: 75\tLearning Rate: 6.084722881095514e-05\n",
            "Epoch: 75\tTraining Time: 0.8981\n",
            "Epoch: 75\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 75\tValidation Time: 0.5579\n",
            "Epoch: 75\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch    75: reducing learning rate of group 0 to 4.8678e-05.\n",
            "Epoch: 76\tLearning Rate: 4.867778304876412e-05\n",
            "Epoch: 76\tTraining Time: 0.8911\n",
            "Epoch: 76\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 76\tValidation Time: 0.5463\n",
            "Epoch: 76\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch: 77\tLearning Rate: 4.867778304876412e-05\n",
            "Epoch: 77\tTraining Time: 0.9082\n",
            "Epoch: 77\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 77\tValidation Time: 0.5828\n",
            "Epoch: 77\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch    77: reducing learning rate of group 0 to 3.8942e-05.\n",
            "Epoch: 78\tLearning Rate: 3.8942226439011294e-05\n",
            "Epoch: 78\tTraining Time: 0.8928\n",
            "Epoch: 78\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 78\tValidation Time: 0.5608\n",
            "Epoch: 78\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch: 79\tLearning Rate: 3.8942226439011294e-05\n",
            "Epoch: 79\tTraining Time: 0.8944\n",
            "Epoch: 79\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 79\tValidation Time: 0.5564\n",
            "Epoch: 79\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch    79: reducing learning rate of group 0 to 3.1154e-05.\n",
            "Epoch: 80\tLearning Rate: 3.1153781151209036e-05\n",
            "Epoch: 80\tTraining Time: 0.8829\n",
            "Epoch: 80\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 80\tValidation Time: 0.5725\n",
            "Epoch: 80\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch: 81\tLearning Rate: 3.1153781151209036e-05\n",
            "Epoch: 81\tTraining Time: 0.8995\n",
            "Epoch: 81\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 81\tValidation Time: 0.5626\n",
            "Epoch: 81\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch    81: reducing learning rate of group 0 to 2.4923e-05.\n",
            "Epoch: 82\tLearning Rate: 2.4923024920967232e-05\n",
            "Epoch: 82\tTraining Time: 0.9052\n",
            "Epoch: 82\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 82\tValidation Time: 0.5670\n",
            "Epoch: 82\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch: 83\tLearning Rate: 2.4923024920967232e-05\n",
            "Epoch: 83\tTraining Time: 0.8987\n",
            "Epoch: 83\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 83\tValidation Time: 0.5516\n",
            "Epoch: 83\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch    83: reducing learning rate of group 0 to 1.9938e-05.\n",
            "Epoch: 84\tLearning Rate: 1.9938419936773788e-05\n",
            "Epoch: 84\tTraining Time: 0.8997\n",
            "Epoch: 84\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 84\tValidation Time: 0.5578\n",
            "Epoch: 84\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch: 85\tLearning Rate: 1.9938419936773788e-05\n",
            "Epoch: 85\tTraining Time: 0.8822\n",
            "Epoch: 85\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 85\tValidation Time: 0.5524\n",
            "Epoch: 85\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch    85: reducing learning rate of group 0 to 1.5951e-05.\n",
            "Epoch: 86\tLearning Rate: 1.5950735949419033e-05\n",
            "Epoch: 86\tTraining Time: 0.8859\n",
            "Epoch: 86\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 86\tValidation Time: 0.5539\n",
            "Epoch: 86\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch: 87\tLearning Rate: 1.5950735949419033e-05\n",
            "Epoch: 87\tTraining Time: 0.9050\n",
            "Epoch: 87\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 87\tValidation Time: 0.5603\n",
            "Epoch: 87\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch    87: reducing learning rate of group 0 to 1.2761e-05.\n",
            "Epoch: 88\tLearning Rate: 1.2760588759535226e-05\n",
            "Epoch: 88\tTraining Time: 0.8991\n",
            "Epoch: 88\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 88\tValidation Time: 0.5579\n",
            "Epoch: 88\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch: 89\tLearning Rate: 1.2760588759535226e-05\n",
            "Epoch: 89\tTraining Time: 0.8785\n",
            "Epoch: 89\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 89\tValidation Time: 0.5516\n",
            "Epoch: 89\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch    89: reducing learning rate of group 0 to 1.0208e-05.\n",
            "Epoch: 90\tLearning Rate: 1.0208471007628182e-05\n",
            "Epoch: 90\tTraining Time: 0.9021\n",
            "Epoch: 90\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 90\tValidation Time: 0.5595\n",
            "Epoch: 90\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch: 91\tLearning Rate: 1.0208471007628182e-05\n",
            "Epoch: 91\tTraining Time: 0.8989\n",
            "Epoch: 91\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 91\tValidation Time: 0.5502\n",
            "Epoch: 91\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch    91: reducing learning rate of group 0 to 8.1668e-06.\n",
            "Epoch: 92\tLearning Rate: 8.166776806102545e-06\n",
            "Epoch: 92\tTraining Time: 0.9017\n",
            "Epoch: 92\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 92\tValidation Time: 0.5663\n",
            "Epoch: 92\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch: 93\tLearning Rate: 8.166776806102545e-06\n",
            "Epoch: 93\tTraining Time: 0.8834\n",
            "Epoch: 93\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 93\tValidation Time: 0.5678\n",
            "Epoch: 93\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch    93: reducing learning rate of group 0 to 6.5334e-06.\n",
            "Epoch: 94\tLearning Rate: 6.533421444882037e-06\n",
            "Epoch: 94\tTraining Time: 0.8855\n",
            "Epoch: 94\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 94\tValidation Time: 0.5577\n",
            "Epoch: 94\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch: 95\tLearning Rate: 6.533421444882037e-06\n",
            "Epoch: 95\tTraining Time: 0.8889\n",
            "Epoch: 95\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 95\tValidation Time: 0.5574\n",
            "Epoch: 95\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch    95: reducing learning rate of group 0 to 5.2267e-06.\n",
            "Epoch: 96\tLearning Rate: 5.2267371559056295e-06\n",
            "Epoch: 96\tTraining Time: 0.8920\n",
            "Epoch: 96\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 96\tValidation Time: 0.5626\n",
            "Epoch: 96\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch: 97\tLearning Rate: 5.2267371559056295e-06\n",
            "Epoch: 97\tTraining Time: 0.8892\n",
            "Epoch: 97\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 97\tValidation Time: 0.5516\n",
            "Epoch: 97\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch    97: reducing learning rate of group 0 to 4.1814e-06.\n",
            "Epoch: 98\tLearning Rate: 4.181389724724504e-06\n",
            "Epoch: 98\tTraining Time: 0.9042\n",
            "Epoch: 98\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 98\tValidation Time: 0.5495\n",
            "Epoch: 98\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch: 99\tLearning Rate: 4.181389724724504e-06\n",
            "Epoch: 99\tTraining Time: 0.9041\n",
            "Epoch: 99\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 99\tValidation Time: 0.5661\n",
            "Epoch: 99\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n",
            "Epoch    99: reducing learning rate of group 0 to 3.3451e-06.\n",
            "Epoch: 100\tLearning Rate: 3.345111779779603e-06\n",
            "Epoch: 100\tTraining Time: 0.8821\n",
            "Epoch: 100\tTrain Loss: 0.20725\tTrain Accuracy: 0.94700\n",
            "Epoch: 100\tValidation Time: 0.5765\n",
            "Epoch: 100\tVal Loss: 0.18411\tVal Accuracy: 0.95503\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQHWo97EOZCF",
        "outputId": "4eac6317-dc35-401c-a08c-6af7b595a24c"
      },
      "source": [
        "training_plot(train_losses, valid_losses)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ufvA5fWOZCF",
        "outputId": "25faacf7-4ab2-4683-8cfd-fd8792c7245a"
      },
      "source": [
        "test_loss, test_acc = valid(tdnn, test_loader, criterion, device, None, empty_cache)\n",
        "print('Test Loss: {:.5f}\\tTest Accuracy: {:.5f}'.format(test_loss, test_acc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final Validation Time: 0.5700\n",
            "Test Loss: 0.99745\tTest Accuracy: 0.67284\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRSKkixbOZCF",
        "outputId": "a43098b1-f3ff-4221-8b0d-880c691ad0d7"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "test_predict = test(tdnn, test_loader, device, empty_cache)\n",
        "auc = roc_auc_score(y_test, test_predict)\n",
        "print('AUC Score: {:.5f}'.format(auc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing Time: 0.5578\n",
            "AUC Score: 0.50000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}